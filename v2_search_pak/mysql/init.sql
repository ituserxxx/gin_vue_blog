-- phpMyAdmin SQL Dump
-- version 5.2.0
-- https://www.phpmyadmin.net/
--
-- 主机： blog_mysql
-- 生成日期： 2023-02-23 05:18:51
-- 服务器版本： 8.0.31
-- PHP 版本： 8.0.19

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- 数据库： `gin_vue_blog`
--

-- --------------------------------------------------------

--
-- 表的结构 `blog_article`
--

CREATE TABLE `blog_article` (
  `id` int NOT NULL,
  `title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `create_time` datetime NOT NULL,
  `update_time` datetime DEFAULT NULL,
  `status` tinyint DEFAULT '2' COMMENT '1-发布，2-草稿'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=DYNAMIC;

--
-- 转存表中的数据 `blog_article`
--

INSERT INTO `blog_article` (`id`, `title`, `content`, `create_time`, `update_time`, `status`) VALUES
(1, 'Linux 端口开放外部访问', '## 查看所有端口开放列表\n\n```shell\nfirewall-cmd --zone=public --list-ports\n```\n## 查看端口状态，比如redis 6379\n\n```\nfirewall-cmd --zone=public --query-port=6379/tcp\n```\n\n如果是no-表示关闭，yes-表示开启\n\n## 开启端口6379访问\n\n```\nfirewall-cmd --zone=public --add-port=6379/tcp --permanent\n```\n\n## 防火墙重载\n\n```\nfirewall-cmd --reload\n```\n\n## 再次查看端口状态\n\n```\nfirewall-cmd --zone=public --query-port=6379/tcp\n```', '2021-10-26 11:28:28', NULL, 1),
(2, 'Linux 查找某个文件的关键字内容', '## 查看某几行：\n\n```\nsed -n \'5,10p\' filename\n``` \n\n## 查看某个关键字前后几行\n\n```\ngrep -C 10 keywords filename\n```\n\n## 查看某个关键字在当前目录哪个文件\n\n```\ngrep -r \"user_id\" ./dir\n```\n\n## 实时查看某个文件最后1000行\n\n```\ntail -f -n 1000 filename\n```\n\n## cat 命令查看前后5行\n\n```\ncat log.txt | grep \'ERROR\' -C 5\n```\n\n## 查找某个内容上下几行\n```\n//-A after -B before\ngrep \'500\' -A 1 -B 1 access.log\n```', '2021-10-26 11:31:29', '2022-01-17 16:54:36', 1),
(3, '深圳冬天有点冷？', '<img src=\"https://pic2.zhimg.com/v2-caea979bfb6e8b2a54aecc7e0f2c4ba0_r.jpg\" height=400px width=100%>\n\n从决定跟你成为最好的朋友那刻开始，我就知道我疯了什么样子我都觉得最好。\n\n你说任何话，做任何事，我都觉得是对的。\n\n因为我喜欢你，所以就算你对我冷言冷语爱理不理我还是觉得你就是个性迷人有脾气的光芒万丈小可爱。\n\n我大概是没救了～我那些没由来的情绪低落闷闷不乐沉默我，也不知道它从哪里来，什么时候走！有时候我就像神经病，冷言冷语提不起兴趣。\n\n你如果也喜欢我就请你别离开我。\n\n虽然我不一定能让你很开心，我不一定完美可是你在我会很安心。\n\n我不确定自己是不是在对的时间遇见错的人，还是在错的时间遇到了对的人。\n\n我唯一能确定的是你是最好的。\n\n想你时会不自觉扬上了嘴角，听到你的名字会突然变得沉默。\n\n独自一人在夜里时会想你想到失眠。\n\n我总在问自己为什么还坚持可能没有答案但我只知道放下你我做不到。\n\n也许你不是最好的那一个，但我知道遇见你我便不想再聊任何人了。\n\n这也许是我能给予你的最认真最固执的坚持！你不需要给我任何答案。我说这些话只是想让你知道在你身上我不想留下任何遗憾。\n\n该说的都说了就剩最后一句今天的深圳有点冷能转给我10块钱买个烤红薯吗？', '2021-10-26 11:38:10', '2021-10-26 11:38:33', 1),
(4, 'Git 的一些操作', '## 本地关联的远程仓库\n\n```\n代码根目标执行：\ngit init && git add . && git commit -m\"init\" && git push\ngit remote add origin https://xxxxx.git\ngit pull\ngit branch --set-upstream-to=origin/master master\ngit pull\n查看当前分支\ngit branch\n```\n\n## 报错提示：fatal: refusing to merge unrelated histories\n\n```\ngit pull origin master --allow-unrelated-histories\n```\n\n## 更换git仓库地址方法\n\n```\n git remote rm origin      //先移除之前的远程仓库\n\n git remote add origin  http://xxx.git.com   //git地址 \n```\n\n## 将 add 后的内容撤销\n\n```\ngit reset HEAD    // 把暂存区(git add)的内容撤销到工作区\n```\n\n## 解决每次输账户密码才能git push git pull\n\n```\ngit config –global credential.helper store\ngit pull\n```\n\n再输入一次之后就不会了\n\n\n## 报错提示\n\n```\nCloning into \'czq\'...\nremote: Access denied\nfatal: unable to access \'https://gitee.com/xxxx/xxxx.git/\': The requested URL returned error: 403\n```\n\n### 解决\n\n```\ngit config --system --unset credential.helper\n\ngit config --global --unset http.proxy\n\ngit config --global --unset https.proxy\n\ncmd 端口刷新dns：ipconfig /flushdns\n```\n\n\n# Git飞行规则(Flight Rules)\n\n🌍\n*[English](README.md) ∙ [Español](README_es.md)  ∙  [Русский](README_ru.md) ∙ [繁體中文](README_zh-TW.md) ∙ [简体中文](README_zh-CN.md) ∙ [한국어](README_kr.md)  ∙  [Tiếng Việt](README_vi.md) ∙ [Français](README_fr.md) ∙ [日本語](README_ja.md)*\n\n#### 前言\n\n- 英文原版[README](https://github.com/k88hudson/git-flight-rules/blob/master/README.md)\n- 翻译可能存在错误或不标准的地方，欢迎大家指正和修改，谢谢！\n\n#### 什么是\"飞行规则\"?\n\n这是一篇给宇航员（这里就是指使用Git的程序员们）的指南，用来指导问题出现后的应对之法。\n\n>  *飞行规则(Flight Rules)* 是记录在手册上的来之不易的一系列知识，记录了某个事情发生的原因，以及怎样一步一步的进行处理。本质上, 它们是特定场景的非常详细的标准处理流程。 [...]\n\n> 自20世纪60年代初以来，NASA一直在捕捉(capturing)我们的失误，灾难和解决方案, 当时水星时代(Mercury-era)的地面小组首先开始将“经验教训”收集到一个纲要(compendium)中，该纲现在已经有上千个问题情景，从发动机故障到破损的舱口把手到计算机故障，以及它们对应的解决方案。\n\n&mdash; Chris Hadfield, *一个宇航员的生活指南(An Astronaut\'s Guide to Life)*。\n\n#### 这篇文章的约定\n\n为了清楚的表述，这篇文档里的所有例子使用了自定义的bash 提示，以便指示当前分支和是否有暂存的变化(changes)。分支名用小括号括起来，分支名后面跟的`*`表示暂存的变化(changes)。\n\n[![Join the chat at https://gitter.im/k88hudson/git-flight-rules](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/k88hudson/git-flight-rules?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*\n\n  - [编辑提交(editting commits)](#%E7%BC%96%E8%BE%91%E6%8F%90%E4%BA%A4editting-commits)\n    - [我刚才提交了什么?](#%E6%88%91%E5%88%9A%E6%89%8D%E6%8F%90%E4%BA%A4%E4%BA%86%E4%BB%80%E4%B9%88)\n    - [我的提交信息(commit message)写错了](#%E6%88%91%E7%9A%84%E6%8F%90%E4%BA%A4%E4%BF%A1%E6%81%AFcommit-message%E5%86%99%E9%94%99%E4%BA%86)\n    - [我提交(commit)里的用户名和邮箱不对](#%E6%88%91%E6%8F%90%E4%BA%A4commit%E9%87%8C%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E9%82%AE%E7%AE%B1%E4%B8%8D%E5%AF%B9)\n    - [我想从一个提交(commit)里移除一个文件](#%E6%88%91%E6%83%B3%E4%BB%8E%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4commit%E9%87%8C%E7%A7%BB%E9%99%A4%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6)\n    - [我想删除我的最后一次提交(commit)](#%E6%88%91%E6%83%B3%E5%88%A0%E9%99%A4%E6%88%91%E7%9A%84%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E6%AC%A1%E6%8F%90%E4%BA%A4commit)\n    - [删除任意提交(commit)](#%E5%88%A0%E9%99%A4%E4%BB%BB%E6%84%8F%E6%8F%90%E4%BA%A4commit)\n    - [我尝试推一个修正后的提交(amended commit)到远程，但是报错：](#%E6%88%91%E5%B0%9D%E8%AF%95%E6%8E%A8%E4%B8%80%E4%B8%AA%E4%BF%AE%E6%AD%A3%E5%90%8E%E7%9A%84%E6%8F%90%E4%BA%A4amended-commit%E5%88%B0%E8%BF%9C%E7%A8%8B%E4%BD%86%E6%98%AF%E6%8A%A5%E9%94%99)\n    - [我意外的做了一次硬重置(hard reset)，我想找回我的内容](#%E6%88%91%E6%84%8F%E5%A4%96%E7%9A%84%E5%81%9A%E4%BA%86%E4%B8%80%E6%AC%A1%E7%A1%AC%E9%87%8D%E7%BD%AEhard-reset%E6%88%91%E6%83%B3%E6%89%BE%E5%9B%9E%E6%88%91%E7%9A%84%E5%86%85%E5%AE%B9)\n  - [暂存(Staging)](#%E6%9A%82%E5%AD%98staging)\n    - [我需要把暂存的内容添加到上一次的提交(commit)](#%E6%88%91%E9%9C%80%E8%A6%81%E6%8A%8A%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9%E6%B7%BB%E5%8A%A0%E5%88%B0%E4%B8%8A%E4%B8%80%E6%AC%A1%E7%9A%84%E6%8F%90%E4%BA%A4commit)\n    - [我想要暂存一个新文件的一部分，而不是这个文件的全部](#%E6%88%91%E6%83%B3%E8%A6%81%E6%9A%82%E5%AD%98%E4%B8%80%E4%B8%AA%E6%96%B0%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E9%83%A8%E5%88%86%E8%80%8C%E4%B8%8D%E6%98%AF%E8%BF%99%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84%E5%85%A8%E9%83%A8)\n    - [我想把在一个文件里的变化(changes)加到两个提交(commit)里](#%E6%88%91%E6%83%B3%E6%8A%8A%E5%9C%A8%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E9%87%8C%E7%9A%84%E5%8F%98%E5%8C%96changes%E5%8A%A0%E5%88%B0%E4%B8%A4%E4%B8%AA%E6%8F%90%E4%BA%A4commit%E9%87%8C)\n    - [我想把暂存的内容变成未暂存，把未暂存的内容暂存起来](#%E6%88%91%E6%83%B3%E6%8A%8A%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9%E5%8F%98%E6%88%90%E6%9C%AA%E6%9A%82%E5%AD%98%E6%8A%8A%E6%9C%AA%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9%E6%9A%82%E5%AD%98%E8%B5%B7%E6%9D%A5)\n  - [未暂存(Unstaged)的内容](#%E6%9C%AA%E6%9A%82%E5%AD%98unstaged%E7%9A%84%E5%86%85%E5%AE%B9)\n    - [我想把未暂存的内容移动到一个新分支](#%E6%88%91%E6%83%B3%E6%8A%8A%E6%9C%AA%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9%E7%A7%BB%E5%8A%A8%E5%88%B0%E4%B8%80%E4%B8%AA%E6%96%B0%E5%88%86%E6%94%AF)\n    - [我想把未暂存的内容移动到另一个已存在的分支](#%E6%88%91%E6%83%B3%E6%8A%8A%E6%9C%AA%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9%E7%A7%BB%E5%8A%A8%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E5%B7%B2%E5%AD%98%E5%9C%A8%E7%9A%84%E5%88%86%E6%94%AF)\n    - [我想丢弃本地未提交的变化(uncommitted changes)](#%E6%88%91%E6%83%B3%E4%B8%A2%E5%BC%83%E6%9C%AC%E5%9C%B0%E6%9C%AA%E6%8F%90%E4%BA%A4%E7%9A%84%E5%8F%98%E5%8C%96uncommitted-changes)\n    - [我想丢弃某些未暂存的内容](#%E6%88%91%E6%83%B3%E4%B8%A2%E5%BC%83%E6%9F%90%E4%BA%9B%E6%9C%AA%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9)\n  - [分支(Branches)](#%E5%88%86%E6%94%AFbranches)\n    - [我从错误的分支拉取了内容，或把内容拉取到了错误的分支](#%E6%88%91%E4%BB%8E%E9%94%99%E8%AF%AF%E7%9A%84%E5%88%86%E6%94%AF%E6%8B%89%E5%8F%96%E4%BA%86%E5%86%85%E5%AE%B9%E6%88%96%E6%8A%8A%E5%86%85%E5%AE%B9%E6%8B%89%E5%8F%96%E5%88%B0%E4%BA%86%E9%94%99%E8%AF%AF%E7%9A%84%E5%88%86%E6%94%AF)\n    - [我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致](#%E6%88%91%E6%83%B3%E6%89%94%E6%8E%89%E6%9C%AC%E5%9C%B0%E7%9A%84%E6%8F%90%E4%BA%A4commit%E4%BB%A5%E4%BE%BF%E6%88%91%E7%9A%84%E5%88%86%E6%94%AF%E4%B8%8E%E8%BF%9C%E7%A8%8B%E7%9A%84%E4%BF%9D%E6%8C%81%E4%B8%80%E8%87%B4)\n    - [我需要提交到一个新分支，但错误的提交到了main](#%E6%88%91%E9%9C%80%E8%A6%81%E6%8F%90%E4%BA%A4%E5%88%B0%E4%B8%80%E4%B8%AA%E6%96%B0%E5%88%86%E6%94%AF%E4%BD%86%E9%94%99%E8%AF%AF%E7%9A%84%E6%8F%90%E4%BA%A4%E5%88%B0%E4%BA%86main)\n    - [我想保留来自另外一个ref-ish的整个文件](#%E6%88%91%E6%83%B3%E4%BF%9D%E7%95%99%E6%9D%A5%E8%87%AA%E5%8F%A6%E5%A4%96%E4%B8%80%E4%B8%AAref-ish%E7%9A%84%E6%95%B4%E4%B8%AA%E6%96%87%E4%BB%B6)\n    - [我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里](#%E6%88%91%E6%8A%8A%E5%87%A0%E4%B8%AA%E6%8F%90%E4%BA%A4commit%E6%8F%90%E4%BA%A4%E5%88%B0%E4%BA%86%E5%90%8C%E4%B8%80%E4%B8%AA%E5%88%86%E6%94%AF%E8%80%8C%E8%BF%99%E4%BA%9B%E6%8F%90%E4%BA%A4%E5%BA%94%E8%AF%A5%E5%88%86%E5%B8%83%E5%9C%A8%E4%B8%8D%E5%90%8C%E7%9A%84%E5%88%86%E6%94%AF%E9%87%8C)\n    - [我想删除上游(upstream)分支被删除了的本地分支](#%E6%88%91%E6%83%B3%E5%88%A0%E9%99%A4%E4%B8%8A%E6%B8%B8upstream%E5%88%86%E6%94%AF%E8%A2%AB%E5%88%A0%E9%99%A4%E4%BA%86%E7%9A%84%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF)\n    - [我不小心删除了我的分支](#%E6%88%91%E4%B8%8D%E5%B0%8F%E5%BF%83%E5%88%A0%E9%99%A4%E4%BA%86%E6%88%91%E7%9A%84%E5%88%86%E6%94%AF)\n    - [我想删除一个分支](#%E6%88%91%E6%83%B3%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E5%88%86%E6%94%AF)\n    - [我想从别人正在工作的远程分支签出(checkout)一个分支](#%E6%88%91%E6%83%B3%E4%BB%8E%E5%88%AB%E4%BA%BA%E6%AD%A3%E5%9C%A8%E5%B7%A5%E4%BD%9C%E7%9A%84%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF%E7%AD%BE%E5%87%BAcheckout%E4%B8%80%E4%B8%AA%E5%88%86%E6%94%AF)\n  - [Rebasing 和合并(Merging)](#rebasing-%E5%92%8C%E5%90%88%E5%B9%B6merging)\n    - [我想撤销rebase/merge](#%E6%88%91%E6%83%B3%E6%92%A4%E9%94%80rebasemerge)\n    - [我已经rebase过, 但是我不想强推(force push)](#%E6%88%91%E5%B7%B2%E7%BB%8Frebase%E8%BF%87-%E4%BD%86%E6%98%AF%E6%88%91%E4%B8%8D%E6%83%B3%E5%BC%BA%E6%8E%A8force-push)\n    - [我需要组合(combine)几个提交(commit)](#%E6%88%91%E9%9C%80%E8%A6%81%E7%BB%84%E5%90%88combine%E5%87%A0%E4%B8%AA%E6%8F%90%E4%BA%A4commit)\n      - [安全合并(merging)策略](#%E5%AE%89%E5%85%A8%E5%90%88%E5%B9%B6merging%E7%AD%96%E7%95%A5)\n      - [我需要将一个分支合并成一个提交(commit)](#%E6%88%91%E9%9C%80%E8%A6%81%E5%B0%86%E4%B8%80%E4%B8%AA%E5%88%86%E6%94%AF%E5%90%88%E5%B9%B6%E6%88%90%E4%B8%80%E4%B8%AA%E6%8F%90%E4%BA%A4commit)\n      - [我只想组合(combine)未推的提交(unpushed commit)](#%E6%88%91%E5%8F%AA%E6%83%B3%E7%BB%84%E5%90%88combine%E6%9C%AA%E6%8E%A8%E7%9A%84%E6%8F%90%E4%BA%A4unpushed-commit)\n    - [检查是否分支上的所有提交(commit)都合并(merge)过了](#%E6%A3%80%E6%9F%A5%E6%98%AF%E5%90%A6%E5%88%86%E6%94%AF%E4%B8%8A%E7%9A%84%E6%89%80%E6%9C%89%E6%8F%90%E4%BA%A4commit%E9%83%BD%E5%90%88%E5%B9%B6merge%E8%BF%87%E4%BA%86)\n    - [交互式rebase(interactive rebase)可能出现的问题](#%E4%BA%A4%E4%BA%92%E5%BC%8Frebaseinteractive-rebase%E5%8F%AF%E8%83%BD%E5%87%BA%E7%8E%B0%E7%9A%84%E9%97%AE%E9%A2%98)\n      - [这个rebase 编辑屏幕出现\'noop\'](#%E8%BF%99%E4%B8%AArebase-%E7%BC%96%E8%BE%91%E5%B1%8F%E5%B9%95%E5%87%BA%E7%8E%B0noop)\n      - [有冲突的情况](#%E6%9C%89%E5%86%B2%E7%AA%81%E7%9A%84%E6%83%85%E5%86%B5)\n  - [Stash](#stash)\n    - [暂存所有改动](#%E6%9A%82%E5%AD%98%E6%89%80%E6%9C%89%E6%94%B9%E5%8A%A8)\n    - [暂存指定文件](#%E6%9A%82%E5%AD%98%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6)\n    - [暂存时记录消息](#%E6%9A%82%E5%AD%98%E6%97%B6%E8%AE%B0%E5%BD%95%E6%B6%88%E6%81%AF)\n    - [使用某个指定暂存](#%E4%BD%BF%E7%94%A8%E6%9F%90%E4%B8%AA%E6%8C%87%E5%AE%9A%E6%9A%82%E5%AD%98)\n    - [暂存时保留未暂存的内容](#%E6%9A%82%E5%AD%98%E6%97%B6%E4%BF%9D%E7%95%99%E6%9C%AA%E6%9A%82%E5%AD%98%E7%9A%84%E5%86%85%E5%AE%B9)\n  - [杂项(Miscellaneous Objects)](#%E6%9D%82%E9%A1%B9miscellaneous-objects)\n    - [克隆所有子模块](#%E5%85%8B%E9%9A%86%E6%89%80%E6%9C%89%E5%AD%90%E6%A8%A1%E5%9D%97)\n    - [删除标签(tag)](#%E5%88%A0%E9%99%A4%E6%A0%87%E7%AD%BEtag)\n    - [恢复已删除标签(tag)](#%E6%81%A2%E5%A4%8D%E5%B7%B2%E5%88%A0%E9%99%A4%E6%A0%87%E7%AD%BEtag)\n    - [已删除补丁(patch)](#%E5%B7%B2%E5%88%A0%E9%99%A4%E8%A1%A5%E4%B8%81patch)\n  - [跟踪文件(Tracking Files)](#%E8%B7%9F%E8%B8%AA%E6%96%87%E4%BB%B6tracking-files)\n    - [我只想改变一个文件名字的大小写，而不修改内容](#%E6%88%91%E5%8F%AA%E6%83%B3%E6%94%B9%E5%8F%98%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E5%90%8D%E5%AD%97%E7%9A%84%E5%A4%A7%E5%B0%8F%E5%86%99%E8%80%8C%E4%B8%8D%E4%BF%AE%E6%94%B9%E5%86%85%E5%AE%B9)\n    - [我想从Git删除一个文件，但保留该文件](#%E6%88%91%E6%83%B3%E4%BB%8Egit%E5%88%A0%E9%99%A4%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%E4%BD%86%E4%BF%9D%E7%95%99%E8%AF%A5%E6%96%87%E4%BB%B6)\n  - [配置(Configuration)](#%E9%85%8D%E7%BD%AEconfiguration)\n    - [我想给一些Git命令添加别名(alias)](#%E6%88%91%E6%83%B3%E7%BB%99%E4%B8%80%E4%BA%9Bgit%E5%91%BD%E4%BB%A4%E6%B7%BB%E5%8A%A0%E5%88%AB%E5%90%8Dalias)\n    - [我想缓存一个仓库(repository)的用户名和密码](#%E6%88%91%E6%83%B3%E7%BC%93%E5%AD%98%E4%B8%80%E4%B8%AA%E4%BB%93%E5%BA%93repository%E7%9A%84%E7%94%A8%E6%88%B7%E5%90%8D%E5%92%8C%E5%AF%86%E7%A0%81)\n  - [我不知道我做错了些什么](#%E6%88%91%E4%B8%8D%E7%9F%A5%E9%81%93%E6%88%91%E5%81%9A%E9%94%99%E4%BA%86%E4%BA%9B%E4%BB%80%E4%B9%88)\n- [其它资源(Other Resources)](#%E5%85%B6%E5%AE%83%E8%B5%84%E6%BA%90other-resources)\n  - [书(Books)](#%E4%B9%A6books)\n  - [教程(Tutorials)](#%E6%95%99%E7%A8%8Btutorials)\n  - [脚本和工具(Scripts and Tools)](#%E8%84%9A%E6%9C%AC%E5%92%8C%E5%B7%A5%E5%85%B7scripts-and-tools)\n  - [GUI客户端(GUI Clients)](#gui%E5%AE%A2%E6%88%B7%E7%AB%AFgui-clients)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n## 编辑提交(editting commits)\n\n<a name=\"diff-last\"></a>\n### 我刚才提交了什么?\n\n如果你用 `git commit -a` 提交了一次变化(changes)，而你又不确定到底这次提交了哪些内容。 你就可以用下面的命令显示当前`HEAD`上的最近一次的提交(commit):\n\n```sh\n(main)$ git show\n```\n\n或者\n\n```sh\n$ git log -n1 -p\n```\n\n<a name=\"#i-wrote-the-wrong-thing-in-a-commit-message\"></a>\n### 我的提交信息(commit message)写错了\n\n如果你的提交信息(commit message)写错了且这次提交(commit)还没有推(push), 你可以通过下面的方法来修改提交信息(commit message):\n\n```sh\n$ git commit --amend --only\n```\n这会打开你的默认编辑器, 在这里你可以编辑信息. 另一方面, 你也可以用一条命令一次完成:\n\n```sh\n$ git commit --amend --only -m \'xxxxxxx\'\n```\n\n如果你已经推(push)了这次提交(commit), 你可以修改这次提交(commit)然后强推(force push), 但是不推荐这么做。\n\n<a name=\"commit-wrong-author\"></a>\n### 我提交(commit)里的用户名和邮箱不对\n\n如果这只是单个提交(commit)，修改它：\n\n```sh\n$ git commit --amend --author \"New Authorname <authoremail@mydomain.com>\"\n```\n\n如果你需要修改所有历史, 参考 \'git filter-branch\'的指南页.\n\n<a href=\"#i-want-to-remove-a-file-from-a-commit\"></a>\n### 我想从一个提交(commit)里移除一个文件\n\n通过下面的方法，从一个提交(commit)里移除一个文件:\n\n```sh\n$ git checkout HEAD^ myfile\n$ git add -A\n$ git commit --amend\n```\n\n这将非常有用，当你有一个开放的补丁(open patch)，你往上面提交了一个不必要的文件，你需要强推(force push)去更新这个远程补丁。\n\n<a name=\"delete-pushed-commit\"></a>\n### 我想删除我的的最后一次提交(commit)\n\n如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。\n\n```sh\n$ git reset HEAD^ --hard\n$ git push -f [remote] [branch]\n```\n\n如果你还没有推到远程, 把Git重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化):\n\n```\n(my-branch)$ git reset --soft HEAD^\n```\n\n这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 `git revert SHAofBadCommit`， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是rebase-safe的 (例如： 其它开发者不会从这个分支拉), 只需要使用 `git push -f`； 更多, 请参考 [the above section](#deleteremove-last-pushed-commit)。\n\n<a name=\"delete-any-commit\"></a>\n### 删除任意提交(commit)\n\n同样的警告：不到万不得已的时候不要这么做.\n\n```sh\n$ git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT\n$ git push -f [remote] [branch]\n```\n\n或者做一个 [交互式rebase](#interactive-rebase) 删除那些你想要删除的提交(commit)里所对应的行。\n\n<a name=\"#force-push\"></a>\n### 我尝试推一个修正后的提交(amended commit)到远程，但是报错：\n\n```sh\nTo https://github.com/yourusername/repo.git\n! [rejected]        mybranch -> mybranch (non-fast-forward)\nerror: failed to push some refs to \'https://github.com/tanay1337/webmaker.org.git\'\nhint: Updates were rejected because the tip of your current branch is behind\nhint: its remote counterpart. Integrate the remote changes (e.g.\nhint: \'git pull ...\') before pushing again.\nhint: See the \'Note about fast-forwards\' in \'git push --help\' for details.\n```\n\n注意, rebasing(见下面)和修正(amending)会用一个**新的提交(commit)代替旧的**, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (`-f`)。 注意 &ndash; *总是* 确保你指明一个分支!\n\n```sh\n(my-branch)$ git push origin mybranch -f\n```\n\n一般来说, **要避免强推**. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。\n\n<a href=\"undo-git-reset-hard\"></a>\n### 我意外的做了一次硬重置(hard reset)，我想找回我的内容\n\n如果你意外的做了 `git reset --hard`, 你通常能找回你的提交(commit), 因为Git对每件事都会有日志，且都会保存几天。\n\n```sh\n(main)$ git reflog\n```\n\n你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的SHA，再重置一次:\n\n```sh\n(main)$ git reset --hard SHA1234\n```\n\n这样就完成了。\n\n## 暂存(Staging)\n\n<a href=\"#i-need-to-add-staged-changes-to-the-previous-commit\"></a>\n### 我需要把暂存的内容添加到上一次的提交(commit)\n\n```sh\n(my-branch*)$ git commit --amend\n\n```\n\n<a name=\"commit-partial-new-file\"></a>\n### 我想要暂存一个新文件的一部分，而不是这个文件的全部\n\n一般来说, 如果你想暂存一个文件的一部分, 你可这样做:\n\n```sh\n$ git add --patch filename.x\n```\n\n`-p` 简写。这会打开交互模式， 你将能够用 `s` 选项来分隔提交(commit)； 然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时, 这样做:\n\n```sh\n$ git add -N filename.x\n```\n\n然后, 你需要用 `e` 选项来手动选择需要添加的行，执行 `git diff --cached` 将会显示哪些行暂存了哪些行只是保存在本地了。\n\n<a href=\"stage-in-two-commits\"></a>\n### 我想把在一个文件里的变化(changes)加到两个提交(commit)里\n\n`git add` 会把整个文件加入到一个提交. `git add -p` 允许交互式的选择你想要提交的部分.\n\n<a href=\"unstaging-edits-and-staging-the-unstaged\"></a>\n### 我想把暂存的内容变成未暂存，把未暂存的内容暂存起来\n\n多数情况下，你应该将所有的内容变为未暂存，然后再选择你想要的内容进行commit。\n但假定你就是想要这么做，这里你可以创建一个临时的commit来保存你已暂存的内容，然后暂存你的未暂存的内容并进行stash。然后reset最后一个commit将原本暂存的内容变为未暂存，最后stash pop回来。\n\n```sh\n$ git commit -m \"WIP\"\n$ git add .\n$ git stash\n$ git reset HEAD^\n$ git stash pop --index 0\n```\n\n注意1: 这里使用`pop`仅仅是因为想尽可能保持幂等。\n注意2: 假如你不加上`--index`你会把暂存的文件标记为为存储.这个[链接](https://stackoverflow.com/questions/31595873/git-stash-with-staged-files-does-stash-convert-staged-files-to-unstaged?answertab=active#tab-top) 解释得比较清楚。（不过是英文的，其大意是说，这是一个较为底层的问题，stash时会做2个commit，其中一个会记录index状态，staged的文件等东西，另一个记录worktree和其他的一些东西，如果你不在apply时加index，git会把两个一起销毁，所以staged里就空了）。\n\n## 未暂存(Unstaged)的内容\n\n<a href=\"move-unstaged-edits-to-new-branch\"></a>\n### 我想把未暂存的内容移动到一个新分支\n\n```sh\n$ git checkout -b my-branch\n```\n\n<a href=\"move-unstaged-edits-to-old-branch\"></a>\n### 我想把未暂存的内容移动到另一个已存在的分支\n\n```sh\n$ git stash\n$ git checkout my-branch\n$ git stash pop\n```\n\n<a href=\"i-want-to-discard-my-local-uncommitted-changes\"></a>\n### 我想丢弃本地未提交的变化(uncommitted changes)\n\n如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以：\n\n```sh\n# one commit\n(my-branch)$ git reset --hard HEAD^\n# two commits\n(my-branch)$ git reset --hard HEAD^^\n# four commits\n(my-branch)$ git reset --hard HEAD~4\n# or\n(main)$ git checkout -f\n```\n\n重置某个特殊的文件, 你可以用文件名做为参数:\n\n```sh\n$ git reset filename\n```\n\n<a href=\"i-want-to-discard-specific-unstaged-changes\"></a>\n### 我想丢弃某些未暂存的内容\n\n如果你想丢弃工作拷贝中的一部分内容，而不是全部。\n\n签出(checkout)不需要的内容，保留需要的。\n\n```sh\n$ git checkout -p\n# Answer y to all of the snippets you want to drop\n```\n\n另外一个方法是使用 `stash`， Stash所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。\n\n```sh\n$ git stash -p\n# Select all of the snippets you want to save\n$ git reset --hard\n$ git stash pop\n```\n\n或者, stash 你不需要的部分, 然后stash drop。\n\n```sh\n$ git stash -p\n# Select all of the snippets you don\'t want to save\n$ git stash drop\n```\n\n## 分支(Branches)\n\n<a name=\"pull-wrong-branch\"></a>\n### 我从错误的分支拉取了内容，或把内容拉取到了错误的分支\n\n这是另外一种使用 `git reflog` 情况，找到在这次错误拉(pull) 之前HEAD的指向。\n\n```sh\n(main)$ git reflog\nab7555f HEAD@{0}: pull origin wrong-branch: Fast-forward\nc5bc55a HEAD@{1}: checkout: checkout message goes here\n```\n\n重置分支到你所需的提交(desired commit):\n\n```sh\n$ git reset --hard c5bc55a\n```\n\n完成。\n\n<a href=\"discard-local-commits\"></a>\n### 我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致\n\n先确认你没有推(push)你的内容到远程。\n\n`git status` 会显示你领先(ahead)源(origin)多少个提交:\n\n```sh\n(my-branch)$ git status\n# On branch my-branch\n# Your branch is ahead of \'origin/my-branch\' by 2 commits.\n#   (use \"git push\" to publish your local commits)\n#\n```\n\n一种方法是:\n\n```sh\n(my-branch)$ git reset --hard origin/my-branch\n```\n\n<a name=\"commit-wrong-branch\"></a>\n### 我需要提交到一个新分支，但错误的提交到了main\n\n在main下创建一个新分支，不切换到新分支,仍在main下:\n\n```sh\n(main)$ git branch my-branch\n```\n\n把main分支重置到前一个提交:\n\n```sh\n(main)$ git reset --hard HEAD^\n```\n\n`HEAD^` 是 `HEAD^1` 的简写，你可以通过指定要设置的`HEAD`来进一步重置。\n\n或者, 如果你不想使用 `HEAD^`, 找到你想重置到的提交(commit)的hash(`git log` 能够完成)， 然后重置到这个hash。 使用`git push` 同步内容到远程。\n\n例如, main分支想重置到的提交的hash为`a13b85e`:\n\n```sh\n(main)$ git reset --hard a13b85e\nHEAD is now at a13b85e\n```\n\n签出(checkout)刚才新建的分支继续工作:\n\n```sh\n(main)$ git checkout my-branch\n```\n\n<a name=\"keep-whole-file\"></a>\n### 我想保留来自另外一个ref-ish的整个文件\n\n假设你正在做一个原型方案(原文为working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容:\n\n```sh\n(solution)$ git add -A && git commit -m \"Adding all changes from this spike into one big commit.\"\n```\n\n当你想要把它放到一个分支里 (可能是`feature`, 或者 `develop`), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。\n\n假设你有:\n\n  * 分支 `solution`, 拥有原型方案， 领先 `develop` 分支。\n  * 分支 `develop`, 在这里你应用原型方案的一些内容。\n\n我去可以通过把内容拿到你的分支里，来解决这个问题:\n\n```sh\n(develop)$ git checkout solution -- file1.txt\n```\n\n这会把这个文件内容从分支 `solution` 拿到分支 `develop` 里来:\n\n```sh\n# On branch develop\n# Your branch is up-to-date with \'origin/develop\'.\n# Changes to be committed:\n#  (use \"git reset HEAD <file>...\" to unstage)\n#\n#        modified:   file1.txt\n```\n\n然后, 正常提交。\n\nNote: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ [Wikipedia](https://en.wikipedia.org/wiki/Extreme_programming_practices).\n\n<a name=\"cherry-pick\"></a>\n### 我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里\n\n假设你有一个`main`分支， 执行`git log`, 你看到你做过两次提交:\n\n```sh\n(main)$ git log\n\ncommit e3851e817c451cc36f2e6f3049db528415e3c114\nAuthor: Alex Lee <alexlee@example.com>\nDate:   Tue Jul 22 15:39:27 2014 -0400\n\n    Bug #21 - Added CSRF protection\n\ncommit 5ea51731d150f7ddc4a365437931cd8be3bf3131\nAuthor: Alex Lee <alexlee@example.com>\nDate:   Tue Jul 22 15:39:12 2014 -0400\n\n    Bug #14 - Fixed spacing on title\n\ncommit a13b85e984171c6e2a1729bb061994525f626d14\nAuthor: Aki Rose <akirose@example.com>\nDate:   Tue Jul 21 01:12:48 2014 -0400\n\n    First commit\n```\n\n让我们用提交hash(commit hash)标记bug (`e3851e8` for #21, `5ea5173` for #14).\n\n首先, 我们把`main`分支重置到正确的提交(`a13b85e`):\n\n```sh\n(main)$ git reset --hard a13b85e\nHEAD is now at a13b85e\n```\n\n现在, 我们对 bug #21 创建一个新的分支:\n\n```sh\n(main)$ git checkout -b 21\n(21)$\n```\n\n接着, 我们用 *cherry-pick* 把对bug #21的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在HEAD上面。\n\n```sh\n(21)$ git cherry-pick e3851e8\n```\n\n这时候, 这里可能会产生冲突， 参见[交互式 rebasing 章](#interactive-rebase) [**冲突节**](#merge-conflict) 解决冲突.\n\n再者， 我们为bug #14 创建一个新的分支, 也基于`main`分支\n\n```sh\n(21)$ git checkout main\n(main)$ git checkout -b 14\n(14)$\n```\n\n最后, 为 bug #14 执行 `cherry-pick`:\n\n```sh\n(14)$ git cherry-pick 5ea5173\n```\n\n<a name=\"delete-stale-local-branches\"></a>\n### 我想删除上游(upstream)分支被删除了的本地分支\n一旦你在github 上面合并(merge)了一个pull request, 你就可以删除你fork里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。\n\n```sh\n$ git fetch -p\n```\n\n<a name=\'restore-a-deleted-branch\'></a>\n### 我不小心删除了我的分支\n\n如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件:\n\n```sh\n(main)$ git checkout -b my-branch\n(my-branch)$ git branch\n(my-branch)$ touch foo.txt\n(my-branch)$ ls\nREADME.md foo.txt\n```\n\n添加文件并做一次提交\n\n```sh\n(my-branch)$ git add .\n(my-branch)$ git commit -m \'foo.txt added\'\n(my-branch)$ foo.txt added\n 1 files changed, 1 insertions(+)\n create mode 100644 foo.txt\n(my-branch)$ git log\n\ncommit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012\nAuthor: siemiatj <siemiatj@example.com>\nDate:   Wed Jul 30 00:34:10 2014 +0200\n\n    foo.txt added\n\ncommit 69204cdf0acbab201619d95ad8295928e7f411d5\nAuthor: Kate Hudson <katehudson@example.com>\nDate:   Tue Jul 29 13:14:46 2014 -0400\n\n    Fixes #6: Force pushing after amending commits\n```\n\n现在我们切回到主(main)分支，‘不小心的’删除`my-branch`分支\n\n```sh\n(my-branch)$ git checkout main\nSwitched to branch \'main\'\nYour branch is up-to-date with \'origin/main\'.\n(main)$ git branch -D my-branch\nDeleted branch my-branch (was 4e3cd85).\n(main)$ echo oh noes, deleted my branch!\noh noes, deleted my branch!\n```\n\n在这时候你应该想起了`reflog`, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。\n\n```\n(main)$ git reflog\n69204cd HEAD@{0}: checkout: moving from my-branch to main\n4e3cd85 HEAD@{1}: commit: foo.txt added\n69204cd HEAD@{2}: checkout: moving from main to my-branch\n```\n\n正如你所见，我们有一个来自删除分支的提交hash(commit hash)，接下来看看是否能恢复删除了的分支。\n\n```sh\n(main)$ git checkout -b my-branch-help\nSwitched to a new branch \'my-branch-help\'\n(my-branch-help)$ git reset --hard 4e3cd85\nHEAD is now at 4e3cd85 foo.txt added\n(my-branch-help)$ ls\nREADME.md foo.txt\n```\n\n看! 我们把删除的文件找回来了。 Git的 `reflog` 在rebasing出错的时候也是同样有用的。\n\n<a name=\"i-want-to-delete-a-branch\"></a>\n### 我想删除一个分支\n\n删除一个远程分支:\n\n```sh\n(main)$ git push origin --delete my-branch\n```\n\n你也可以:\n\n```sh\n(main)$ git push origin :my-branch\n```\n\n删除一个本地分支:\n\n```sh\n(main)$ git branch -D my-branch\n```\n\n<a name=\"i-want-to-checkout-to-a-remote-branch-that-someone-else-is-working-on\"></a>\n### 我想从别人正在工作的远程分支签出(checkout)一个分支\n\n首先, 从远程拉取(fetch) 所有分支:\n\n```sh\n(main)$ git fetch --all\n```\n\n假设你想要从远程的`daves`分支签出到本地的`daves`\n\n```sh\n(main)$ git checkout --track origin/daves\nBranch daves set up to track remote branch daves from origin.\nSwitched to a new branch \'daves\'\n```\n\n(`--track` 是 `git checkout -b [branch] [remotename]/[branch]` 的简写)\n\n这样就得到了一个`daves`分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到.\n\n## Rebasing 和合并(Merging)\n\n<a name=\"undo-rebase\"></a>\n### 我想撤销rebase/merge\n\n你可以合并(merge)或rebase了一个错误的分支, 或者完成不了一个进行中的rebase/merge。 Git 在进行危险操作的时候会把原始的HEAD保存在一个叫ORIG_HEAD的变量里, 所以要把分支恢复到rebase/merge前的状态是很容易的。\n\n```sh\n(my-branch)$ git reset --hard ORIG_HEAD\n```\n\n<a name=\"force-push-rebase\"></a>\n### 我已经rebase过, 但是我不想强推(force push)\n\n不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了Git历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做:\n\n```sh\n(main)$ git checkout my-branch\n(my-branch)$ git rebase -i main\n(my-branch)$ git checkout main\n(main)$ git merge --ff-only my-branch\n```\n\n更多, 参见 [this SO thread](http://stackoverflow.com/questions/11058312/how-can-i-use-git-rebase-without-requiring-a-forced-push).\n\n<a name=\"interactive-rebase\"></a>\n### 我需要组合(combine)几个提交(commit)\n\n假设你的工作分支将会做对于 `main` 的pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 *所有* 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(main)分支是最新的和你的变化都已经提交了, 然后:\n\n```sh\n(my-branch)$ git reset --soft main\n(my-branch)$ git commit -am \"New awesome feature\"\n```\n\n如果你想要更多的控制, 想要保留时间戳, 你需要做交互式rebase (interactive rebase):\n\n```sh\n(my-branch)$ git rebase -i main\n```\n\n如果没有相对的其它分支， 你将不得不相对自己的`HEAD` 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于`HEAD~2` 进行rebase， 组合最近3次提交(commit), 相对于`HEAD~3`, 等等。\n\n```sh\n(main)$ git rebase -i HEAD~2\n```\n\n在你执行了交互式 rebase的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容:\n\n```vim\npick a9c8a1d Some refactoring\npick 01b2fd8 New awesome feature\npick b729ad5 fixup\npick e3851e8 another fix\n\n# Rebase 8074d12..b729ad5 onto 8074d12\n#\n# Commands:\n#  p, pick = use commit\n#  r, reword = use commit, but edit the commit message\n#  e, edit = use commit, but stop for amending\n#  s, squash = use commit, but meld into previous commit\n#  f, fixup = like \"squash\", but discard this commit\'s log message\n#  x, exec = run command (the rest of the line) using shell\n#\n# These lines can be re-ordered; they are executed from top to bottom.\n#\n# If you remove a line here THAT COMMIT WILL BE LOST.\n#\n# However, if you remove everything, the rebase will be aborted.\n#\n# Note that empty commits are commented out\n```\n\n所有以 `#` 开头的行都是注释, 不会影响 rebase.\n\n然后，你可以用任何上面命令列表的命令替换 `pick`, 你也可以通过删除对应的行来删除一个提交(commit)。\n\n例如, 如果你想 **单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面**, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 `f`:\n\n```vim\npick a9c8a1d Some refactoring\npick 01b2fd8 New awesome feature\nf b729ad5 fixup\nf e3851e8 another fix\n```\n\n如果你想组合这些提交(commit) **并重命名这个提交(commit)**, 你应该在第二个提交(commit)旁边添加一个`r`，或者更简单的用`s` 替代 `f`:\n\n```vim\npick a9c8a1d Some refactoring\npick 01b2fd8 New awesome feature\ns b729ad5 fixup\ns e3851e8 another fix\n```\n\n你可以在接下来弹出的文本提示框里重命名提交(commit)。\n\n```vim\nNewer, awesomer features\n\n# Please enter the commit message for your changes. Lines starting\n# with \'#\' will be ignored, and an empty message aborts the commit.\n# rebase in progress; onto 8074d12\n# You are currently editing a commit while rebasing branch \'main\' on \'8074d12\'.\n#\n# Changes to be committed:\n#	modified:   README.md\n#\n\n```\n\n如果成功了, 你应该看到类似下面的内容:\n\n```sh\n(main)$ Successfully rebased and updated refs/heads/main.\n```\n\n#### 安全合并(merging)策略\n`--no-commit` 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 `no-ff` 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。\n\n```sh\n(main)$ git merge --no-ff --no-commit my-branch\n```\n\n#### 我需要将一个分支合并成一个提交(commit)\n\n```sh\n(main)$ git merge --squash my-branch\n```\n\n<a name=\"rebase-unpushed-commits\"></a>\n#### 我只想组合(combine)未推的提交(unpushed commit)\n\n有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。\n\n```sh\n(main)$ git rebase -i @{u}\n```\n\n这会产生一次交互式的rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行reorder/fix/squash 都是安全的。\n\n<a name=\"check-if-all-commits-on-a-branch-are-merged\"></a>\n### 检查是否分支上的所有提交(commit)都合并(merge)过了\n\n检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的head(或任何 commits)之间做一次diff:\n\n```sh\n(main)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll\n```\n\n这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是:\n\n```sh\n(main)$ git log main ^feature/120-on-scroll --no-merges\n```\n\n### 交互式rebase(interactive rebase)可能出现的问题\n\n<a name=\"noop\"></a>\n#### 这个rebase 编辑屏幕出现\'noop\'\n\n如果你看到的是这样:\n```\nnoop\n```\n\n这意味着你rebase的分支和当前分支在同一个提交(commit)上, 或者 *领先(ahead)* 当前分支。 你可以尝试:\n\n* 检查确保主(main)分支没有问题\n* rebase  `HEAD~2` 或者更早\n\n<a name=\"merge-conflict\"></a>\n#### 有冲突的情况\n\n如果你不能成功的完成rebase, 你可能必须要解决冲突。\n\n首先执行 `git status` 找出哪些文件有冲突:\n\n```sh\n(my-branch)$ git status\nOn branch my-branch\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n	modified:   README.md\n```\n\n在这个例子里面, `README.md` 有冲突。 打开这个文件找到类似下面的内容:\n\n```vim\n   <<<<<<< HEAD\n   some code\n   =========\n   some code\n   >>>>>>> new-commit\n```\n\n你需要解决新提交的代码(示例里, 从中间`==`线到`new-commit`的地方)与`HEAD` 之间不一样的地方.\n\n有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor):\n\n```sh\n(main*)$ git mergetool -t opendiff\n```\n\n在你解决完所有冲突和测试过后, `git add` 变化了的(changed)文件, 然后用`git rebase --continue` 继续rebase。\n\n```sh\n(my-branch)$ git add README.md\n(my-branch)$ git rebase --continue\n```\n\n如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行`git rebase --skip`。\n\n任何时候你想结束整个rebase 过程，回来rebase前的分支状态, 你可以做:\n\n```sh\n(my-branch)$ git rebase --abort\n```\n\n<a name=\"stashing\"></a>\n## Stash\n\n### 暂存所有改动\n\n暂存你工作目录下的所有改动\n\n```sh\n$ git stash\n```\n\n你可以使用`-u`来排除一些文件\n\n```sh\n$ git stash -u\n```\n\n### 暂存指定文件\n\n假设你只想暂存某一个文件\n\n```sh\n$ git stash push working-directory-path/filename.ext\n```\n\n假设你想暂存多个文件\n\n```sh\n$ git stash push working-directory-path/filename1.ext working-directory-path/filename2.ext\n```\n\n<a name=\"stash-msg\"></a>\n### 暂存时记录消息\n\n这样你可以在`list`时看到它\n\n```sh\n$ git stash save <message>\n```\n或\n```sh\n$ git stash push -m <message>\n```\n<a name=\"stash-apply-specific\"></a>\n### 使用某个指定暂存\n\n首先你可以查看你的`stash`记录\n\n```sh\n$ git stash list\n```\n\n然后你可以`apply`某个`stash`\n\n```sh\n$ git stash apply \"stash@{n}\"\n```\n\n此处， \'n\'是`stash`在栈中的位置，最上层的`stash`会是0\n\n除此之外，也可以使用时间标记(假如你能记得的话)。\n\n```sh\n$ git stash apply \"stash@{2.hours.ago}\"\n```\n\n<a href=\"stage-and-keep-unstaged\"></a>\n### 暂存时保留未暂存的内容\n\n你需要手动create一个`stash commit`， 然后使用`git stash store`。\n\n```sh\n$ git stash create\n$ git stash store -m \"commit-message\" CREATED_SHA1\n```\n\n<a name=\"miscellaneous-objects\"></a>\n## 杂项(Miscellaneous Objects)\n\n<a name=\"clone-submodules\"></a>\n### 克隆所有子模块\n\n```sh\n$ git clone --recursive git://github.com/foo/bar.git\n```\n\n如果已经克隆了:\n\n```sh\n$ git submodule update --init --recursive\n```\n\n<a name=\"delete-tag\"></a>\n### 删除标签(tag)\n\n```sh\n$ git tag -d <tag_name>\n$ git push <remote> :refs/tags/<tag_name>\n```\n\n<a name=\"recover-tag\"></a>\n### 恢复已删除标签(tag)\n\n如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag):\n\n```sh\n$ git fsck --unreachable | grep tag\n```\n\n记下这个标签(tag)的hash，然后用Git的 [update-ref](http://git-scm.com/docs/git-update-ref):\n\n```sh\n$ git update-ref refs/tags/<tag_name> <hash>\n```\n\n这时你的标签(tag)应该已经恢复了。\n\n<a name=\"deleted-patch\"></a>\n### 已删除补丁(patch)\n\n如果某人在 GitHub 上给你发了一个pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 `git am`。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。\n\n做完提交后, 再修改作者，参见[变更作者](#commit-wrong-author)。 然后, 应用变化, 再发起一个新的pull request。\n\n## 跟踪文件(Tracking Files)\n\n<a href=\"i-want-to-change-a-file-names-capitalization-without-changing-the-contents-of-the-file\"></a>\n### 我只想改变一个文件名字的大小写，而不修改内容\n\n```sh\n(main)$ git mv --force myfile MyFile\n```\n\n<a href=\"remove-from-git\"></a>\n### 我想从Git删除一个文件，但保留该文件\n\n```sh\n(main)$ git rm --cached log.txt\n```\n\n## 配置(Configuration)\n\n<a name=\"adding-command-aliases\"></a>\n### 我想给一些Git命令添加别名(alias)\n\n在 OS X 和 Linux 下, 你的 Git的配置文件储存在 ```~/.gitconfig```。我在```[alias]``` 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下:\n\n```vim\n[alias]\n    a = add\n    amend = commit --amend\n    c = commit\n    ca = commit --amend\n    ci = commit -a\n    co = checkout\n    d = diff\n    dc = diff --changed\n    ds = diff --staged\n    f = fetch\n    loll = log --graph --decorate --pretty=oneline --abbrev-commit\n    m = merge\n    one = log --pretty=oneline\n    outstanding = rebase -i @{u}\n    s = status\n    unpushed = log @{u}\n    wc = whatchanged\n    wip = rebase -i @{u}\n    zap = fetch -p\n```\n\n<a name=\"credential-helper\"></a>\n### 我想缓存一个仓库(repository)的用户名和密码\n\n你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper能帮你。\n\n```sh\n$ git config --global credential.helper cache\n# Set git to use the credential memory cache\n```\n\n```sh\n$ git config --global credential.helper \'cache --timeout=3600\'\n# Set the cache to timeout after 1 hour (setting is in seconds)\n```\n\n<a href=\"#ive-no-idea-what-i-did-wrong\"></a>\n## 我不知道我做错了些什么\n\n你把事情搞砸了：你 `重置(reset)` 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。\n\n这就是 `git reflog` 的目的， `reflog` 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次HEAD的改变, 一条新的记录就会增加到`reflog`。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。\n\n```sh\n(main)$ git reflog\n0a2e358 HEAD@{0}: reset: moving to HEAD~2\n0254ea7 HEAD@{1}: checkout: moving from 2.2 to main\nc10f740 HEAD@{2}: checkout: moving from main to 2.2\n```\n\n上面的reflog展示了从main分支签出(checkout)到2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 `HEAD@{0}`标识.\n\n如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前main上指向的提交(0254ea7)。\n\n```sh\n$ git reset --hard 0254ea7\n```\n\n然后使用git reset就可以把main改回到之前的commit，这提供了一个在历史被意外更改情况下的安全网。\n\n([摘自](https://www.atlassian.com/git/tutorials/rewriting-history/git-reflog)).\n\n# 其它资源(Other Resources)\n\n## 书(Books)\n\n* [Pro Git](https://git-scm.com/book/en/v2) - Scott Chacon\'s excellent git book\n* [Git Internals](https://github.com/pluralsight/git-internals-pdf) - Scott Chacon\'s other excellent git book\n\n## 教程(Tutorials)\n\n* [Learn Git branching](https://learngitbranching.js.org/) 一个基于网页的交互式 branching/merging/rebasing 教程\n* [Getting solid at Git rebase vs. merge](https://medium.com/@porteneuve/getting-solid-at-git-rebase-vs-merge-4fa1a48c53aa)\n* [git-workflow](https://github.com/asmeurer/git-workflow) - [Aaron Meurer](https://github.com/asmeurer)的怎么使用Git为开源仓库贡献\n* [GitHub as a workflow](http://hugogiraudel.com/2015/08/13/github-as-a-workflow/) - 使用GitHub做为工作流的趣事, 尤其是空PRs\n\n## 脚本和工具(Scripts and Tools)\n\n* [firstaidgit.io](http://firstaidgit.io/) 一个可搜索的最常被问到的Git的问题\n* [git-extra-commands](https://github.com/unixorn/git-extra-commands) - 一堆有用的额外的Git脚本\n* [git-extras](https://github.com/tj/git-extras) - GIT 工具集 -- repo summary, repl, changelog population, author commit percentages and more\n* [git-fire](https://github.com/qw3rtman/git-fire) - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。\n* [git-tips](https://github.com/git-tips/tips) - Git小提示\n* [git-town](https://github.com/Originate/git-town) - 通用，高级Git工作流支持！ http://www.git-town.com\n\n## GUI客户端(GUI Clients)\n* [GitKraken](https://www.gitkraken.com/) - 豪华的Git客户端 Windows, Mac & Linux\n* [git-cola](https://git-cola.github.io/) - 另外一个Git客户端 Windows & OS X\n* [GitUp](https://github.com/git-up/GitUp) - 一个新的Git客户端，在处理Git的复杂性上有自己的特点\n* [gitx-dev](https://rowanj.github.io/gitx/) - 图形化的Git客户端 OS X\n* [Source Tree](https://www.sourcetreeapp.com/) - 免费的图形化Git客户端 Windows & OS X\n* [Tower](http://www.git-tower.com/) - 图形化Git客户端 OS X(付费)\n', '2021-10-26 14:15:31', '2021-10-26 14:24:51', 1),
(5, 'Go 打包部署Linux环境', '## 打包成二进制文件，可以在 Linux 平台运行\n\n进入到 main.go 文件目录下,执行命令：\n\n```\nset GOARCH=amd64\nset GOOS=linux\ngo build -o main main.go\n```\n\n将生成 main 二进制可执行文件，放置 Linux 环境，赋予权限：\n\n```\nchmod 777 main\n```\n\n后台执行：\n\n```\nnohup ./main &\n```\n\n\n### goland设置代理\nGOPROXY=https://goproxy.cn,direct\n', '2020-06-09 17:19:39', '2021-10-27 11:05:13', 1),
(6, '进程、线程、协程', '# 进程、线程、协程\n\n- 进程:进程是具有一定独立功能的程序，进程是系统资源分配和调度的最小单位。 每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。\n\n- 线程:线程是进程的一个实体,线程是内核态,而且是 CPU 调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。\n\n- 协程:协程是一种用户态的轻量级线程，协程的调度完全是由用户来控制的。协程拥有自己的寄存器上下文和栈。 协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。\n## 进程\n\n\n\n### 描述\n\n进程是程序的一次执行过程，是一个动态概念，是程序在执行过程中分配和管理资源的基本单位\n\n### 与Cpu关系\n\n操作系统会拆分CPU为一段段时间的运行片，轮流分配给不同的程序\n\n对于多cpu，多个进程可以并行在多个cpu中计算，当然也会存在进程切换\n\n对于单cpu，多个进程在这个单cpu中是并发运行，根据时间片读取上下文+执行程序+保存上下文\n\n同一个进程同一时间段只能在一个cpu中运行，如果进程数小于cpu数，那么未使用的cpu将会空闲\n\n### 多进程\n\n指计算机系统可以同时执行多个进程，从一个进程到另外一个进程的转换是由操作系统内核管理的，一般是同时运\n\n行多个软件\n\n\n\n### 与线程区别\n\n- 进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位\n\n- 一个程序有至少一个进程，一个进程有至少一个线程\n- 进程有自己的独立地址空间，线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多\n- 多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间\n- 每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行\n\n### 进程间通信\n\n-  管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在父子进程关系（亲缘关系）进程间使用。\n- 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。\n- 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。\n- 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。\n- 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。\n- 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。\n- 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。\n\n## 线程\n\n### 描述\n\n- 操作系统能够进行运算调度的最小单位。线程被包含在进程之中，是进程中的实际运作单位，一个进程内可以包含多个线程，\n\n-  线程是资源调度的最小单位\n- 线程在等待IO的过程中会陷入阻塞状态\n\n\n\n### 资源和开销\n\n- 同一进程中的多条线程共享该进程中的全部系统资源，如虚拟地址空间，文件描述符文件描述符和信号处理等等。但同一进程中的多个线程有各自的调用栈、寄存器环境、线程本地存储等信息。\n\n- 线程创建的开销主要是线程堆栈的建立，分配内存的开销。这些开销并不大，**最大**的开销发生在**线程上下文切换**的时候。\n\n### 线程间通信\n\n注：**线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制**\n\n- 锁机制：包括互斥锁、条件变量、读写锁、**自旋锁**\n- 互斥锁**提供了以排他方式防止数据结构被并发修改的方法。互斥锁确保同一时间只能有一个线程访问共享资源。当锁被占用时试图对其加锁的线程都进入阻塞状态(释放CPU资源使其由运行状态进入等待状态)。当锁释放时哪个等待线程能获得该锁取决于内核的调度。\n\n- **读写锁**允许多个线程同时读共享数据，而对写操作是互斥的。当以写模式加锁而处于写状态时任何试图加锁的线程(不论是读或写)都阻塞，当以读状态模式加锁而处于读状态时“读”线程不阻塞，“写”线程阻塞。读模式共享，写模式互斥。\n\n- **条件变量**可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。\n\n- **自旋锁**上锁受阻时线程不阻塞而是在循环中轮询查看能否获得该锁，没有线程的切换因而没有切换开销，不过对CPU的霸占会导致CPU资源的浪费。 所以自旋锁适用于并行结构(多个处理器)或者适用于锁被持有时间短而不希望在线程切换产生开销的情况。\n\n-  **信号量机制(Semaphore)**：包括无名线程信号量和命名线程信号量 **信号机制(Signal)**：类似进程间的信号处理\n\n- **线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。**\n\n\n\n\n\n## 协程\n\n### 描述\n\n- 协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。\n\n- 协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。\n- 协程只有在等待IO的过程中才能重复利用线程\n- 在协程中不能调用导致线程阻塞的操作。也就是说，协程只有和异步IO结合起来，才能发挥最大的威力。\n\n### 资源开销\n\n- 协程的调度完全由用户控制\n  - 协程拥有自己的寄存器上下文和栈，协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作用户空间栈，完全没有内核切换的开销\n- Goroutine 是 Golang 的协程实现。Goroutine 的栈只有 2KB大小，而且是**动态伸缩**的，可以按需调整大小，最大可达 1G 相比线程来说既不浪费又灵活\n- 线程也都有一个固定大小的内存块来做栈，一般会是 2MB 大小，线程栈会用来存储线程上下文信息。2MB 的线程栈和协程栈相比大了很多\n\n### 阻塞\n\n- 协程中调用阻塞式i/o会阻塞整个线程，因为协程之间的调度是**用户在协程中主动调用协程切换功能**（比如yield语句）手动实现的，而不是系统自动强制执行的，如果一个协程调用了阻塞式i/o，这个协程就被阻塞了，就无法调用协程切换功能去执行其它协程，也就意味着整个线程被阻塞了，所以协程中是不能直接调用任何会阻塞线程的功能的，需要进行封装。\n\n- 对阻塞式操作的封装不是简单的让出协程执行权，因为一旦让出执行权，该协程就不会被继续执行，后续的阻塞式操作也就没有机会被完成了，正确的做法是新建一个线程或者从线程池中分配一个线程，在这个线程中执行需要的阻塞式操作，同时将当前协程休眠（让出执行权），在新线程中的操作完成后，再唤醒协程。\n\n', '2020-06-09 10:52:21', '2021-10-27 11:04:40', 1),
(7, 'Golang  GMP模型', '# GMP 模型\n\n****\n\n-  M (thread) \n- G (goroutine)\n-  P (Processor）\n\n调度模型图\n\n![avatar](https://cdn.learnku.com/uploads/images/202003/11/58489/Ugu3C2WSpM.jpeg!large)\n\n\n\n**全局队列**（Global Queue）：存放等待运行的 G\n\n**P 的本地队列**：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。\n\n**P 列表**：所有的 P 都在程序启动时创建，并保存在数组中，最多有 `GOMAXPROCS`(可配置) 个。\n\n**M**：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去\n\n**Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行**。\n\n未完\n\n参考：https://learnku.com/articles/41728\n\n', '2021-10-27 10:53:35', NULL, 1),
(8, 'Laravel 框架原理', '# laravel框架原理\nLaravel的请求周期可以分成6步骤\n- 注册类文件，自动加载预设文件\n- 创建服务容器\n- 创建 HTTP / Console 内核\n- 载入服务提供者到容器\n- 分发请求\n- 发送响应并结束\n\nLaravel是单一入口方式，所有的数据请求都需要经过public/index.php的文件，\n首先会检测是否处于维护阶段（maintenance.php）\n\n\n## 注册类文件自动加载器\nLaravel然后通过composer进行依赖管理，从composer的autoload.php文件里面自动预加载设置好的文件\n\n## 创建服务容器\nindex.php加载和运行bootstrap/app.php文件，获取应用实例，创建服务容器(函数方法，类等的代码结构体)。\n\n## 创建 HTTP / Console 内核 - 各种配置和中间件\nHTTP内核 继承自Illuminate\\Foundation\\Http\\Kernel类，该类定义了一个bootstrappers数组，该数组中的类在请求被执行前运行，bootstrappers配置了错误处理、日志、检测应用环境、其他在请求被处理前需要处理的任务。\n\n## 载入服务提供者到容器- config/app.php的providers数组\n内核启动会为应用载入服务提供者，服务提供者都被配置在config/app.php配置文件的providers数组中。服务提供者被注册后，boot方法被调用。\n服务提供者负责启动框架的所有组件，如数据库、队列、验证器、路由组件等。因他们启动并配置框架提供的所有特性，服务提供者是整个Laravel启动过程中最重要部分。\n\n## 分发请求\n一旦应用被启动且所有服务提供者被注册，Request将会被交给路由器进行分发，路由器将会分发请求到路由或控制器，同时运行所有路由指定的中间件。\n\n## 发送响应和结束\nLaravel的设计模式\n依赖注入。如User 控制器依赖 UserModel，实例化的时候，直接注入。\n服务容器通过依赖注入，实现灵活的高度解耦\n门面：在服务提供者上面再封装一层静态调用，提供一个静态类调用容器中的绑定对象作用。\n\n\n', '2019-06-03 11:02:28', '2021-10-27 11:03:59', 1),
(9, 'php-设计模式之代理模式', '# 代理模式\n\n## 描述\n\n为其他对象提供一种代理以控制对这个对象的访问，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。\n\n## 优点\n\n- 职责清晰\n- 高扩展性\n- 智能化。\n\n## 缺点\n\n- 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢\n- 实现代理模式需要额外的工作，有些代理模式的实现非常复杂\n\n\n\n## 注意事项 \n\n- 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口\n- 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。\n\n```php\nabstract class Subject { // 抽象主题角色\n    abstract public function action();\n}\nclass RealSubject extends Subject { // 真实主题角色\n    public function __construct() {}\n    public function action() {\n        echo \'真实 action\';\n    }\n}\nclass ProxySubject extends Subject { // 代理主题角色\n    private $_real_subject = NULL;\n    public function __construct() {}\n    public function action() {\n        $this->_beforeAction();\n        if (is_null($this->_real_subject)) {\n            $this->_real_subject = new RealSubject();\n        }\n        $this->_real_subject->action();\n        $this->_afterAction();\n    }\n    private function _beforeAction() {\n        echo \'在action前,我想干点啥....\';\n    }\n    private function _afterAction() {\n        echo \'在action后,我还想干点啥....\';\n    }\n}\n// client\n$subject = new ProxySubject();\n$subject->action();\n\n```\n', '2020-02-12 11:07:12', '2021-10-27 11:08:09', 1),
(10, 'php-设计模式之单例模式', '# 单例模式\n## 特点\n- 单例类只能有一个实例\n- 单例类必须自己创建自己的唯一实例\n- 单例类必须给所有其他对象提供这一实例\n- 避免大量的new操作（new 对象都会消耗内存）\n\n## 场景：\n- 数据库连接 \n- 日志 (多种不同用途的日志也可能会成为多例模式)\n- 在应用中锁定文件 (系统中只存在一个 ...)\n- 线程池\n## 种类\n懒汉式单例、饿汉式单例、登记式单例\n\n```php\nclass Singleton\n{\n    /**\n    * 一个私有静态变量\n    * @var Singleton\n    */\n    private static $instance;\n\n    /**\n    * 通过懒加载获得实例（在第一次使用的时候创建）返回唯一实例的一个引用 \n    */\n    public static function getInstance(): Singleton\n    {\n        if (null === static::$instance) {\n            static::$instance = new static();\n        }\n        return static::$instance;\n    }\n\n    /**\n    * 不允许从外部调用以防止创建多个实例\n    * 要使用单例，必须通过 Singleton::getInstance() 方法获取实例\n    */\n    private function __construct()\n    {\n    }\n\n    /**\n    * 防止实例被克隆（这会创建实例的副本）\n    */\n    private function __clone()\n    {\n    }\n\n    /**\n    * 防止反序列化（这将创建它的副本）\n    */\n    private function __wakeup()\n    {\n    }\n    public static helloWord(){\n        return \"helloWord\";\n    }\n}\n\n//只能静态方式取得实例，不能new 和 clone\n$test = Singleton::getInstance()->helloWord();\nvar_dump($test);\n```', '2021-10-27 11:08:37', NULL, 1),
(11, 'php-设计模式之工厂模式(工厂方法)', '\n# 工厂方法模式\n\n## 描述\n\n工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。\n在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，\n即通过工厂子类来确定究竟应该实例化哪一个具体产品类。\n\n\n## 特点\n\n- 在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。\n- 基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够使工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，\n  是因为所有的具体工厂类都具有同一抽象父类。\n- 使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了。这样，\n  系统的可扩展性也就变得非常好，完全符合“开闭原则”。\n\n## 缺点\n\n- 在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。\n- 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。\n\n## 场景\n\n- 一个类不知道它所需要的对象的类：在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建；客户端需要知道创建具体产品的工厂类。\n- 一个类通过其子类来指定创建哪个对象：在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，\n  子类对象将覆盖父类对象，从而使得系统更容易扩展。\n- 将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。\n\n## 角色\n\n- Product：抽象产品\n- ConcreteProduct：具体产品\n- Factory：抽象工厂\n- ConcreteFactory：具体工厂\n\n```php\n\n//抽象产品\nclass Button\n{\n    public function get (){\n        echo \'具体产品\';\n    }\n}\n//具体产品\nclass WinButton extends Button\n{\n\n}\n\n//具体产品\nclass MacButton extends Button\n{\n}\n\n//抽象工厂\ninterface ButtonFactory\n{\n    public function createButton($type);\n}\n\n//具体工厂\nclass MyButtonFactory implements ButtonFactory\n{\n    // 实现工厂方法\n    public function createButton($type)\n    {\n        switch ($type) {\n            case \'Mac\':\n                return new MacButton();\n            case \'Win\':\n                return new WinButton();\n        }\n    }\n}\n\n$button_obj = new MyButtonFactory();\nvar_dump($button_obj->createButton(\'Mac\')->get());\nvar_dump($button_obj->createButton(\'Win\')->get());\n\n```\n\n', '2020-02-15 11:09:51', '2021-10-27 11:10:10', 1),
(12, 'php-设计模式之工厂模式(抽象工厂)', '\n#  抽象工厂模式\n\n## 描述\n\n提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，属于对象创建型模式。\n\n\n## 特点\n\n- 在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，\n  无须关心创建细节，甚至无须知道具体产品类的类名。\n- 基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够使工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。\n  工厂方法模式之所以又被称为多态工厂模式，是因为所有的具体工厂类都具有同一抽象父类。\n- 使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，\n  而只要添加一个具体工厂和具体产品就可以了。这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。\n\n## 缺点\n\n- 在添加新的产品对象时，难以扩展抽象工厂来生产新种类的产品，这是因为在抽象工厂角色中规定了所有可能被创建的产品集合，要支持新种类的产品就意味着要对该接口进行扩展，而这将涉及到对抽象工厂角色及其所有子类的修改，显然会带来较大的不便。\n- 开闭原则的倾斜性（增加新的工厂和产品族容易，增加新的产品等级结构麻烦）\n\n## 场景\n\n- 个系统不应当依赖于产品类实例如何被创建、组合和表达的细节，这对于所有类型的工厂模式都是重要的。\n- 系统中有多于一个的产品族，而每次只使用其中某一产品族。\n- 属于同一个产品族的产品将在一起使用，这一约束必须在系统的设计中体现出来。\n- 系统提供一个产品类的库，所有的产品以同样的接口出现，从而使客户端不依赖于具体实现。\n\n## 角色\n\n- AbstractFactory：抽象工厂\n- ConcreteFactory：具体工厂\n- AbstractProduct：抽象产品\n- Product：具体产品\n\n```php\n//抽象产品\nclass Button{}\n//抽象产品\nclass Border{}\n\n//具体产品\nclass MacButton extends Button{}\n//具体产品\nclass WinButton extends Button{}\n//具体产品\nclass MacBorder extends Border{}\n//具体产品\nclass WinBorder extends Border{}\n\n//抽象工厂\ninterface AbstractFactory {\n    public function CreateButton();\n    public function CreateBorder();\n}\n//具体工厂\nclass MacFactory implements AbstractFactory{\n    public function CreateButton(){ return new MacButton(); }\n    public function CreateBorder(){ return new MacBorder(); }\n}\n//具体工厂\nclass WinFactory implements AbstractFactory{\n    public function CreateButton(){ return new WinButton(); }\n    public function CreateBorder(){ return new WinBorder(); }\n}\n\n```\n\n', '2020-05-05 11:11:08', '2021-10-27 11:11:22', 1);
INSERT INTO `blog_article` (`id`, `title`, `content`, `create_time`, `update_time`, `status`) VALUES
(13, 'php-设计模式之工厂模式(简单工厂)', '# 工厂模式\n\n- 简单工厂模式\n\n- 工厂方法模式\n\n- 抽象工厂模式\n\n  \n\n## 特征\n\n- 提供了一种创建对象的最佳方式\n- 创建对象时不会对客户端暴露创建逻辑\n- 通过使用一个共同的接口来指向新创建的对象\n\n## 解决\n\n- 接口选择的问题\n- 明确地计划不同条件下创建不同实例时\n- 让其子类实现工厂接口，返回的也是一个抽象的产品\n\n## 优点\n\n- 调用者想创建一个对象，只要知道其名称就可以了\n- 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以\n- 屏蔽产品的具体实现\n- 调用者只关心产品的接口\n\n## 缺点\n\n- 每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加\n- 增加了系统的复杂度\n- 增加了系统具体类的依赖\n\n## 场景\n\n- 日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等\n- 数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时\n- 需要三个协议，\"POP3\"、\"IMAP\"、\"HTTP\"，可以把这三个作为产品类，共同实现一个接口\n\n\n\n## 简单工厂模式\n\n### 描述\n\n又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类\n\n### 特点\n\n- 将对象的创建 和 对象本身业务处理 分离 可以降低系统的耦合度\n- 在调用工厂类的工厂方法时，由于工厂方法是静态方法，使用起来很方便，可通过类名直接调用，而且只需要传入一个简单的参数即可，在实际开发中，还可以在调用时将所传入的参数保存在XML等格式的配置文件中，修改参数时无须修改任何源代码。\n- 简单工厂模式最大的问题在于工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，这一点与开闭原则是相违背的。\n- 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节。\n\n### 缺点\n\n- 于工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。\n- 使用简单工厂模式将会增加系统中类的个数，在一定程序上增加了系统的复杂度和理解难度。\n- 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。\n- 简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。\n\n### 使用场景\n\n- 工厂类负责创建的对象比较少：由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。\n- 客户端只知道传入工厂类的参数，对于如何创建对象不关心：客户端既不需要关心创建细节，甚至连类名都不需要记住，只需要知道类型所对应的参数。\n\n### 角色\n\n- - Factory：工厂角色\n\n    工厂角色负责实现创建所有实例的内部逻辑\n\n- - Product：抽象产品角色\n\n    抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口\n\n- - ConcreteProduct：具体产品角色\n\n    具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。\n\n```php\n//具体产品角色\nclass web\n{\n    public function create()\n    {\n        echo \"web\";\n    }\n}\n//具体产品角色\n\nclass app\n{\n    public function create()\n    {\n        echo \"app\";\n    }\n\n}\n\n//工厂角色\nclass factory\n{\n    //抽象产品角色\n    public function ConcreteProduct($key)\n    {\n        if ($key == \'air\') {\n            return new web();\n        }\n        if ($key == \'app\') {\n            return new app();\n        }\n    }\n}\n$factory = new factory();\n$app = $factory->ConcreteProduct(\'app\');\n$app->create();\n```\n\n', '2020-03-13 11:12:02', '2021-10-27 11:12:18', 1),
(14, '	 php-设计模式之策略模式', '# 策略模式\n\n## 定义\n\n定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式(Policy)\n\n## 特点\n\n- 在有多种算法相似的情况下，使用 if...else 所带来的复杂和难以维护。\n- 利用面向对象的继承和多态机制，将多个算法解耦。避免类中出现太多的if-else语句\n- 通过不同的环境选择不同的策略，达到一样的目的（多种方式实现同一个目的）\n- 分离「策略」并使他们之间能互相快速切换，实现继承替代方案\n\n```php\n<?php\n/**\n* 策略模式\n* 定义一系列的算法,把每一个算法封装起来, 并且使它们可相互替换。本模式使得算法可独立于使用它的客户而变化\n*/ \n/**\n*  抽象策略角色，以接口实现\n* 出行旅游\n*/\ninterface TravelStrategy{\n public function travelAlgorithm();\n} \n\n/**\n * 具体策略类(ConcreteStrategy)1：乘坐飞机\n */\nclass AirPlanelStrategy implements TravelStrategy {\n public function travelAlgorithm(){\n echo \"travel by AirPlain\", \"<BR \\r\\n\"; \n }\n} \n/**\n * 具体策略类(ConcreteStrategy)2：乘坐火车\n */\nclass TrainStrategy implements TravelStrategy {\n public function travelAlgorithm(){\n echo \"travel by Train\", \"<BR \\r\\n\"; \n }\n} \n/**\n * 具体策略类(ConcreteStrategy)3：骑自行车\n */\nclass BicycleStrategy implements TravelStrategy {\n public function travelAlgorithm(){\n echo \"travel by Bicycle\", \"<BR \\r\\n\"; \n }\n} \n/**\n * 环境角色\n * 环境类(Context):用一个ConcreteStrategy对象来配置。维护一个对Strategy对象的引用。可定义一个接口来让Strategy访问它的数据。\n * 算法解决类，以提供客户选择使用何种解决方案：\n */\nclass PersonContext{\n private $_strategy = null;\n \n public function __construct(TravelStrategy $travel){\n $this->_strategy = $travel;\n }\n /**\n * 旅行\n */\n public function setTravelStrategy(TravelStrategy $travel){\n $this->_strategy = $travel;\n }\n /**\n * 旅行\n */\n public function travel(){\n return $this->_strategy->travelAlgorithm();\n }\n} \n\n// 第一种方式-乘坐火车旅行\n$person = new PersonContext(new TrainStrategy());\n$person->travel();\n// 第二种方式-改骑自行车\n$person->setTravelStrategy(new BicycleStrategy());\n$person->travel();\n\n```\n\n', '2020-03-18 11:13:16', '2021-10-27 11:13:28', 1),
(15, 'php-设计模式之装饰器模式', '# 装饰器模式\n\n## 特征\n\n- 装饰器模式（Eecorator），可以动态地添加修改类的功能且又不改变其结构\n- 一个类提供了一项功能，如果要在修改并添加额外的功能，传统的编程模式，需要写一个子类继承它，并重新实现类的方法．\n- 使用装饰器模式，进需在运行时添加一个装饰器对象即可实现，可以实现最大的灵活性\n\n## 逻辑\n\n- Component 类充当抽象角色，不应该具体实现\n-  修饰类引用和继承 Component 类，具体扩展类重写父类方法\n\n## 优点\n\n- 装饰类和被装饰类可以独立发展，不会相互耦合\n\n- 装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能\n\n## 缺点 \n\n- 多层装饰比较复杂\n\n## 场景\n\n- 扩展一个类的功能\n- 动态增加功能，动态撤销\n\n```php\n/**\n * 创建渲染接口。\n * 这里的装饰方法 renderData() 返回的是字符串格式数据。\n */\ninterface RenderableInterface\n{\n    public function renderData(): string;\n}\n\n/**\n * 创建 Webservice 服务类实现 RenderableInterface。\n * 该类将在后面为装饰者实现数据的输入。\n */\nclass WebService implements RenderableInterface\n{\n    private $data;\n    public function __construct(string $data)\n    {\n        $this->data = $data;\n    }\n\n    /**\n     * 实现 RenderableInterface 渲染接口中的 renderData() 方法。 返回传入的数据。\n     */\n    public function renderData(): string\n    {\n        return $this->data;\n    }\n}\n\n/**\n * 装饰者 必须实现渲染接口类 RenderableInterface 契约，这是该设计模式的关键点。否则，这将不是一个装饰者而只是一个自欺欺人的包装。\n * 创建抽象类 RendererDecorator （渲染器装饰者）实现渲染接口。\n */\nabstract class RendererDecorator implements RenderableInterface\n{\n    /**\n     * @var RenderableInterface\n     * 定义渲染接口变量。\n     */\n    protected $wrapped;\n\n    /**\n     * @param RenderableInterface $renderer\n     * 传入渲染接口类对象 $renderer。\n     */\n    public function __construct(RenderableInterface $renderer)\n    {\n        $this->wrapped = $renderer;\n    }\n}\n\n/**\n * 创建 Xml 修饰者 并继承抽象类 RendererDecorator 。\n */\nclass XmlRenderer extends RendererDecorator\n{\n    /**\n     * 对传入的渲染接口对象进行处理，生成 DOM 数据文件。\n     */\n    public function renderData(): string\n    {\n        $doc = new \\DOMDocument();\n        $data = $this->wrapped->renderData();\n        $doc->appendChild($doc->createElement(\'content\', $data));\n\n        return $doc->saveXML();\n    }\n}\n\n/**\n * 创建 Json 修饰者 并继承抽象类 RendererDecorator 。\n */\nclass JsonRenderer extends RendererDecorator\n{\n    /**\n     * 对传入的渲染接口对象进行处理，生成 JSON 数据。\n     */\n    public function renderData(): string\n    {\n        return json_encode($this->wrapped->renderData());\n    }\n}\n\n$webService = new WebService(\"test string\");\n\n$xmlRender = new XmlRenderer($webService);\nvar_dump($xmlRender->renderData()); \n\n//输出 json 数据\n$jsonRender = new JsonRenderer($webService);\nvar_dump($jsonRender->renderData());\n```\n', '2020-03-19 11:14:01', '2021-10-27 11:15:36', 1),
(16, 'php-设计模式之观察者模式', '# 观察者模式\n\n观察者模式（又称为发布-订阅（Publish/Subscribe）模式\n\n## 特点\n\n- 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。\n- 一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知\n\n## 使用场景\n\n- 个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度\n- 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。\n- 一个对象必须通知其他对象，而并不知道这些对象是谁。\n\n```php\n\n//抽象被观察者\nabstract class Subject\n{\n    //观察者数组\n    private $observers;\n\n    //增加观察者方法\n    public function addObserver(Observer $observer)\n    {\n        $this->observers[] = $observer;\n        echo \"add ob succ\" . PHP_EOL;\n    }\n\n    //通知所有观察者\n    public function sendMsg()\n    {\n        foreach($this->observers as $observer){\n            $observer->update();\n        }\n    }\n}\n\n//具体被观察者\nclass Server extends Subject\n{\n    public function send()\n    {\n        $this->sendMsg();\n    }\n}\n\n//抽象观察者接口\ninterface Observer\n{\n    public function update();\n}\n\n//具体观察者\nclass Web implements Observer\n{\n    public function update()\n    {\n        echo \'web  is  get\';\n    }\n}\n\nclass App implements Observer\n{\n    public function update()\n    {\n        echo \'App  is  get\';\n    }\n}\n\n//实例化被观察者\n$server = new Server();\n//实例化观察者\n$web = new Web();\n$app = new App();\n//添加被观察者\n$server->addObserver($web);\n$server->addObserver($app);\n\n//被观察者发布消息\n$server->send();\n\n//观察者将会受到消息\n\n```\n\n', '2020-07-16 11:14:29', '2021-10-27 11:15:19', 1),
(17, 'php-设计模式之适配器模式', '# 适配器模式\n\n## 特点\n\n- 可以让任何两个没有关联的类一起运行\n- 提高了类的复用\n- 增加了类的透明度\n- 将目标类和适配者类解耦，解决了目标类和适配者类接口不一致的问题\n\n\n## 缺点\n\n- 过多地使用适配器，会让系统非常零乱，不易整体进行把握\n- 增加代码阅读难度，降低代码可读性，过多使用适配器会使系统代码变得凌乱\n- 适配器编写过程需要结合业务场景全面考虑，可能会增加系统的复杂性\n\n\n\n```php\n<?php\n//对象适配器\ninterface Target {\n    public function sampleMethod1();\n    public function sampleMethod2();\n}\n\nclass Adaptee {\n    public function sampleMethod1() {\n        echo \'#######\';\n    }\n}\n\nclass Adapter implements Target {\n    private $_adaptee;\n    public function __construct(Adaptee $adaptee) {\n        $this->_adaptee = $adaptee;\n    }\n\n    public function sampleMethod1() {\n        $this->_adaptee->sampleMethod1(); \n    }\n\n    public function sampleMethod2() {\n        echo \'!!!!!!!!\';\n    }\n}\n\n$adapter = new Adapter(new Adaptee());\n$adapter->sampleMethod1();\n$adapter->sampleMethod2();\n\n//类适配器\ninterface Target2 {\n    public function sampleMethod1();\n    public function sampleMethod2();\n}\n\nclass Adaptee2 { // 源角色\n    public function sampleMethod1() {}\n}\n\nclass Adapter2 extends Adaptee2 implements Target2 { // 适配后角色\n    public function sampleMethod2() {} \n}\n$adapter = new Adapter2();\n$adapter->sampleMethod1();\n$adapter->sampleMethod2();\n```\n\n', '2020-02-06 11:16:08', '2021-10-27 11:16:23', 1),
(18, '数据结构和算法基础介绍', '### 什么是数据结构和算法\n\n- 广义上，数据结构就是一组数据的存储结构，算法就是操作数据结构的一种方法。\n- 程序 = 数据结构 + 算法\n- 结构是数据元素之间不是独立的，存在特定的关系，数据结构指的是数据对象中数据元素之间的关系。\n\n### 算法的概念\n- 算法是计算机处理信息的本质，用过算法来告诉计算机如何执行程序。\n- 算法是一种解决问题的方法和思想\n\n### 算法的5大特性\n输入、输出、有穷性、确定性、可行性\n### 时间复杂度\n- 分析执行的算法中，算法完成工作需要多少基本的操作。完成最少的操作，是最优时间复杂度\n- 完成最多的操作，是最坏时间复杂度\n- 平均的操作，是平均时间复杂度\n### 常见的时间复杂度\n从低阶到高阶：常数阶O(1)、对数阶O(logn)、线性阶O(n)、nlogn阶O(nlogn)、指数阶O(n**2)\n![img](https://img-blog.csdnimg.cn/20210224182037589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTU2ODM5MQ==,size_16,color_FFFFFF,t_70)\n### 常见的数据结构\n#### 数组\n数组是可以再内存中连续存储多个元素的结构，在内存中的分配也是连续的，数组中的元素通过数组下标进行访问，数组下标从0开始。例如下面这段代码就是将数组的第一个元素赋值为 1。\n```\nint[] data = new int[100]；\ndata[0]  = 1;\n```\n优点：\n- 按照索引查询元素速度快\n- 按照索引遍历数组方便\n缺点：\n- 数组的大小固定后就无法扩容了\n- 数组只能存储一种类型的数据\n- 添加，删除的操作慢，因为要移动其他的元素。\n#### 栈\n栈是一种特殊的线性表，仅能在线性表的一端操作，栈顶允许操作，栈底不允许操作。\n\n栈的特点是：先进后出，或者说是后进先出，从栈顶放入元素的操作叫入栈，取出元素叫出栈。\n\n越先放进去的东西越晚才能拿出来，所以，栈常应用于实现递归功能方面的场景，例如斐波那契数列。\n\n#### 队列\n队列与栈一样，也是一种线性表，不同的是，队列可以在一端添加元素，在另一端取出元素，也就是：先进先出。从一端放入元素的操作称为入队，取出元素为出队。\n\n使用场景：\n\n因为队列先进先出的特点，在多线程阻塞队列管理中非常适用。\n\n#### 链表\n\n链表是物理存储单元上非连续的、非顺序的存储结构，数据元素的逻辑顺序是通过链表的指针地址实现，每个元素包含两个结点，一个是存储元素的数据域 (内存空间)，另一个是指向下一个结点地址的指针域。根据指针的指向，链表能形成不同的结构，例如单链表，双向链表，循环链表等。\n\n链表的优点：\n- 链表是很常用的一种数据结构，不需要初始化容量，可以任意加减元素；\n- 添加或者删除元素时只需要改变前后两个元素结点的指针域指向地址即可，所以添加，删除很快；\n缺点：\n- 因为含有大量的指针域，占用空间较大；\n- 查找元素需要遍历链表来查找，非常耗时。\n#### 树\n树是一种数据结构，它是由n（n>=1）个有限节点组成一个具有层次关系的集合。把它叫做 “树” 是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的，它具有以下的特点：\n- 每个节点有零个或多个子节点；\n- 没有父节点的节点称为根节点；\n- 每一个非根节点有且只有一个父节点；\n- 除了根节点外，每个子节点可以分为多个不相交的子树；\n\n##### 常用实例：二叉树\n二叉树是树的特殊一种，具有如下特点：\n- 每个结点最多有两颗子树，结点的度最大为2。\n- 左子树和右子树是有顺序的，次序不能颠倒。\n- 即使某结点只有一个子树，也要区分左右子树。\n\n二叉树是一种比较有用的折中方案，它添加，删除元素都很快，并且在查找方面也有很多的算法优化，所以，二叉树既有链表的好处，也有数组的好处，是两者的优化方案，在处理大批量的动态数据方面非常有用。\n\n##### \n二叉树有很多扩展的数据结构，包括平衡二叉树、红黑树、B+树等，这些数据结构二叉树的基础上衍生了很多的功能，在实际应用中广泛用到，例如mysql的数据库索引结构用的就是B+树，还有HashMap的底层源码中用到了红黑树。等等。\n\n#### 散列表\n散列表，也叫哈希表，是根据关键码和值 (key和value) 直接进行访问的数据结构，通过key和value来映射到集合中的一个位置，这样就可以很快找到集合中的对应元素。\n\n##### 记录的存储位置=f(key)\n\n这里的对应关系 f 成为散列函数，又称为哈希 (hash函数)，而散列表就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里，这种存储空间可以充分利用数组的查找优势来查找元素，所以查找的速度很快。\n\n#### 堆\n堆是一种比较特殊的数据结构，可以被看做一棵树的数组对象，具有以下的性质：\n- 堆中某个节点的值总是不大于或不小于其父节点的值；\n- 堆总是一棵完全二叉树。\n\n#### 图\n### 常用数据结构比对\n|  数据结构	   | 优点  | 缺点   |\n|  ----  | ----  | ---  |\n| 数组	|  插入快| 查找,删除慢,大小固定,只能存储单一元素 |\n|有序数组| 比无序数组查询快| 插入慢,删除慢,大小固定,只能存储单一元素 |\n|栈     |  提供后进先出的存储方式 | 存储其它项很慢  |\n|队列	|  提供先进先出的存储方式 | 存储其它项很慢 |\n|链表    |	插入块，删除快 |	查找慢  |\n|二叉树  |  如果树是平衡的,则查找,插入,删除都快 |	删除算法复杂 |\n|红黑数  |	  查找,删除,插入都快,树总是平衡的 |算法复杂 |\n|2-3-4树 |  查找,删除,插入都快,树总是平衡的 | 算法复杂 |\n|哈希表  |	如果关键字已知则存储极快 | 删除慢,如果不知道关键字存储慢,对存储空间使用不充分 |\n|堆	|插入,删除块,对最大数据项存储快 |	对其它数据项存储慢 |\n|图	|对现实世界建模|	有些算法慢且复杂 |\n', '2021-10-27 16:12:31', NULL, 1),
(19, 'Linux 定时任务 Crontab', '## contabl 常用参数\n```\ncrontab\n    -e      (编辑工作表)\n    -l      (列出工作表里的命令)\n```\n\ncrontab的命令构成为： 时间+动作，其时间有分、时、日、月、周五种，操作符有：\n```\n* 取值范围内的所有数字\n/ 每过多少个数字\n- 从X到Z\n，散列数字\n```\n\n## 常用例子\n\n```\n30 21 * * * command  //每晚9:30执行 command\n0 23 * * 6 command //每星期六的晚上11:00 执行command\n```\n', '2020-05-06 16:59:49', '2021-10-28 17:10:44', 1),
(20, 'Php-算法-插入排序', '# 插入排序\n\n## 原理\n\n通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。**插入排序**在实现上，\n通常采用in-place排序（即只需用到 O(1) 的额外空间的排序），因而在从后向前扫描过程中，\n需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。\n\n## 步骤\n\n- 从第一个元素开始，该元素可以认为已经被排序\n- 取出下一个元素，在已经排序的元素序列中从后向前扫描\n- 如果该元素（已排序）大于新元素，将该元素移到下一位置\n- 重复步骤3，直到找到已排序的元素小于或者等于新元素的位置\n- 将新元素插入到该位置后\n\n```\n$a = [ 9, 2, 3, 4,1, 5, 8,9];\nfunction insertSort($arr)\n{\n    $count = count($arr);\n    if ($count < 2) {\n        return $arr;\n    }\n    for ($i = 1; $i < $count; $i++) {\n        $temp = $arr[$i];\n        for ($k = $i - 1; $k >= 0; $k--) {\n            if ($temp< $arr[$k]) {\n                $arr[$k + 1] = $arr[$k];\n                $arr[$k] = $temp;\n            }\n        }\n    }\n    return $arr;\n}\nprint_r(insertSort($a));\n\n/**每次变化\nstring(15) \"2,9,3,4,1,5,8,9\"\nstring(15) \"2,3,9,4,1,5,8,9\"\nstring(15) \"2,3,4,9,1,5,8,9\"\nstring(15) \"1,2,3,4,9,5,8,9\"\nstring(15) \"1,2,3,4,5,9,8,9\"\nstring(15) \"1,2,3,4,5,8,9,9\"\nstring(15) \"1,2,3,4,5,8,9,9\"\n*/\n```\n\n', '2021-10-29 15:58:44', NULL, 1),
(21, 'Php-算法-二分查找', '# 二分查找（while方式+递归方式）\n\n## 特点\n\n- 半搜索、对数搜索，是一种在**有序数组**中查找某一特定元素的搜索算法。\n\n\n\n## 逻辑\n\n从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜索过程结束；如果某一特定元素大于或者小于中间元素，\n则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组为空，则代表找不到。\n这种搜索算法每一次比较都使搜索范围缩小一半。\n\n- 确定要查找的区间\n\n- 确定要二分时的参照点\n\n- 区间内选取二分点\n\n- 根据二分点的值，综合左右区间情况以及求解的目的，舍去一半无用的区间\n\n- 继续在有效区间重复上面的步骤\n\n## 时间复杂度\n\nO(logn)\n\n\n\n```php\n\n/**\n * 二分查找法-while方式\n * @param $arr\n * @param $search\n * @return string\n */\nfunction BinSearchByWhile($arr,$search): string\n{\n    $height=count($arr)-1;\n    $low=0;\n    while($low<=$height){\n        $mid=intval(($low+$height)/2);//获取中间数\n        if($arr[$mid]==$search){\n            return $mid.\":succ\";//返回\n        }elseif($arr[$mid]<$search){\n            // 去右边查\n            $low=$mid+1;\n        }elseif($arr[$mid]>$search){\n            // 去右边查\n            $height=$mid-1;\n        }\n    }\n    return \'fail\';\n}\n\n/**\n * 二分查找法-递归方式\n * @param $arr\n * @param $number\n * @param $lower\n * @param $high\n * @return int\n */\nfunction BinarySearchByRecursion($arr, $number, $lower, $high): int\n{\n    // 中间点\n    $middle = intval(($lower + $high) / 2);\n    // 最低点比最高点大就退出\n    if ($lower > $high) {\n        return -1;\n    }\n    if ($number > $arr[$middle]) {\n        // 去左边查\n        return BinarySearchByRecursion($arr, $number, $middle + 1, $high);\n    } elseif ($number < $arr[$middle]) {\n        // 去右边查\n        return BinarySearchByRecursion($arr, $number, $lower, $middle - 1);\n    } else {\n        return $middle;\n    }\n}\n$a = [  2, 3, 4,4, 5, 8,9];\nvar_dump( BinarySearchByRecursion($a,5,0, count($a)));\n\n```\n\n', '2021-10-29 15:59:21', '2021-10-29 16:00:10', 1),
(22, 'Php-算法-冒泡排序', '# 冒泡排序\n\n冒泡排序大概的意思是依次比较相邻的两个数，然后根据大小做出排序，直至最后两位数 由于在排序过程中总是小数往前放，\n大数往后放，相当于气泡往上升，所以称作冒泡排序 涉及非相邻元素的位置交换，所以是不稳定的排序算法\n冒泡是从前往后冒，所以，每轮比较的次数也是逐渐减少的，最后一个数不用比较，其时间复杂度为O(n²)\n算法如下：\n\n```php\n<?php\n/**\n * @param array $arr\n * @return array\n */\nfunction sortM(array $arr): array\n{\n    // 判断参数是否为数组，且不为空\n    if (!is_array($arr) || empty($arr)) {\n        return $arr;\n    }\n    $len = count($arr) -1;\n    // 循环需要冒泡的轮数\n    for ($i = 0; $i < $len; $i++) {\n         $mark = true;//此处是一个优化点：当$i < $len 时，已经排完序了，直接结束\n        // 循环每轮需要比较的次数\n        for ($j = 0; $j < $len - $i; $j++) {\n            // 大的数，交换位置，往后挪\n            if ($arr[$j] > $arr[$j + 1]) {\n                list($arr[$j],$arr[$j + 1]) = [$arr[$j + 1],$arr[$j]];\n                $mark= false;\n            }\n        }\n        if ($mark){\n            return $arr;\n        }\n    }\n    return $arr;\n}\nvar_dump(implode(\"<\",sortM([1,-3,4,5,2,6,0])));\n```\n', '2021-10-29 16:00:00', NULL, 1),
(23, 'Php-算法-选择排序', '# 选择排序\n\n首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置\n然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾\n以此类推，直到所有元素均排序完毕。\n\n- 时间复杂度： O(n^2) （n的平方）\n- 空间复杂度：原地排序算法\n- 算法稳定性：涉及非相邻元素的位置交换，所以是不稳定的排序算法\n\n```php\n<?php\n/**\n * @param array $arr\n * @return array\n */\nfunction SelectSort(array $arr): array\n{\n    $len = count($arr);\n    if ($len <= 1) {\n        return $arr;\n    }\n    //控制最大循环次数,未排序区的第一个值\n    for ($i = 0; $i < $len; $i++) {\n        //假设最小的数的为未排序区的第一个数\n        $min = $i;\n        //拿未排序区的每一个值与最小数比较，总是记录最小的数，这样就可以找到未排序区的最小值\n        for ($j = $i + 1; $j < $len; $j++) {\n            if ($arr[$j] < $arr[$min]) {\n                $min = $j;\n            }\n        }\n        //把未排序区的最小值与未排序区第一个数交换位置，也就是把未排序区中的最小值放到已排序区的后面\n        if ($min != $i) {\n            list($arr[$i], $arr[$min]) = [$arr[$min], $arr[$i]];\n        }\n    }\n    return $arr;\n}\n\nvar_dump(implode(\"<\",SelectSort([1,-3,4,5,2,6,0])));\n```\n\n', '2021-10-29 16:00:32', NULL, 1),
(24, 'Redis-穿透、击穿、雪崩理解以及解决方案', '# 穿透、击穿、雪崩理解以及解决方案\n\n## 缓存穿透\n\n### 描述\n\n是指查询一个数据库**一定不存在**的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，\n并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。\n\n### 击穿场景\n\n查询数据库**id=-1**的数据，就是查询一定不存在的对象，就会每次都去查询数据库，而每次查询都是空，每次又都不会进行缓存。假如有恶意攻击，\n就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。即便是采用UUID，也是很容易找到一个不存在的KEY，进行攻击。\n\n### 解决方案\n\n- 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截\n- 采用缓存空值的方式，从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，只是设定缓存有效时间可以设置短点，\n  如60秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击\n- 布隆过滤器是一种数据结构，更准确的说是一种概率型的数据结构，因为它能判断某个元素一定不存在或者是可能存在\n  过布隆过滤器来快速的判断出一个key是否存在数据库中，如果可能存在再去数据库查询，如果布隆过滤器中不存在那么就需要再去数据库查询了\n- 预热\n  所谓缓存预热就是将一些可能经常使用数据在系统启动的时候预先设置到缓存中，这样可以避免在使用到的时候先去数据库中查询\n- 降级  \n  降级的最终目的是保证核心服务可用，即使是有损的。但是有的一些业务的核心服务是不能降级的。这是一种丢卒保帅的思想\n  \n## 缓存击穿\n\n### 描述\n\n指**一个key非常热点**，在不停的扛着大并发，某一时刻段（大并发）**集中对这一个key**进行访问，当这个key在**失效的瞬间**，持续的大并发就穿破缓存，\n直接请求数据库，就像在一个屏障上凿开了一个洞。\n可以理解为**缓存中没有**但**数据库中有的数据**（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，\n引起数据库压力瞬间增大，造成过大压力。\n\n### 解决方案\n\n- 设置热点数据永远不过期\n- 加互斥锁\n  为什么要用互斥锁的方式？如果不使用互斥锁的方式很容易导致数据不一致的情况，这里为了保证缓存和数据库的一致性，就只能牺牲一点点的效率了\n\n## 缓存雪崩\n\n### 描述\n\n指在某**一个时间段**，缓存大**批量的集中过期失效**，而查询数据量巨大都走到了数据库，引起数据库压力过大甚至down机\n\n### 解决方案\n\n- 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生\n- 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中\n- 设置热点数据永远不过期\n', '2021-10-29 16:01:13', '2021-10-29 16:01:27', 1),
(25, 'Redis 布隆过滤器', '# Redis 布隆过滤器\n\n## 描述\n\n一种数据结构，布隆过滤器底层是一个64位的整型,是由一串很长的二进制向量组成，可以将其看成一个二进制数组。\n既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。\n\n### 添加数据\n\n当要向布隆过滤器中添加一个元素key时，通过多个hash函数，算出一个值，然后映射在的将这个值置为1。\n\n![img](https://img2020.cnblogs.com/blog/1120165/202003/1120165-20200330221613591-2062171492.png)\n\n### 判断数据是否存在\n\n只需要将这个新的数据通过上面自定义的几个哈希函数，分别算出各个值，然后看其对应的地方是否都是1，如果存在一个不是1的情况，那么我们可以说，该新数据一定不存在于这个布隆过滤器中\n\n### 优缺点\n\n- 布隆过滤器可以判断某个数据一定不存在，但是无法判断一定存在\n- 二进制组成的数组，占用内存极少，并且插入和查询速度都足够快\n- 随着数据的增加，误判率会增加；还有无法判断数据一定存在\n- 另外还有一个重要缺点，无法删除数据\n\n\n\n### redis 实现 \n\n通过bitmaps类型\n\n\n\n\n\n暂时只有基本介绍，后期发实战\n', '2021-10-29 16:02:07', NULL, 1),
(26, 'Redis 过期策略、淘汰机制', '# redis过期策略、淘汰机制\n\n### 定时删除\n\n指的是设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作；\n\n### 定期删除\n\nredis默认每隔100ms就随机抽取一些设置了过期时间的key， 检测这些key是否过期，如果过期了就将其删掉。\n**为什么会选择一部分，而不是全部**：因为如果这是redis里面有大量的key都设置了过期时间，那么如果全部去检测一遍，CPU负载就会很高，\n会浪费大量的时间在检测上面，甚至直接导致redis挂掉。所有只会抽取一部分而不会全部检查。**出现问题**：这样的话就会出现大量的\n已经过期的key并没有被删除，这就是 **为什么有时候大量的key明明已经过了失效时间，但是redis的内存还是被大量占用的原因** ，为了解决这个问题，\n就需要 **惰性删除** 这个策略了。\n\n### 惰性删除\n\n惰性删除不在是redis去主动删除，而是在你要获取某个key 的时候，redis会先去检测一下这个key是否已经过期，如果没有过期则返回给你，\n如果已经过期了，那么redis会删除这个key，不会返回给你。\n\n这样两种策略就保证了 **过期的key最终一定会被删除掉** ，但是这只是保证了最终一定会被删除，要是定时删除漏掉了大量过期的key，\n而且我们也没有及时的去访问这些key，那么这些key不就不会被删除了吗？不就会一直占着我们的内存吗?这样不还是会导致redis内存耗尽吗？\n\n由于存在这样的问题，所以redis引入了 **内存淘汰机制** 来解决。\n\n### 内存淘汰机制\n\n通过设置参数：maxmemory-policy\n内存淘汰机制就保证了在redis的内存占用过多的时候，去进行内存淘汰，也就是删除一部分key，保证redis的内存占用率不会过高，那么它会删除那些key呢？\n\n- noeviction（不开启）：当内存不足以容纳新写入数据时，新写入操作会报错，无法写入新数据，一般不采用\n- allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key，这个是最常用的\n- allkeys-random：当内存不足以容纳新写入的数据时，在键空间中，随机移除key，一般也不使用\n- allkeys-ttl： 移除即将过期的key(minor TTL)\n- volatile-lru：volatile-lru：当内存不足以容纳新写入数据时，在**设置了过期时间**的键空间中，移除最近最少使用的key（这个一般不太合适） \n- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间**的键空间中，随机移除某个key \n- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间**的键空间中，有更早过期时间的key优先移除\n\n### Redis过期键采用的是定期删除+惰性删除二者结合的方式进行删除的。\n', '2021-10-29 16:02:29', NULL, 1),
(27, 'Redis 基础介绍', '# 基础介绍\n\n- 读写操作不会因为磁盘的 IO 速度限制\n\n- 单线程\n\n  保证了每个操作的原子性，也减少了线程的上下文切换和竞争。\n\n- 基于内存操作\n\n  一般都是简单的存取操作，线程占用的时间很多，时间的花费主要集中在 IO 上，所以读取速度快\n\n- 5 种数据类型：String、List、Hash、Set、SortedSet\n\n  - 整个 Redis 就是一个全局 哈希表，他的时间复杂度是 O(1)，而且为了防止哈希冲突导致链表过长，Redis 会执行 rehash 操作，扩充 哈希桶数量，减少哈希冲突。并且防止一次性 重新映射数据过大导致线程阻塞，采用 渐进式 rehash。巧妙的将一次性拷贝分摊到多次请求过程后总，避免阻塞\n  - 对数据存储进行了优化，如压缩表，对短数据进行压缩存储，再如，跳表，使用有序的数据结构加快读取的速度\n\n-  I/O 多路复用技术，并发处理连接。\n\n  - 采用了 epoll + 自己实现的简单的事件框架。epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，绝不在 IO 上浪费一点时间。\n  - 使用的是非阻塞 IO：IO 多路复用，使用了单线程来轮询描述符，将数据库的开、关、读、写都转换成了事件，Redis 采用自己实现的事件分离器，效率比较高', '2021-10-29 16:02:54', NULL, 1),
(28, 'redis 持久化机制备份数据 AOF 和 RDB', '# redis AOF RDB\n\n## 持久化机制备份数据\n\n### RDB \n\n二进制快照文件\n\n- 文件紧凑\n- 占用空间小\n- 恢复速度比较快\n- 对Redis本身读写性能影响较小（子进程Fork模式）\n\n### AOF \n\n记录了Redis的操作命令，重放请求恢复数据，AOF的文件会比RDB大\n\n流程：\n\n- 将执行命令记录在AOF缓存，之后再写入到磁盘（时间根据参数决定）\n- 三种方式写入\n  - 关闭时\n  - 每秒定期\n  - 执行完命令后立刻\n  \n\n- 丢失的数据比RDB少（按照第三种方式）\n- AOF会影响执行速度，所有一般按照第二种方式写入，对性能影响不大\n\n\n\n### 注意点：\n\n- 当AOF文件过大时，redis会自动在后台Fork一个子进程对AOF进行重写（比如：同一个key的set操作只执行最后的一次）\n- 重写过程中，redis会将新的操作记录在原来的AOF缓冲区和重写缓冲区都记录，当新的AOF创建完成，redis就会将重写缓冲区内容追加到新的AOf文件\n  ，再用新的AOF文件替换原来的AOF文件\n\n', '2021-10-29 16:03:32', NULL, 1),
(29, 'Redis Setbit 用法和场景', '# setbit 用法 \n\n## 官方解释\n\nSETBIT key offset value\n\n设置或者清空key的value(字符串)在offset处的bit值。\n\n那个位置的bit要么被设置，要么被清空，这个由value（只能是0或者1）来决定。\n\n当key不存在的时候，就创建一个新的字符串value。\n\n要确保这个字符串大到在offset处有bit值。\n\n参数offset需要大于等于0，并且小于232(限制bitmap大小为512)。\n\n当key对应的字符串增大的时候，新增的部分bit值都是设置为0。\n\n**注意**\n\n当set最后一个bit(offset等于232-1)并且key还没有一个字符串value或者其value是个比较小的字符串时，Redis需要立即分配所有内存，这有可能会导致服务阻塞一会。在一台2010MacBook Pro上，offset为232-1（分配512MB）需要～300ms，offset为230-1(分配128MB)需要～80ms，offset为228-1（分配32MB）需要～30ms，offset为226-1（分配8MB）需要8ms。注意，一旦第一次内存分配完，后面对同一个key调用[SETBIT](http://www.redis.cn/commands/setbit.html)就不会预先得到内存分配。\n\n返回值\n\n[integer-reply](http://www.redis.cn/topics/protocol.html#integer-reply)：在offset处原来的bit值\n\n### 个人理解\n\n![img](https://easyreadfs.nosdn.127.net/bFxn73tfrlnNzJDOe-0WzA==/8796093023252283210)\n\n- setbit只有两个值0和1，8个位正好是1b，所以位操作是非常节省空间的一种操作\n\n- Redis 中字符串的最大长度是 512M，其最大值是：Max = 8 * 1024 * 1024 * 512  =  2^32\n- offset 最大为Max - 1（原因：C语言中字符串的末尾都要存储一位分隔符）\n\n## 相关命令\n\n```shell\n# 设置值，其中value只能是 0 和 1\nsetbit key offset value\n\n# 获取值\ngetbit key offset\n\n# 获取指定范围内值为 1 的个数\n# start 和 end 以字节为单位\nbitcount key start end\n\n# BitMap间的运算\n# operations 位移操作符，枚举值\n  AND 与运算 &\n  OR 或运算 |\n  XOR 异或 ^\n  NOT 取反 ~\n# result 计算的结果，会存储在该key中\n# key1 … keyn 参与运算的key，可以有多个，空格分割，not运算只能一个key\n# 当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。返回值是保存到 destkey 的字符串的长度（以字节byte为单位），和输入 key 中最长的字符串长度相等。\nbitop [operations] [result] [key1] [keyn…]\n\n# 返回指定key中第一次出现指定value(0/1)的位置\nbitpos [key] [value]\n```\n\n\n\n## 用法案例\n\n- 用户今日是否签到\n- 今日是否打开\n- 是否已经完成某个任务\n- 用户是否在线\n- 等等\n\n## 示例\n\n### 签到场景\n\n- 1亿用户，\n- 今日签到过\n\n- 连续2天签到用户数量\n- 第一天或第二天签到的用户数量\n\n### 实现\n\n```sh\n# 条件: key 为日期\n# 3天日期：date1  date2  date3\n# userId: 123  456  789\n\n# 设置用户123在第1天签到\n>setbit date1 123 1\n\n# 设置用户123在第2天签到\n>setbit date2 123 1\n\n# 设置用户234在第1天签到\n>setbit date1 456 1\n\n# 设置用户234在第2天没有签到\n>setbit date2 456 0\n\n#判断用户123今日是否签到（返回1则签到过，0则没有）\n>getbit date1 456\n\n#获取连续2天签到的用户数量\n>bitop and resd12 date1 date2 #(把统计结果保存到 resd12 的字符串的长度)\n>bitcount resd12#(连续2天签到的用户数量)\n\n#获取第一天或第二天签到的用户数量\n>bitop or resd12 date1 date2 #(把统计结果保存到 resd12 的字符串的长度)\n>bitcount resd12#(连续2天签到的用户数量)\n\n```\n\n\n\n', '2021-10-29 16:04:05', NULL, 1),
(30, 'Linux 通过 Nohup自动重启命令', '#/bin/sh\n\n```\nmypid=$(lsof -i:8816 | awk \'{print $2}\'|sed -n \'2p\');\nkill -9 $mypid;\nchmod 777 mryy_admin_test\nnohup ./mryy_admin_test > nohup.out 2>&1 &\nnewPid=$(lsof -i:8816 | awk \'{print $2}\'|sed -n \'2p\');\necho \"新的pid:\"$newPid;\n```\n', '2020-05-07 16:40:42', '2021-12-16 14:29:51', 1),
(31, 'Golang  学习网站', 'go101\nhttps://gfw.go101.org/article/control-flows-more.html\n\n\nhttps://github.com/unknwon/the-way-to-go_ZH_CN/blob/master/eBook/directory.md\n\n\n\nhttps://chai2010.gitbooks.io/advanced-go-programming-book/content/ch1-basic/ch1-02-hello-revolution.html', '2021-11-11 10:11:25', '2022-01-10 14:25:13', 1),
(32, 'Golang  Channel通道', '## 介绍\n通道是Go中的一种类型\n\n通道是Go中招牌特性之一,和另一个招牌特性协程一起，这两个招牌特性使得使用Go进行并发编程（concurrent programming）变得十分方便和有趣，并且大大降低了并发编程的难度。\n\n通道的主要作用是用来实现并发同步\n\n通过共享内存来通讯和通过通讯来共享内存是并发编程中的两种编程风格。 \n\n当通过共享内存来通讯的时候，我们需要一些传统的并发同步技术（比如互斥锁）来避免数据竞争。\n\nGo提供了一种独特的并发同步技术来实现通过通讯来共享内存。此技术即为通道。 我们可以把一个通道看作是在一个程序内部的一个先进先出（FIFO：first in first out）数据队列。 一些协程可以向此通道发送数据，另外一些协程可以从此通道接收数据。\n\n Go通道可以帮助程序员轻松地避免数据竞争，但不会防止程序员因为犯错而写出错误的并发代码的情况发生。\n\n## 通道类型和值\n\n和数组、切片以及映射类型一样，每个通道类型也有一个元素类型。 一个通道只能传送它的（通道类型的）元素类型的值。\n\n通道可以是双向的，也可以是单向的。\n\n字面形式chan T表示一个元素类型为T的双向通道类型。 编译器允许从此类型的值中接收和向此类型的值中发送数据。\n\n字面形式chan<- T表示一个元素类型为T的单向发送通道类型。 编译器不允许从此类型的值中接收数据。\n\n字面形式<-chan T表示一个元素类型为T的单向接收通道类型。 编译器不允许向此类型的值中发送数据。\n\n双向通道chan T的值可以被隐式转换为单向通道类型chan<- T和<-chan T，但反之不行（即使显式也不行）， 类型chan<- T和<-chan T的值也不能相互转换。\n\n每个通道值有一个容量属性。此属性的意义将在下一节中得到解释。 一个容量为0的通道值称为一个非缓冲通道（unbuffered channel），一个容量不为0的通道值称为一个缓冲通道（buffered channel）。\n\n通道类型的零值也使用预声明的nil来表示。 一个非零通道值必须通过内置的make函数来创建。 比如make(chan int, 10)将创建一个元素类型为int的通道值。 第二个参数指定了欲创建的通道的容量。此第二个实参是可选的，它的默认值为0。', '2021-11-12 16:16:48', '2021-11-12 16:17:10', 2),
(33, '去TMD生活', '我乃农村人,偶做城中客。\n小学读过半卷书，坐井说天阔。\n大志梦功名，现实梦以破。\n待到囊中羞涩时，都是我的错啊。\n欲游山河十万里，伴我共蹉跎。\n囊中空肚子饿，夜无眠又害渴。\n乞讨天下人无数，施舍有几个。\n\n来城十余载，头无半片瓦。\n债高如驻台，回望已无路。\n归乡已鬓白，孩童古诗朗。\n家中如做客，父母近古稀。\n行囊衣两件。车鸣催人远。\n又是归城时，何时归故乡。\n\n浑浑噩噩二十余载,\n惶惶恐恐纯属无奈.\n今夕伯乐展我荣彩,\n他日定千金还复来.\n投桃报李.', '2021-12-04 22:53:47', '2021-12-06 09:48:12', 1),
(34, 'Laravel框架架构原理', '# laravel框架原理\nLaravel的请求周期可以分成6步骤\n- 注册类文件，自动加载预设文件\n- 创建服务容器\n- 创建 HTTP / Console 内核\n- 载入服务提供者到容器\n- 分发请求\n- 发送响应并结束\n\nLaravel是单一入口方式，所有的数据请求都需要经过public/index.php的文件，\n首先会检测是否处于维护阶段（maintenance.php）\n\n\n## 注册类文件自动加载器\nLaravel然后通过composer进行依赖管理，从composer的autoload.php文件里面自动预加载设置好的文件\n\n## 创建服务容器\nindex.php加载和运行bootstrap/app.php文件，获取应用实例，创建服务容器(函数方法，类等的代码结构体)。\n\n## 创建 HTTP / Console 内核 - 各种配置和中间件\nHTTP内核 继承自Illuminate\\Foundation\\Http\\Kernel类，该类定义了一个bootstrappers数组，该数组中的类在请求被执行前运行，bootstrappers配置了错误处理、日志、检测应用环境、其他在请求被处理前需要处理的任务。\n\n## 载入服务提供者到容器- config/app.php的providers数组\n内核启动会为应用载入服务提供者，服务提供者都被配置在config/app.php配置文件的providers数组中。服务提供者被注册后，boot方法被调用。\n服务提供者负责启动框架的所有组件，如数据库、队列、验证器、路由组件等。因他们启动并配置框架提供的所有特性，服务提供者是整个Laravel启动过程中最重要部分。\n\n## 分发请求\n一旦应用被启动且所有服务提供者被注册，Request将会被交给路由器进行分发，路由器将会分发请求到路由或控制器，同时运行所有路由指定的中间件。\n\n## 发送响应和结束\nLaravel的设计模式\n依赖注入。如User 控制器依赖 UserModel，实例化的时候，直接注入。\n服务容器通过依赖注入，实现灵活的高度解耦\n门面：在服务提供者上面再封装一层静态调用，提供一个静态类调用容器中的绑定对象作用\n\n参考：\nhttps://learnku.com/laravel/t/1954/on-laravel-design-pattern\nhttps://blog.csdn.net/weixin_42980713/article/details/84997338\n', '2020-06-04 10:00:41', '2021-12-08 10:01:36', 1),
(35, 'Mysql索引', '# 索引\n\n前提：**本文基于InnoDB储存引擎**\n\n\n## 介绍\n\n- 索引是一个**单独的、存储在磁盘上的数据库结构**，它们包含着对数据表里所有记录的引用指针。使用索引用于快速找出在某个或多个列中有一特定值的行，所有MySQL列类型都可以被索引，对相关列使用索引是提高查询操作速度的最佳途径。\n\n- MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。比如我们在查字典的时候，前面都有检索的拼音和偏旁、笔画等，然后找到对应字典页码，这样然后就打开字典的页数就可以知道我们要搜索的某一个key的全部值的信息了。\n\n- 建立索引会占用磁盘空间的索引文件。\n## 索引的目的\n快速访问数据表中的特定信息，提高检索速度，创建唯一性索引，保证数据库表中每一行数据的唯一性。加速表和表之间的连接，使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间\n\n负面影响：\n创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加，索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间， 当对表进行增、删、改、的时候索引也要动态维护， 这样就降低了数据的维护速度\n\n## 类别\n\n- **Primary Key（聚集索引）**：InnoDB存储引擎的表会存在主键（唯一非null），如果建表的时候没有指定主键，则会使用第一非空的唯一索引作为聚集索引，否则InnoDB会自动帮你创建一个不可见的、长度为6字节的row_id用来作为聚集索引\n- **单列索引**：单列索引即一个索引只包含单个列\n\n- **组合索引**：组合索引指在表的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的**左边字段时**，索引才会被使用。使用组合索引时**遵循最左前缀集合**\n\n- **Unique（唯一索引）**：索引列的值必须唯一，但允许有空值。若是组合索引，则列值的组合必须唯一。主键索引是一种特殊的唯一索引，不允许有空值\n\n- **Key（普通索引）**：是MySQL中的基本索引类型，允许在定义索引的列中插入重复值和空值\n\n- **FULLTEXT（全文索引）**：全文索引类型为FULLTEXT，在定义索引的列上支持值的全文查找，允许在这些索引列中插入重复值和空值。全文索引可以在CHAR、VARCHAR或者TEXT类型的列上创建\n\n- **SPATIAL（空间索引）**：空间索引是对空间数据类型的字段建立的索引，MySQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING和POLYGON。MySQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类似的语法创建空间索引。创建空间索引的列必须声明为NOT NULL\n\n## 查看表索引列表\n\n```\n SHOW INDEX FROM table_name\n```\n\n\n\n## 创建语句\n\n```\n\n#主键索引-该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL\nALTER TABLE tbl_name ADD PRIMARY KEY (column1)\n#唯一所以-这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）\nALTER TABLE tbl_name ADD UNIQUE index_name (column1)\n#普通索引-索引值可出现多次。\nALTER TABLE tbl_name ADD INDEX index_name (column1)\n#全文索引\nALTER TABLE tbl_name ADD FULLTEXT index_name (column1)\n#组合索引\nALTER TABLE tbl_name add INDEX `index_name` (`column1`,`column2`,`column3`) \n#空间索引\nALTER TABLE tbl_name ADD SPATIAL INDEX(column1);\n\n```\n\n## 移除语句\n\n```\n#主键索引\nALTER TABLE tbl_name DROP PRIMARY KEY \n#唯一所以\nALTER TABLE tbl_name DROP UNIQUE index_name\n#普通索引\nALTER TABLE tbl_name DROP INDEX index_name \n#全文索引\nALTER TABLE tbl_name DROP FULLTEXT index_name \n#组合索引\nALTER TABLE tbl_name DROP INDEX `index_name` \n#空间索引\nALTER TABLE tbl_name DROP SPATIAL INDEX(column1);\n# 或者使用下面这个\nDROP INDEX index_name ON table_name;\n```\n\n\n\n## explain使用说明\n\n```\nexplain select * from user\n```\n\n字段说明：\n\n![avatar](https://wx3.sinaimg.cn/mw690/007eXScSgy1gspw21sqlgj30q003r74n.jpg)\n\n```\nid: SELECT识别符。这是SELECT的查询序列号,表示查询中执行select子句或操作表的顺序,id相同，执行顺序从上到下,id不同，id值越大执行优先级越高\nselect_type：表示SELECT语句的类型。它可以是以下几种取值：\n    SIMPLE:表示简单查询，其中不包括连接查询和子查询；\n    PRIMARY:表示主查询，或者是最外层的查询语句，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY；\n    UNION:表示连接查询的第2个或后面的查询语句， 不依赖于外部查询的结果集\n    DEPENDENT UNION:连接查询中的第2个或后面的SELECT语句，依赖于外面的查询；\n    UNION RESULT:连接查询的结果；\n    SUBQUERY:子查询中的第1个SELECT语句；不依赖于外部查询的结果集\n    DEPENDENT SUBQUERY:子查询中的第1个SELECT，依赖于外面的查询；\n    DERIVED:导出表的SELECT（FROM子句的子查询）,MySQL会递归执行这些子查询，把结果放在临时表里。\n    DEPENDENT DERIVED:派生表依赖于另一个表\n    MATERIALIZED:物化子查询\n    UNCACHEABLE SUBQUERY:子查询，其结果无法缓存，必须针对外部查询的每一行重新进行评估\n    UNCACHEABLE UNION:UNION中的第二个或随后的 select 查询，属于不可缓存的子查询\ntable:表示查询的表\npartitions:查询将从中匹配记录的分区。该值适用NULL于未分区的表\ntype:表示表的连接类型\n    system:该表是仅有一行的系统表。这是const连接类型的一个特例\n    const: 数据表最多只有一个匹配行，它将在查询开始时被读取，并在余下的查询优化中作为常量对待。const表查询速度很快，因为只读取一次,const用于使用常数值比较PRIMARY KEY或UNIQUE索引的所有部分的场合。\n    eq_ref:对于每个来自前面的表的行组合，从该表中读取一行,可以用于使用=运算符进行比较的索引列 。比较值可以是常量，也可以是使用在此表之前读取的表中列的表达式\n    ref:对于来自前面的表的任意行组合，将从该表中读取所有匹配的行，ref可以用于使用“＝”或“＜＝＞”操作符的带索引的列。\n    fulltext:使用FULLTEXT 索引执行联接\n    ref_or_null:这种连接类型类似于ref，但是除了MySQL还会额外搜索包含NULL值的行。此联接类型优化最常用于解析子查询\n    index_merge:此联接类型指示使用索引合并优化。在这种情况下，key输出行中的列包含使用的索引列表，并key_len包含使用的索引 的最长键部分的列表\n    unique_subquery:类型替换 以下形式的eq_ref某些 IN子查询,unique_subquery 只是一个索引查找函数，它完全替代了子查询以提高效率。\n    index_subquery:连接类型类似于 unique_subquery。它代替IN子查询,但只适合子查询中的非唯一索引\n    range:只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。当使用＝、＜＞、＞、＞＝、＜、＜＝、IS NULL、＜＝＞、BETWEEN或者IN操作符用常量比较关键字列时，类型为range\n    index:该index联接类型是一样的 ALL，只是索引树被扫描。这发生两种方式：1、如果索引是查询的覆盖索引，并且可用于满足表中所需的所有数据，则仅扫描索引树。在这种情况下，Extra列显示为 Using index，2、使用对索引的读取执行全表扫描，以按索引顺序查找数据行。 Uses index没有出现在 Extra列中。\n    ALL:对于前面的表的任意行组合进行完整的表扫描    \npossible_keys:指出MySQL能使用哪个索引在该表中找到行。若该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看它是否引用某些列或适合索引的列来提高查询性能。如果是这样，可以创建适合的索引来提高查询的性能。\nkye:表示查询实际使用的索引，如果没有选择索引，该列的值是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX\nkey_len：表示MySQL选择的索引字段按字节计算的长度，若键是NULL，则长度为NULL。注意，通过key_len值可以确定MySQL将实际使用一个多列索引中的几个字段\nref：表示使用哪个列或常数与索引一起来查询记录。\nrows：显示MySQL在表中进行查询时必须检查的行数。\nExtra：表示MySQL在处理查询时的详细信息\n```\n\n\n\n## 索引实现原理\n\n- innodb存储的索引是基于B+树实现的\n\n- B树和B+树又被称为多路查找，一个节点存储了多个key来减少磁盘IO，从而提高检索速度。\n\n### B+树\n\n#### 特征\n\n- 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。\n\n- 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。\n\n- 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。\n\n#### 优势\n\n- 单一节点存储更多的元素，使得查询的IO次数更少。\n\n- 所有查询都要查找到叶子节点，查询性能稳定。\n\n- 所有叶子节点形成有序链表，便于范围查询。\n\n- 在B+树中，所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接。\n\n\n\n### B树（平衡多路查找树（B-Tree））\n\n	- 树内的每个节点都存储数据\n	- 叶子节点之间无指针连接\n\n#### B树和B+树有什么区别\n\n- B树一个节点里面存的是（key&value），而B+树存储的是（key），所以B树里一个节点存不了很多（key&value），但是B+树一个节点能存储很多（key），B+树叶子节点存所有的数据\n- B+树的叶子节点是（key&value，并用一个链表串联起来\n- B+树节点存储的是索引，在单个节点存储容量有限的情况下，单节点也能存储大量索引，使得整个 B+树高度降低，减少了磁盘 IO\n- B+树的叶子节点是真正数据存储的地方，叶子节点用了链表连接起来，这个链表本身就是有序的，在数据范围查找时，更具备效率\n\n未完\n\n参考链接：https://zhuanlan.zhihu.com/p/346849749', '2021-12-08 10:04:55', '2021-12-08 10:06:34', 1),
(36, '个人理解的微服务', '微服务改造的过程实际上也是个抽象的过程。\n微服务架构设计，一个微服务应该就是一个可单独部署，可运行的应用，也就是微服务最小的运行单元。\n微服务本身内部高度内聚，微服务与微服务之间低耦合。\n首先对于应用划分上，就应该想清楚每个微服务的职责，每个微服务服务内部建立起自己的依赖，完成自己的职责和业务。\n微服务与微服务之间交互通过HTTP或RPC接口调用，降低微服务之间代码实现和业务的耦合。\n微服务的实现不应该受限某程序语言(或Java，或Go，或Python)，不应该受限于某框架(或SpringCloud，或Dubbo，或各种RPC框架等等)。\n我的代码结构是对于一个微服务本身(即应用)划分的，领域是对于微服务内部本身而言的，即这个微服务涉及哪些领域。\n首先从大的方向去划分每一个微服务，然后再从每一个微服务确定所包含的领域，领域的边界，等等.比如划分了一个 认证授权服务，那么 领域可能有 用户，权限；实体可能有角色，资源等等。领域行为有授权登录，用户退出，授权等等。\n　　不要被框架和结构本身所限制！\n\n参考：https://www.zhihu.com/question/65502802\n\n\ngrpc go demo\nhttps://github.com/Bingjian-Zhu/go-grpc-example\n\n\n\ngo-zero文档\nhttps://go-zero.dev/cn/', '2021-12-08 11:21:48', '2022-01-05 10:49:09', 1),
(37, 'sync.Mutex 和 sync.RWMutex', 'https://www.jianshu.com/p/679041bdaa39', '2021-12-15 18:14:44', NULL, 2),
(38, '切片、数组、make、copy', '#### New Make 区别\n- new 函数只接受一个参数，这个参数是一个类型，并且返回一个指向该类型内存地址的指针。同时 new 函数会把分配的内存置为零，也就是类型的零值。\n- make 也是用于内存分配的，但是和 new 不同，它只用于 chan、map 以及 slice 的内存创建，而且它返回的类型就是这三个类型本身，而不是他们的指针类型，因为这三种类型就是引用类型，所以就没有必要返回他们的指针了。\n- var 声明 (包括结构体)，系统会默认为他分配内存空间，并赋该类型的零值。\n如果使用 var 声明一个指针类型的变量，系统不会为他分配内存，默认就是 nil。此时如果你想直接使用，那么系统会抛异常。需要只用 new 分配内存\n\n#### 切片\n```\n//切片是一个引用类型 其都指向它的底层数组\n\n// 初始化\ns1 = []int{1, 2, 3}\ns2 = []string{\"x\", \"y\", \"z\"}\n\n//由数组得到切片\na1 := [...]int{1, 3, 5, 7, 9}\ns3 := a1[0:3] // 左闭右开\nfmt.Println(s3)\n```\n\n#### make函数切片\n```\nmake([]type,len,cap)\na1 := make([]int, 4, 6) //==>  [0,0,0,0]\n\na2 := make([]int, 0, 6)//===>[]\n```\n\n#### append() 为切片追加元素\n```\n//append追加元素时，原来的底层数组放不下的时候，Go底层就会换一个新的底层数组，为了防止原来的切片丢失，需要用原来的切片来进行接收\n\ns1 := []string{\"北京\", \"上海\", \"广州\"}\n\n//单个追加\ns1 = append(s1, \"成都\")\n\n// 追加多个元素\ns2 := []string{\"大连\", \"重庆\", \"西安\"}\ns1 = append(s1, s2...) //...表示拆开\n\n\n```\n#### 使用copy函数复制切片\n```\na1 := []int{1, 3, 5}\na2 := a1\na3 := make([]int, 3)\n\n// 拷贝赋值  值拷贝\ncopy(a3, a1)\nfmt.Println(a1, a2, a3)\na1[0] = 100\nfmt.Println(a1, a2, a3)\n\n// 从切片中删除元素2\na := []int{1, 2, 3, 4, 5, 6}\na = append(a[:1], a[2:]...)\nfmt.Println(a)\n\nx1 := [...]int{1, 3, 5, 7}\ns1 := x1[:]\nfmt.Println(s1, len(s1), cap(s1))\n// 1. 切片不保存具体的值\n// 2. 切片对应一个底层数组\n// 3. 底层数组都是占用一块连续的内存空间\ns1 = append(s1[:1], s1[2:]...) // 修改了底层数组！！ 前移元素覆盖掉原来的数组\nfmt.Println(s1, len(s1), cap(s1))\n```', '2021-12-16 10:11:28', '2022-03-02 15:24:10', 1),
(39, 'golang-打印相关fmt', '```\nnum := 90\n%T ：查看类型 //fmt.Printf(\"%T\\n\",num)\n%b ：二进制\n%d ：十进制\n%o ：八进制\n%x ：十六进制\n%s ：字符串\n%c ：字符\n%v ：值\n%p ：指针 将指针表示为十六进制\n%f ：浮点数\n%t : 布尔值\n\n//整数 --> 字符\nfmt.Printf(\"%q\\n\", 65)\n// \'A\'\n\n//百分数\nfmt.Printf(\"%d%%\\n\", num)\n// 90%\n```', '2020-07-22 16:45:35', '2021-12-20 16:47:20', 1),
(40, 'golang - 读、写取文件三种方式', '\n### 读文件\n```\npackage main\n\nimport (\n	\"bufio\"\n	\"fmt\"\n	\"io\"\n	\"io/ioutil\"\n	\"os\"\n)\n\n// 文件操作\nfunc readFile1() {\n	fileObj, err1 := os.Open(\"F:/GoCode/src/test.txt\")\n	if err1 != nil {\n		fmt.Printf(\"open file failed, err %v\\n\", err1)\n		return\n	}\n	fmt.Printf(\"%T\\n\", fileObj)\n	// 延时关闭文件\n	defer fileObj.Close()\n	// 循环读文件\n	for {\n		var buffer = make([]byte, 2)\n		n, err2 := fileObj.Read(buffer)\n		if n == 0 {\n			return\n		}\n		if err2 != nil {\n			fmt.Println(\"read file failed\")\n		} else {\n			fmt.Printf(\"读到的字节数：%d\\n\", n) // 字节数\n			fmt.Println(string(buffer))\n		}\n\n	}\n}\n\n// 利用bufio这个包读文件\nfunc readFile2() {\n	fileObj, err1 := os.Open(\"F:/GoCode/src/test.txt\")\n	if err1 != nil {\n		fmt.Printf(\"open file failed, err %v\\n\", err1)\n		return\n	}\n	fmt.Printf(\"%T\\n\", fileObj)\n	// 延时关闭文件\n	defer fileObj.Close()\n	// 循环读文件\n	reader := bufio.NewReader((fileObj))\n	for {\n		str, err := reader.ReadString(\'\\n\')\n		if err == io.EOF { // 读到文件末尾\n			return\n		}\n		if err != nil { // 读取文件失败\n			fmt.Printf(\"read file failed, err :%v\\n\", err)\n			return\n		}\n		fmt.Print(str)\n	}\n}\n\n// 第三种读文件的方式\nfunc readFile3() {\n	b, err := ioutil.ReadFile(\"F:/GoCode/src/test.txt\")\n	if err != nil {\n		fmt.Printf(\"read file failed, err %v\\n\", err)\n	} else {\n		fmt.Println(string(b))\n	}\n}\n\nfunc main() {\n	//readFile1()\n	//readFile2()\n	readFile3()\n}\n\n```\n### 写文件\n```\n// 写文件\nfunc writeFile1() {\n	// O_APPEND 追加  O_TRUNC 每次写都清空\n	fileObj, err1 := os.OpenFile(\"./src/day05/10_file_write/test.txt\", os.O_TRUNC|os.O_CREATE|os.O_WRONLY, 0644)\n	if err1 != nil {\n		fmt.Printf(\"open file error :%v\\n\", err1)\n		return\n	}\n	var myByte []byte = []byte(\"come on\\n\")\n	// write\n	n, err2 := fileObj.Write(myByte)\n	if err2 != nil {\n		fmt.Printf(\"write file error :%v\\n\", err2)\n		return\n	} else {\n		fmt.Printf(\"写入的字节数是: %d\\n\", n)\n	}\n	// writestring\n	n, _ = fileObj.WriteString(\"baby\")\n	fmt.Printf(\"写入的字节数是: %d\\n\", n)\n	fileObj.Close()\n}\n\nfunc writeFile2() {\n	// O_APPEND 追加  O_TRUNC 每次写都清空\n	fileObj, err1 := os.OpenFile(\"./src/day05/10_file_write/test.txt\", os.O_TRUNC|os.O_CREATE|os.O_WRONLY, 0644)\n	if err1 != nil {\n		fmt.Printf(\"open file error :%v\\n\", err1)\n		return\n	}\n	defer fileObj.Close()\n	// 创建一个写的对象\n	ret := bufio.NewWriter(fileObj)\n	ret.WriteString(\"let\'s Go\\n\") // 写到缓存中\n	ret.Flush()                   // 将缓存中的内容写入到文件\n}\n\nfunc writeFile3() {\n	str := \"simiada\"\n	err := ioutil.WriteFile(\"./src/day05/10_file_write/test.txt\", []byte(str), 0644)\n	if err != nil {\n		fmt.Printf(\"write error: %v\\n\", err)\n	} else {\n		fmt.Println(\"write done\")\n	}\n}\n\nfunc main() {\n	//writeFile1()\n	//writeFile2()\n	writeFile3()\n}\n\n```', '2020-07-31 17:14:26', '2021-12-20 17:14:41', 1),
(41, 'go 关于channel的两个简单demo', '\n#### var wg sync.WaitGroup \n等待所有的goroutine执行完之后再退出\n```\nvar wg sync.WaitGroup\ngo func(){\n	wg.Add(1)  //表示启用几个goroutine\n}()\ngo func(){\n	wg.Done()\n}()\nwg.Wait() // 计数器减为0时则程序结束\n```\n\n#### channel ：分为带缓冲区的channel和不带缓冲区的channel\n```\nvar wg sync.WaitGroup\nvar c chan int // 需要指定通道中元素的类型\nfunc noBufChannel() {\n	c = make(chan int) //无缓冲区的通道的初始化\n	wg.Add(1)\n	go func() {\n		defer wg.Done()\n		x := <-c // 取出数据\n		fmt.Println(\"go routine\", x)\n	}()\n\n	c <- 10 // 发送到通道中,缓冲区为0的不能接收数据，需要启动一个线程来取出数据，否则会阻塞等待\n	fmt.Println(\"10发送到了通道c中\")\n	// Wait方法阻塞直到WaitGroup计数器减为0。\n	wg.Wait()\n	close(c)\n}\nfunc main() {\n	noBufChannel()\n	bufChannel()\n}\nfunc bufChannel() {\n	c = make(chan int, 10) // 缓冲区为10的通道的初始化\n	c <- 10                // 发送到通道中\n	fmt.Println(\"10发送到了通道c中\")\n	x := <-c // 从一个通道中接收值\n	fmt.Println(x)\n}\n```\n#### 单向通道：关闭通道之后不可再往通道里面发送数据，但可从通道里面发送数据出去\n```\nfunc f1(ch1 chan<- int) {\n	// 1. 启动一个goroutine，生成100个数发送到ch1中\n	defer wg.Done()\n	for i := 0; i < 100; i++ {\n		ch1 <- i\n	}\n	// 关闭通道之后不可再往通道里面发送数据，但可从通道里面发送数据出去\n	close(ch1)\n}\n```\n\n#### channel的关闭close：\n- 对一个已经关闭了的通道取值，取到的值是零值，取到的ok是false类型\n- 如果不关闭通道，当通道已经为空时，再读就被报错deadlock!', '2021-12-21 10:10:53', '2021-12-21 10:46:14', 1),
(42, 'golang 加锁、原子操作、sync.Map例子', '#### 用多个goroutine处理一个公共的变量 需要加锁\n```\nvar x int\nvar wg sync.WaitGroup\nvar lock sync.Mutex // 定义一个互斥锁\nfunc add() {\n	defer wg.Done()\n	for i := 0; i < 5000; i++ {\n		lock.Lock()   // 加锁\n		x++           // 写操作\n		lock.Unlock() // 解锁\n	}\n}\nfunc main() {\n	wg.Add(2)\n	go add()\n	go add()\n	wg.Wait()\n	fmt.Println(x)\n}\n```\n#### 读共享，写独占，写的优先级高  读写锁的效率比互斥锁的效率更高\n```\nvar x int = 0\nvar lock sync.Mutex //互斥锁\nvar wg sync.WaitGroup\nvar rwlock sync.RWMutex //读写锁\n// 读操作\nfunc read() {\n	defer wg.Done()\n	lock.Lock()\n	//rwlock.RLock() // 加读锁\n	fmt.Println(x)\n	time.Sleep(time.Millisecond) // 0.001s读一次\n	lock.Unlock()\n	//rwlock.RUnlock() // 解读锁\n}\n// 写操作\nfunc write() {\n	defer wg.Done()\n	lock.Lock()\n	//rwlock.Lock() // lock也即写锁\n	x++\n	time.Sleep(time.Millisecond * 5) // 0.005s写一次\n	lock.Unlock()\n	//rwlock.Unlock()\n}\nfunc main() {\n	startTime := time.Now()\n	// 写一百次\n	for i := 0; i < 10; i++ {\n		wg.Add(1)\n		go write()\n	}\n	// 读一千次\n	for i := 0; i < 1000; i++ {\n		wg.Add(1)\n		go read()\n	}\n	wg.Wait()\n	endTime := time.Now()\n	fmt.Println(endTime.Sub(startTime)) // 程序执行时间\n}\n```\n#### Go内置的map不是并发安全的\n报错：fatal error: concurrent map writes\n```\nvar m = make(map[string]int)\nfunc get(key string) int {\n	return m[key]\n}\nfunc set(key string, value int) {\n	m[key] = value\n}\nfunc main() {\n	wg := sync.WaitGroup{}\n	for i := 0; i < 20; i++ {\n		wg.Add(1)\n		go func(n int) {\n			key := strconv.Itoa(n)\n			set(key, n)\n			fmt.Printf(\"k=:%v,v:=%v\\n\", key, get(key))\n			wg.Done()\n		}(i)\n	}\n	wg.Wait()\n}\n```\n\n#### 多线程使用map时需要使用安全的sync.map\n```\nvar m2 sync.Map\nfunc main() {\n	wg := sync.WaitGroup{}\n	for i := 0; i < 20; i++ {\n		wg.Add(1)\n		go func(n int) {\n			key := strconv.Itoa(n)\n			m2.Store(key, n) //必须使用 sync.map 的内置方法\n			value, _ := m2.Load(key)\n			fmt.Printf(\"k=:%v,v:=%v\\n\", key, value)\n			wg.Done()\n		}(i)\n	}\n	wg.Wait()\n}\n```\n\n#### 原子操作:atomic.AddInt(&x,1),在内部也实现了加锁和解锁\n```\nvar x int64\nvar wg sync.WaitGroup\nfunc add() {\n	defer wg.Done()\n	atomic.AddInt64(&x, 1) // 利用原子操作对值加1  在内部也实现了加锁和解锁   可以直接调用这个即可，方便调用\n}\nfunc main() {\n	for i := 0; i < 10; i++ {\n		wg.Add(1)\n		go add()\n	}\n	wg.Wait()\n	fmt.Println(x)\n}\n```', '2021-12-21 11:30:21', NULL, 1),
(43, '2022-01-02 22:00-在想什么？', '突然，想来写几句\n不知道该干些什么，也不知道该想啥了，王者已经玩腻，lol也已经没有当初的激情，好像看不到什么，也好像什么也看不到，双手已经只能不停的瞎折腾，没有方向、没有动力，时常在想，是不是每个26岁的人都是这样呢？工作两三年，熟悉了社会规则，逐渐迷失，总想逃出去，可是又不知道干什么，一旦出去又发现自己什么都做不了，那时候的他们是怎么度过的呢？会不会跟我一样苦恼，一样思考着同样的问题，越来越觉得没有劲，好像没有了生活的压力，找不到人生的乐趣，除了想守护的亲人、朋友能让自己坚定的不能倒下，其他的好像一切都很灰暗了，总是在思考应该做什么。\n\n有时，真的有点怀念以前的时候，那时候没有这么多想法，只想着如何能活下去，没有时间去思考这些无意义又特别累的事，只想着怎么专心工作、专心挣钱，而不是像现在这样每天刷视频从天亮到天黑，从天黑到天亮，感觉就像是在耗费自己的生命，没有任何的意义，逐渐自闭的感觉。\n夜晚总是让人敏感的，网易云播放着周兴哲的《你，好不好？》，深圳的冬天并没有想象的那么冷，但夜依然不能轻易寐，也许这是深圳年轻人的常规状态吧，幻想着能做很多，但发现又什么都做不了，只能在一个人的出租房不断内耗，和自己的思想躺平。\n\n![image.png size](https://pic2.zhimg.com/v2-caea979bfb6e8b2a54aecc7e0f2c4ba0_r.jpg?source=172ae18b =500x400)', '2022-01-02 22:20:08', '2022-01-02 22:32:00', 1),
(44, 'markdown 图片处理', 'markdown 图片处理\n\n```\n![image.png size](https://pic2.zhimg.com/v2-caea979bfb6e8b2a54aecc7e0f2c4ba0_r.jpg?source=172ae18b =500x400)\n```\n\n<p>\n\n![image.png size](https://pic2.zhimg.com/v2-caea979bfb6e8b2a54aecc7e0f2c4ba0_r.jpg?source=172ae18b =500x400)\n\n\n\n\n![image.png size](https://gitee.com/jushitangguoshan/image_store/raw/master/%E4%B8%8B%E8%BD%BD%20(6).jpg =500x400)\n\n', '2022-01-10 11:37:21', '2022-01-13 17:37:33', 1),
(45, 'Golang 关于《顺序一致性内存模型》', '## 如下：\n```\nvar a string\nvar done bool\n\nfunc setup() {\n    a = \"hello, world\"\n    done = true\n}\n\nfunc main() {\n    go setup()\n    for !done {\n	print(1111)\n    }\n    print(a)\n}\n```\n我们创建了setup线程，用于对字符串a的初始化工作，初始化完成之后设置done标志为true。main函数所在的主线程中，通过for !done {}检测done变为true时，认为字符串初始化工作完成，然后进行字符串的打印工作。\n\n**但是Go语言并不保证在main函数中观测到的对done的写入操作发生在对字符串a的写入的操作之后，因此程序很可能打印一个空字符串。更糟糕的是，因为两个线程之间没有同步事件，setup线程对done的写入操作甚至无法被main线程看到，main函数有可能陷入死循环中**\n\n**注意**\n在Go语言中，同一个Goroutine线程内部，顺序一致性内存模型是得到保证的。但是不同的Goroutine之间，并不满足顺序一致性内存模型，需要通过明确定义的同步事件来作为同步的参考。如果两个事件不可排序，那么就说这两个事件是并发的。为了最大化并行，Go语言的编译器和处理器在不影响上述规定的前提下可能会对执行语句重新排序（CPU也会对一些指令进行乱序执行）。\n\n根据Go语言规范，main函数退出时程序结束，不会等待任何后台线程。因为Goroutine的执行和main函数的返回事件是并发的，谁都有可能先发生，所以什么时候打印，能否打印都是未知的。\n\n### 用前面的原子操作并不能解决问题，因为我们无法确定两个原子操作之间的顺序。解决问题的办法就是通过同步原语来给两个事件明确排序：\n```\nfunc main() {\n    done := make(chan int)\n\n    go func(){\n        println(\"你好, 世界\")\n        done <- 1\n    }()\n\n    <-done\n}\n```\n\n当<-done执行时，必然要求done <- 1也已经执行。根据同一个Gorouine依然满足顺序一致性规则，我们可以判断当done <- 1执行时，println(\"你好, 世界\")语句必然已经执行完成了。因此，现在的程序确保可以正常打印结果。\n\n#### 换一种方式:通过sync.Mutex互斥量也是可以实现同步的：\n```\nfunc main() {\n    var mu sync.Mutex\n\n    mu.Lock()\n    go func(){\n        println(\"你好, 世界\")\n        mu.Unlock()\n    }()\n\n    mu.Lock()\n}\n```\n可以确定后台线程的mu.Unlock()必然在println(\"你好, 世界\")完成后发生（同一个线程满足顺序一致性），main函数的第二个mu.Lock()必然在后台线程的mu.Unlock()之后发生（sync.Mutex保证），此时后台线程的打印工作已经顺利完成了。', '2021-08-19 14:58:40', '2022-01-10 14:59:02', 1),
(46, 'Golang 关于channle管道来实现同步', '## 管道的缓冲影响\n```\nunc main() {\n    done := make(chan int)\n    go func(){\n        fmt.Println(\"你好, 世界\")\n        <-done\n    }()\n\n    done <- 1\n}\n```\n**问题**：根据Go语言内存模型规范，对于从无缓冲Channel进行的接收，发生在对该Channel进行的发送完成之前。因此，后台线程<-done接收操作完成之后，main线程的done <- 1发送操作才可能完成（从而退出main、退出程序），而此时打印工作已经完成了。\n\n**解决**：如果管道有缓存的话，就无法保证main退出之前后台线程能正常打印了。更好的做法是将管道的发送和接收方向调换一下，这样可以避免同步事件受管道缓存大小的影响：\n```\nfunc main() {\n    done := make(chan int, 1) // 带缓存的管道\n\n    go func(){\n        fmt.Println(\"你好, 世界\")\n        done <- 1\n    }()\n\n    <-done\n}\n```\n\n### 基于带缓存的管道\n我们可以很容易将打印线程扩展到N个。下面的例子是开启10个后台线程分别打印：\n```\nfunc main() {\n    done := make(chan int, 10) // 带 10 个缓存\n\n    // 开N个后台打印线程\n    for i := 0; i < cap(done); i++ {\n        go func(){\n            fmt.Println(\"你好, 世界\")\n            done <- 1\n        }()\n    }\n\n    // 等待N个后台线程完成\n    for i := 0; i < cap(done); i++ {\n        <-done\n    }\n}\n```\n#### 对于这种要等待N个线程完成后再进行下一步的同步操作有一个简单的做法，就是使用sync.WaitGroup来等待一组事件\n```\nunc main() {\n    var wg sync.WaitGroup\n\n    // 开N个后台打印线程\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n\n        go func() {\n            fmt.Println(\"你好, 世界\")\n            wg.Done()\n        }()\n    }\n\n    // 等待N个后台线程完成\n    wg.Wait()\n}\n```\n', '2022-01-10 15:46:41', NULL, 1),
(47, 'Laravel nginx配置文件demo', '#### 环境\n- wsl\n- php7.4\n- nginx\n```\n启动 php\nsudo service php7.4-fpm start\n\n查看是否启动\nps -ef |grep php\n\n启动 nginx\nsudo service nginx start\n```\n```\nserver {\n    listen 80;\n    server_name wl.com;  #域名\n    #站点目录，请求到laravel项目的public目录\n    root /mnt/d/xxx/zhishenghuo/code/DeviceModel/public;\n    index index.html index.htm index.php;\n\n    add_header X-Frame-Options \"SAMEORIGIN\";\n    add_header X-XSS-Protection \"1; mode=block\";\n    add_header X-Content-Type-Options \"nosniff\";\n\n    charset utf-8;\n\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    if (!-e $request_filename) {\n        rewrite ^(.*)$ /index.php/$1 last;\n        break;\n    }\n    location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$ {\n\n        expires      30d;\n    }\n\n    location ~ .*\\.(js|css)?$\n    {\n        expires      12h;\n    }\n\n    location ~ /.well-known {\n        allow all;\n    }\n\n    location ~ \\.php$ {\n        fastcgi_pass   unix:/run/php/php7.4-fpm.sock;\n        #wsl需要这样配置：在php-fpm目录下的pool.d/www.conf中查找:listen\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        include fastcgi_params;\n    }\n     access_log /ng/logs/deviceModel/access.log;\n     error_log /ng/logs/deviceModel/error.log;\n}\n\n```', '2022-01-13 16:18:22', '2022-01-13 17:02:22', 1),
(48, 'phpstorm设置鼠标滚动缩放代码字体大小', '![image.png size](https://img-blog.csdnimg.cn/20181114221223274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RvbmdfQWxleA==,size_16,color_FFFFFF,t_70 =500x400)', '2022-01-13 17:38:09', NULL, 1),
(49, '他朝若是同淋雪，此生也算共白头', '但使龙城飞将在，不教胡马度阴山', '2022-01-18 20:40:17', NULL, 1);
INSERT INTO `blog_article` (`id`, `title`, `content`, `create_time`, `update_time`, `status`) VALUES
(50, 'Mysql 命令行', 'mysql -h 192.168.1.110 -P 3306 -uroot -proot\n\n### 数据库语句\n\n```\n/*显示所有数据库*/\nSHOW DATABASES;\n/*进入数据库*/\nUSE MYSQL1;\n/*显示所有表*/\nSHOW TABLES;\n/*查看当前所在库*/\nSELECT DATABASE();\n/*创建表*/\nCREATE TABLE student(\nid int,\nname varchar(20));\n/*查看表结构*/\nDESC student;\n/*查看MySQL版本*/\nSELECT VERSION();\n\n```\n\n\n### 分组函数\n```\n/*\n分组函数**********************************************************************\nsum()\navg()\ncount()\nmax()\nmin()\n特点：\nsum,avg一般用于处理数据类型\nmax,min,count处理类型不限\n分组函数都忽略null值\ncount(*) 不会忽略null\ncount(1) 不会忽略null，相比count(1)通常效率更高\n*/\n\n```\n\n\n### 连接图示\n![img](https://www.freesion.com/images/222/2902bc7691ab48b8a7609bafe8ee84f6.png)\n### 查询SQL\n```\n/*\nselect from\n基础查询******************************************************\n*/\nSELECT * FROM student;\n/*取别名*/\nSELECT id AS 学生号,name 姓名 FROM student;\n/*去重*/\nSELECT DISTINCT id AS \'学 号\' FROM student;\n/* + 的用法仅有运算符，一方为null，结果为null,下方’123‘转换整数失败即为整数0，结果为1*/\nSELECT \'123\'+1;\n/*字符串拼接*/\nSELECT CONCAT(last_name,first_name) FROM student;\n/*字符串拼接需要注意null问题,first_name为null时候显示\'\'*/\nSELECT CONCAT(last_name,IFNULL(first_name,\'\')) AS 姓名 FROM student;\n\n/*\nselect from where\n条件查询**********************************************************\n条件运算：>	< 	=	!=	<>(!=)	>=	<=\n逻辑运算:and or not\n模糊查询:like	between and		in		is null\n*/\n/*查询学生中第三个字符为e，第五个字符为a的学生信息*/\nSELECT * FROM student WHERE name like \'__e_a%\';\n/*查询年龄在[17,22]区间的学生，and的简约写法*/\nSELECT * FROM student WHERE age BETWEEN 17 AND 22;\n/*查询张三，李四，王五的信息，or的简约写法*/\nSELECT * FROM student WHERE name IN(\'张三\'，\'李四\'，\'王五\')；\n/* =, != 无法判断null，null需要使用is，is not判断,<=>是安全等于，不受null限制*/\n\n\n```\n\n### 单行函数\n```\n/*\n排序查询***********************************************************\norder by\nasc  升序\ndesc 降序\n*/\nSELECT * FROM student ORDER BY age ASC;\n/*按年薪高低显示员工信息和年薪*/\nSELECT *, salary*12*(1+IFNULL(commission_pct,0)) AS 年薪 \nFROM employees\nORDER BY 年薪 DESC;\n/*先按学生年龄降序，再按学生名字字节长度升序显示学生信息*/\nSELECT *\nFROM student\nORDER BY age DESC, LENGTH(name) ASC;\n\n/*\n字符函数**********************************************************\nlength()		返回字节数\nconcat()		拼接字符串\nupper()			字符转大写\nlower()			字符转小写\nsubstr(str,n)	字符截取\ninstr(str,s)	返回子字符起始位置\ntrim()			去空格\nlpad(str,n,s)	以s按n长度左填充str\nreplace()		替换\n*/\n\n/*\n数学函数***************************************************************\nround()			四舍五入\nceil()			向上取整\nfloor()			向下取整\ntruncate(1.22,1)截断,结果为1.2\nMod(m,n)		取余,m%n(取余结果符号与m一致)\n*/\n\n/*\n日期函数****************************************************************\nnow()			当前日期+时间\ncurdate()		返回当前日期\ncurtime()		返回当前时间\nyear(now())	\nmonth(now())\nmonthname(now())\nstr_to_date(\'2020-12-2\',\'%Y-%m-%d\')			字符转日期\ndate_format(\'2020/12/2\',\'%Y年%m月%d日\')	  日期转字符\n*/\n\n/*\n流程控制函数**************************************************************\nif(false,\'yes\',\'no\')			按三元函数部署\ncase用法：\njava中:	\n		switch(变量){\n			case 常量1：语句1;break;\n			.....\n			default:语句;break;\n		}\nsql中：（case 后写条件是java的switch,不写条件是多重else if） \n		case 变量/条件\n		when 常量1 then 语句1;/值1\n		.......\n		else 语句;/值\n		end;\n*/\nSELECT salary 原工资, department_id 部门,\nCASE department_id\nWHEN 1 THEN salary*1.1\nWHEN 2 THEN salary*1.2\nELSE salary\nEND AS 新工资\nFROM employees;\n\n\n```\n\n### 范式\n范式：符合一定规范的形式\n\n第一范式：（原子性）每一列不可再分割\n\n第二范式：（主键）有唯一标识符\n\n第三范式：（外键）一个表中的数据不能同时是其他表里的非主键数据\n\n反三范式：有时候为了查询效率，可以违背第三范式\n\n### 备份\n- 直接拷贝物理文件\n\n- 可视化工具中备份\n\n- 命令行mysqldump备份(会导出SQL命令的合集文件)\n```\n#导出数据库[表]\n#mysqldump -h主机 -u用户名 -p密码 数据库 [表名1 ...] > 物理磁盘位置/文件名\nmysqldump -hlocalhost -uroot -p123456 school student >D:/database/mysql.sql\n\n#导入数据库[表]\n#登录情况下：\nsource D:/database/mysql.sql\n#未登录的情况下 \nmysql -u用户名 -p密码 数据库 < 物理磁盘位置/文件名\n\n```\n\n\n### MySQL解锁方式：\n```\n#查看当前数据库锁表的情况\nSELECT * FROM information_schema.INNODB_TRX\n#杀掉查询结果中锁表的\ntrx_mysql_thread_id kill trx_mysql_thread_id\n```', '2022-01-19 17:41:20', '2022-02-08 14:25:19', 1),
(51, 'Curl  请求接口', '# 示例请求\n\ncurl -v www.baidu.com\n\n-i选项可以显示Response的Header信息，连同Body数据\n-I选项可以只显示Response的Header信息\n\ncurl -i www.baidu.com\n\n# post \n我们可以使用-d或--data选项来指定具体的数据\n\ncurl -d key1=value1&key2=value2 http://example.com\ncurl -d key1=value1 -d key2=value2 http://example.com\n\n# Content-Type\n\napplication/x-www-form-urlencoded：默认的形式，即key1=value1&key2=value2的形式；\nmultipart/form-data：使用表单上传文件时使用这个形式；\napplication/json：提交JSON格式的数据；\ntext/xml：提交XML格式的数据。\n\nontent-Type是一个Header，如果不指定的话，那么默认就是使用application/x-www-form-urlencoded形式传输数据，当需要使用别的形式进行数据传输的话，那么就需要指定这个Header：\n\ncurl -d \'{I Am A JSON FORM}\' -H \'Content-Type: application/json\' http://example.com\n\n-H就是用来指定一个具体的Header的选项，值就是key=value 的形式。\n\n# GET\n\n使用-G或-get选项，可以把一个POST请求转化成一个GET请求。如果有-d选项指定的参数，那么curl就会把-d后面的数据添加到URL的后面，用?连接。比如：\n\n curl -d \"key1=value1\" -G http://example.com\n\n得到：http://example.com/?key1=value1\n\n当使用-F选项时，默认的Content-Type就是multipart/form-data，不过，我们也可以使用-H进行指定：\n$ curl -F \'name=Dan\' -H \'Content-Type: multipart/magic\' https://example.com\n和-F构造一个multipart formpost请求。\n', '2022-01-20 14:10:27', NULL, 1),
(52, 'php 有关 isset()  、 ??  的判断解析', '\n### 先看几个示例\n```php\n$a = [\n    \'k\'=>1\n];\nvar_dump($a) ;\nvar_dump(isset($a)); //是否有$a 变量\nvar_dump(isset($a[\"k\"]));//是否有$a变量 且 k 键\nvar_dump($a[\'k\'] ??  \'no_k\');////是否有$a变量 且 k 键，没有k键则给默认值\n\n//运行结果\n/*\narray(1) {\n  [\"k\"]=>\n  int(1)\n}\nbool(true)\nbool(true)\nint(1)\n*/\n```', '2022-01-21 14:55:15', NULL, 1),
(53, 'Go 如何排查和定位GC问题', '### 设置gctrace的变量值为1即可\n这个既可以设置成环境变量，也可以选择按如下方式执行：\n```\nGODEBUG=gctrace=1  go run main.go\n//GODEBUG=gctrace=1 ./main\n```\n\nGODEBUG=gctrace=1 代表只针对这个进程开启gc追踪功能。程序输出如下：\n\n![img](https://static.oschina.net/uploads/space/2018/0119/160520_48bF_3470972.png)\n\n\n解释：gc 1 @0.038s 1%: 0.55+0.12+0.081 ms clock, 2.2+0/0.42/1.1+0.32 ms cpu, 4->4->0 MB, 5 MB goal, 4 P。\n\n- 1 表示第一次执行\n- @0.038s 表示程序执行的总时间\n- 1% 垃圾回收时间占用总的运行时间百分比\n- 0.018+1.3+0.076 ms clock 垃圾回收的时间，分别为STW（stop-the-world）清扫的时间, 并发标记和扫描的时间，STW标记的时间\n- 0.054+0.35/1.0/3.0+0.23 ms cpu 垃圾回收占用cpu时间\n- 4->4->3 MB 堆的大小，gc后堆的大小，存活堆的大小\n- 5 MB goal 整体堆的大小\n- 4 P 使用的处理器数量\n缺点：对什么地方耗用大量内存并造成大量延迟可能并不清除。\n\n### 使用pprof\n```\nimport (\n    \"net/http\"\n    _ \"net/http/pprof\"\n)\ngo func() {\n            log.Println(http.ListenAndServe(\"localhost:8081\", nil))\n}()\n```\n\n在程序启动之后，只需要在命令行或者浏览器输入以下命令即可：\n\n- go tool pprof  http://127.0.0.1:8081/debug/pprof/heap       //查看堆的使用，即内存使用情况\n- go tool pprof  http://127.0.0.1:8081/debug/pprof/profile    //查看cpu耗时，会详细列出每个函数的耗时\n- go tool pprof  http://127.0.0.1:8081/debug/pprof/goroutine  //当前在运行的goroutine情况以及总数\n\n示例：\n![img](https://static.oschina.net/uploads/space/2018/0119/163406_DM5W_3470972.png)\n', '2022-02-08 13:58:44', NULL, 1),
(54, 'golang 锁和 sync 包', '\n在 Go 语言中这种锁的机制是通过 **sync** 包中 Mutex 来实现的。\n\n经典的做法是一次只能让一个线程对共享变量进行操作。当变量被一个线程改变时（临界区），我们为它上锁，直到这个线程执行完成并解锁后，其他线程才能访问它。\n\n#### Mutex 是一个互斥锁\n只能有一个线程将有序的对同一变量进行访问\n```\nimport  \"sync\"\n\ntype Info struct {\n	mu sync.Mutex\n	// ... other fields, e.g.: Str string\n}\n```\n\n如果一个函数想要改变这个变量可以这样写\n```\nfunc Update(info *Info) {\n	info.mu.Lock()\n    // critical section:\n    info.Str = // new value\n    // end critical section\n    info.mu.Unlock()\n}\n```\n#### RWMutex 锁\n它能通过 RLock() 来允许同一时间多个线程对变量进行读操作，但是只能一个线程进行写操作。\n\n#### once.Do(call)\n这个方法确保被调用函数只能被调用一次。\n\n**注意**：相对简单的情况下，通过使用 sync 包可以解决同一时间只能一个线程访问变量或 map 类型数据的问题。如果这种方式导致程序明显变慢或者引起其他问题，我们要重新思考来通过 goroutines 和 channels 来解决问题', '2022-02-09 11:46:29', NULL, 1),
(55, 'golang 处理并发：加锁、通道方式', '### 加锁方式\n```\ntype Pool struct {\n    Mu      sync.Mutex\n    Tasks   []*Task\n}\n\nfunc Worker(pool *Pool) {\n    for {\n        pool.Mu.Lock()\n        // begin critical section:\n        task := pool.Tasks[0]        // take the first task\n        pool.Tasks = pool.Tasks[1:]  // update the pool of tasks\n        // end critical section\n        pool.Mu.Unlock()\n        process(task)\n    }\n}\n```\nsync.Mutex是互斥锁：它用来在代码中保护临界区资源：同一时间只有一个 go 协程（goroutine）可以进入该临界区\n\n这些 worker 有许多都可以并发执行；他们可以在 go 协程中启动。\n一个 worker 先将 pool 锁定，从 pool 获取第一项任务，再解锁和处理任务。\n加锁保证了同一时间只有一个 go 协程可以进入到 pool 中：一项任务有且只能被赋予一个 worker \n如果不加锁，则工作协程可能会在 task:=pool.Tasks[0] 发生切换，导致 pool.Tasks=pool.Tasks[1:] 结果异常：一些 worker 获取不到任务，而一些任务可能被多个 worker 得到。\n加锁实现同步的方式在工作协程比较少时可以工作得很好，但是当工作协程数量很大，任务量也很多时，处理效率将会因为频繁的加锁/解锁开销而降低。当工作协程数增加到一个阈值时，程序效率会急剧下降，这就成为了瓶颈。\n\n### 使用通道\n\n使用通道进行同步：使用一个通道接受需要处理的任务，一个通道接受处理完成的任务（及其结果）。worker 在协程中启动，其数量 N 应该根据任务数量进行调整。\n\n```\nfunc main() {\n        pending, done := make(chan *Task), make(chan *Task)\n        go sendWork(pending)       // put tasks with work on the channel\n        for i := 0; i < N; i++ {   // start N goroutines to do work\n            go Worker(pending, done)\n        }\n        consumeWork(done)          // continue with the processed tasks\n    }\n```\nworker 的逻辑比较简单：从 pending 通道拿任务，处理后将其放到done通道中：\n```\n    func Worker(in, out chan *Task) {\n        for {\n            t := <-in\n            process(t)\n            out <- t\n        }\n    }\n```\n这里并不使用锁：从通道得到新任务的过程没有任何竞争。\n一个 worker 从 pending 通道中获得第一个任务并进行处理，这里并不存在竞争（对一个通道读数据和写数据的整个过程是原子性的\n随着任务数量增加，worker 数量也应该相应增加，同时性能并不会像第一种方式那样下降明显。在 pending 通道中存在一份任务的拷贝', '2022-02-09 17:49:29', NULL, 1),
(56, 'Linux一些常用命令', '查看内容使用情况\n```\nfree\n\ntop\n```\n\n三种标准输入输出\n```\n标准输入（STDIN），文件描述符号为：0，默认从键盘获取输入；\n标准输出（STDOUT），文件描述符号为：1，默认输出到显示终端；\n标准错误输出（STDERR）,文件描述符号为：2，默认输出到显示终端；\n```\n\n如何重定向\n```\n\">\" # 使用本次输出内容替换原有文件的内容；\n\">>\"  把本次输出追加到原文件的后面；\n```\n\n常见的一些输出重定向（标准输出和标准错误输出）表示\n```\n【>】标准输出覆盖重定向\n【>>】标准输出追加重定向\n【2>】标准错误输出覆盖重定向\n【2>>】标准错误输出追加重定向\n【&>】将标准输出和标准错误输出都同时覆盖重定向\n【&>>】将标准输出和标准错误输出都同时追加重定向\n```\n\n&和&&、|和|| 区别、分号(;)用法\n```\n& 表示任务在后台执行；\n&& 逻辑与，只有前一条命令执行成功时，才执行后一条命令 ，如 echo \'1\' && echo \'2\'；\n| 表示管道，上一条命令的输出，作为下一条命令操作对象；\n|| 逻辑或，只有上一条命令执行失败后，才执行下一条命令；\n\";\" 用法方式：command1 ; command2，用 ; 号隔开每个命令，每个命令按照从左到右的顺序执行，彼此之间不关心是否失败， 所有命令都会执行。\n```\n\nnohup 后台启动进程命令\n\n```\nnohup 让某个进程在后台运行。\nnohup 英文全称 no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。\nnohup 命令，在默认情况下（非重定向时），会输出一个名叫 nohup.out 的文件到当前目录下，如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。\n```\n示例\n```\n# 以后台进程执行启动 grafana 命令，& 放在命令到结尾，表示后台运行\nnohup go run ./api > log.log 2>&1 &\n\n# 2>&1 解释：将标准错误输出(2 表示)重定向到标准输出(&1 表示) ，标准输出(&1) 再被重定向输入到 log.log 文件中。\n\n```\n\n#### 从文件中筛选内容存到新文件\n```\ntail -10000000 aaa.log |grep \"内容\" > ./tmp.txt\n```', '2022-02-11 10:14:03', '2022-02-16 10:17:08', 1),
(57, 'golang  锁-互斥锁：Mutex', '\n#### 互斥锁：同一个时刻只有一个线程能够拿到锁\n使用互斥锁（Mutex，全称 mutual exclusion）是为了来保护一个资源不会因为并发操作而引起冲突导致数据不准确。\n\n\n##### 示例：不加锁开3个携程计算count\n```golang\n\nfunc add(count *int, wg *sync.WaitGroup) {\n	for i := 0; i < 1000; i++ {\n		*count += 1\n	}\n	wg.Done()\n}\nfunc main() {\n	var wg sync.WaitGroup\n	var count int\n	wg.Add(3)\n	go add(&count, &wg)\n	go add(&count, &wg)\n	go add(&count, &wg)\n	wg.Wait()\n	fmt.Println(\"count 的值为：\", count)\n}\n```\n\n将出现计算不一致结果：2836   2955  3000 2644 \n\n\n原因就在于这三个协程在执行时，先读取 count 再更新 count 的值，而这个过程并不具备原子性，所以导致了数据的不准确。\n\n##### 解决\n就是给 add 这个函数加上 Mutex 互斥锁，要求同一时刻，仅能有一个协程能对 count 操作。\n\n```\nfunc add(count *int, wg *sync.WaitGroup, lock *sync.Mutex) {\n	for i := 0; i < 1000; i++ {\n		lock.Lock()\n		*count += 1\n		lock.Unlock()\n	}\n	wg.Done()\n}\nfunc main() {\n	var wg sync.WaitGroup\n	var count int\n	var lock  = &sync.Mutex{}\n	wg.Add(3)\n	go add(&count, &wg, lock)\n	go add(&count, &wg, lock)\n	go add(&count, &wg, lock)\n	wg.Wait()\n	fmt.Println(\"count 的值为：\", count)\n}\n```\n\n##### 优缺点\n\n使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁；\n当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的。\n##### 特别注意点\n- 不要重复锁定互斥锁 （panic）\n- 不要忘记解锁互斥锁， 必要时使用defer语句 （panic）\n- 不要对尚未锁定或者已解锁的互斥锁解锁 （panic）\n- 不要对在多个函数之间直接传递互斥锁\n- 对已经锁定的互斥锁进行锁定，会立即阻塞当前的goroutine ,这个goroutine所执行的流程会一直停滞在该调用互斥锁的Lock方法的那行代码', '2022-02-12 15:43:56', '2022-02-12 15:54:43', 1),
(58, 'go  锁-RWMutex', '#### 读写锁sync.RWMutex (针对于读写操作的互斥锁)\n##### 遵循两大原则\n- 可以随便读。多个goroutin同时读\n- 写的时候，啥都不能干。不能读，也不能写\n\n##### 包含4个方法\n- func (*RWMutex) Lock //写锁定\n- func (*RWMutex) Unlock //写解锁\n- func (*RWMutex) RLock //读锁定\n- func (*RWMutex) RUnlock //读解锁\n\n###### 示例\n```\nfunc main() {\n	lock := &sync.RWMutex{}\n	lock.Lock()\n	for i := 0; i < 4; i++ {\n		go func(i int) {\n			fmt.Printf(\"第 %d 个协程准备开始... \\n\", i)\n			lock.RLock()\n			fmt.Printf(\"第 %d 个协程获得读锁, sleep 1s 后，释放锁\\n\", i)\n			lock.RUnlock()\n		}(i)\n	}\n	lock.Unlock()\n	time.Sleep(time.Second * 2)\n}\n```\n\n##### 注意\n- 读锁不能阻塞读锁\n- 读锁需要阻塞写锁，直到所以读锁都释放\n- 写锁需要阻塞读锁，直到所以写锁都释放', '2022-02-12 16:11:09', NULL, 1),
(59, 'Golang  channel 练习', '#### channel练习\n\n1. 启动一个goroutine，生成100个随机数发送到ch1，启动一个goroutine，从ch1通道中读取值，然后计算其平方，放到ch2中， 在main中，从ch2取值打印出来\n```\nfunc main() {\n	chan1  := make(chan int)\n	chan2 := make(chan int)\n	go send(chan1)\n	go jisuan(chan1,chan2)\n	for ret := range chan2 {\n		fmt.Println(ret)\n	}\n}\nfunc send(c1 chan<- int)  {\n	for i:=0; i< 10; i++ {\n		c1 <- i\n	}\n	defer close(c1)\n}\nfunc jisuan(c1 <-chan int,c2 chan<- int)  {\n	for{\n		v,ok := <-c1\n		if !ok {\n			break\n		}\n		c2 <- v*v\n	}\n	defer  close(c2)\n}\n```\n\n2.并发控制\n```\nfunc handleEvent(done chan string, task chan bool) {\n	for i := 0; i < 10; i++ {\n		task <- true\n		go func(id int) {\n			fmt.Printf(\"处理事件 %v\\n\", id)\n			time.Sleep(time.Second * 1)\n			<-task\n			if id == 9 {\n				done <- \"done\"\n			}\n		}(i)\n	}\n}\nfunc main() {\n	done := make(chan string)\n	task := make(chan bool,2) //并法数控制为2\n	go handleEvent(done, task)\n	<-done\n	fmt.Println(\"任务完成\")\n}\n```', '2022-02-12 16:50:51', '2022-02-12 17:42:57', 1),
(60, 'Mysql 的 sql语句执行过程', '### Mysql的架构\n#### 客户端和服务端的连接 \n第一层作为客户端和服务端的连接，连接器负责处理和客户端的连接，还有一些权限认证之类。比如客户端通用用户名密码连接到Mysql服务器，还有对于数据库表的执行权限\n#### 核心层\nMysql大部分的核心功能都在这一层，包括查询缓存、解析器、优化器之类，比如SQL解析、优化、索引选择，到最后生成执行计划\n#### 存储引擎\nMysql通过执行引擎直接调用存储引擎API查询数据库中数据。\n\n#### SQL的大概的执行过程\n1.首先客户端发送请求到服务端，建立连接。\n\n2.服务端先看下查询缓存(5.7版本之后已弃用)是否命中，命中就直接返回，否则继续往下执行。\n\n3.接着来到解析器，进行语法分析，一些系统关键字校验，校验语法是否合规。\n\n4.然后优化器进行SQL优化，比如怎么选择索引之类，然后生成执行计划。\n\n5.最后执行引擎调用存储引擎API查询数据，返回结果。\n\n![img size](https://pic3.zhimg.com/80/v2-a28fac6872ae4753024161f199bdabbe_720w.jpg  =500x600)', '2022-02-14 10:30:39', '2022-02-14 10:31:20', 1),
(61, 'Go-micro 64位windows10 下安装protoc', '64位windows10 下安装protoc\n\n- 去这里https://github.com/google/protobuf/releases\n\n下载对应的protoc，我这里下的是protoc-3.14.0-win64.zip\n\n- 好之后解压就行，然后把bin里面的protoc.exe加入到环境变量，可以参考\n\n\n并且把protoc.exe拷贝到C:\\Windows\\System32', '2022-02-16 17:43:48', '2022-02-16 17:44:00', 1),
(62, 'Docker 常用命令', '**登录、退出仓库**\n```\n#登录\n#未指定镜像仓库地址，默认为官方仓库 Docker Hub\ndocker login -u 用户名 -p 密码 仓库名称\n\n#退出\ndocker logout registry.cn-hangzhou.aliyuncs.com\n```\n\n**镜像**\n```\n查看所有镜像\ndocker images\n\n拉取镜像(默认latest版本)\ndocker pull nginx\ndocker pull nginx:1.17\n\n查找镜像\ndocker search nginx\n\n删除镜像\ndocker rmi -f nginx\n\n```\n**容器**\n```\n查看正在运行的容器\ndocker ps\n\n显示运行容器总文件大小\ndocker ps -s\n\n\n查看docker容器版本\ndocker version\n查看docker容器信息\ndocker info\n\n查看redis容器日志，参数：-f  跟踪日志输出；-t   显示时间戳；--tail  仅列出最新N条容器日志；\ndocker logs -f -t --tail=20 redis\n\n使用run方式在创建时进入\ndocker run -it centos /bin/bash\n\n删除一个运行中的容器\ndocker rm -f redis\n-v 删除容器，并删除容器挂载的数据卷\ndocker rm -v redis\n\n杀掉一个运行中的容器\ndocker kill redis\n停止一个运行中的容器\ndocker stop redis\n将rabbitmq容器中的文件copy至本地路径\ndocker cp rabbitmq:/[container_path] [local_path]\n```\n\n**dockerfile构建镜像**\n```\n在dockerfile同级目录执行\ndocker build -t nginx:v3 .\n```', '2021-10-13 10:02:26', '2022-02-18 10:20:36', 1),
(63, 'Ubuntu  配置ssh', '```shell\n#设置root的口令（密码），用作后续登陆使用\nsudo passwd root\n\n#安装openssh-server（ubuntu自带已安装，但是我使用有问题，没找到原因）\nsudo apt remove openssh-server\nsudo apt install openssh-client openssh-server\n\n#备份原始的sshd_config\nsudo cp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak\nsudo cp /etc/ssh/ssh_config /etc/ssh/ssh_config.bak\n\n#使用vim进行编辑，按i进入insert模式\nsudo vim /etc/ssh/sshd_config\n\n在vim中找到对应项并修改，ESC，输入`wq`保存退出：\nPort 2222\nListenAddress 0.0.0.0        # 如果需要指定监听的IP则去除最左侧的井号，并配置对应IP，默认即监听PC所有IP\nPermitRootLogin no           # 如果你需要用 root 直接登录系统则此处改为 yes\nPasswordAuthentication yes    # 将 no 改为 yes 表示使用帐号密码方式登录\n\n#使用vim进行编辑，按i进入insert模式\nsudo vim /etc/ssh/sshd_config\n\n#在vim中找到对应项并修改，ESC，输入`wq`保存退出：\nPort 2222\nListenAddress 0.0.0.0        # 如果需要指定监听的IP则去除最左侧的井号，并配置对应IP，默认即监听PC所有IP\n\n#启动ssh，查看status\nsudo service ssh start             #启动SSH服务\nsudo service ssh status            #检查状态\nsudo systemctl enable ssh          #开机自动启动ssh命令，我好想失效了\n\n```', '2022-02-23 10:45:56', NULL, 1),
(64, '没有目标，没有爱好，该怎么办?', '这是知乎看到的一个问题，有时候我也会这么思考，但最终无疾而终，看到几个优质的回答后，便会有所力量\n\n\n作者：端坐青石上\n链接：https://www.zhihu.com/question/519017453/answer/2366893386\n\n看大家都说的挺多的挺全的，能点醒人的话不多。我就三点：\n一、很多人都多少会有点“读书无用论”的想法或者意识不到读书学知识的重要性，但他们没看透读了大学读了研究生的很多人为什么依然过得不好的原因，是因为不是知识不值钱，而是大家都会的知识没有太多价值，而此时，你不努把力把大家都会的知识都学到，那以后被筛选掉的人就是你。 \n二、等你工作几年时候你才能明白生活很累、一地鸡毛，身不由己没得选的事更是到处都是，就会发现导致恶果的恶因老早就被自己种下了，到时候你会经常怅惘自己“要是五年前我努力冲一把考个研究生混个学历.......，那我现在.......”、“要是九年前我努力学习考个好点的大学.....，那我现在.......”、“要是我十二年前努力学习考个好点的高中.....，那我现在.......”\n三、现在的懒惰、嫌麻烦，未来可能却要花数倍、十几倍的时间和精力去辛苦补。如果你迷茫，那你就去找个工地、电子厂啥的打工一两个月，感受一下什么叫辛苦和以后的“没得选”是什么样子。这个时刻，有的人10点钟已经安心入睡、有的人11点还在上夜班或者加班，有的人凌晨加完班打开了知乎看到你这个问题想说两句顺便怅惘自己，这就是我，那个被筛选掉的曾经不努力的人，唉。\n\n', '2022-02-28 09:38:02', NULL, 1),
(65, 'mysql 事务：ACID特性', '### 什么是事务\n事务( transaction) 是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消。\n\n### 事务的四大特性\n- 原子性(Atomicity)\n- 一致性(Consistency)\n- 隔离性(Isolation)\n- 持久性(Durability)\n\n### 原子性\n原子性是指一个事务是一个不可分割的工作单位，其中的操作要么都做，要么都不做。即要么执行成功，要么转账失败，是不存在中间的状态\n**实现原理：undo log**\n在说明原子性原理之前，首先介绍一下MySQL的事务日志。MySQL的日志有很多种，如二进制日志、错误日志、查询日志、慢查询日志等，此外InnoDB存储引擎还提供了两种事务日志：redo log(重做日志)和undo log(回滚日志)。其中redo log用于保证事务持久性；undo log则是事务原子性和隔离性实现的基础。\n\n下面说回undo log。实现原子性的关键，是当事务回滚时能够撤销所有已经成功执行的sql语句。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。\n\nundo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。\n\n以update操作为例：当事务执行update时，其生成的undo log中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到update之前的状态。\n\n### 隔离性\n根据定义，隔离性是指多个事务并发执行的时候，事务内部的操作与其他事务是隔离的，并发执行的各个事务之间不能互相干扰，在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务\n- (一个事务)写操作对(另一个事务)写操作的影响：锁机制保证隔离性\n- (一个事务)写操作对(另一个事务)读操作的影响：MVCC保证隔离性\n### 持久性\n事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存。或者这样理解：事务就是被绑定在一起作为一个逻辑工作单元的 SQL 语句分组，如果任何一个语句操作失败那么整个操作就被失败，以后操作就会回滚到操作前状态，或者是上有个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过 ACID 测试，即原子性，一致性，隔离性和持久性\n**实现原理：redo log**\nedo log和undo log都属于InnoDB的事务日志。\n\nredo log存在的背景：\n- InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）\n\n- Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证\n\n- 于是，redo log被引入来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求\n\n- 既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：\n	- 刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。\n	- 刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。\n\n### 一致性\n事务的执行使得数据库从一种正确状态转换成另一种正确状态\n\n特别参考：https://www.cnblogs.com/kismetv/p/10331633.html\n', '2022-02-28 14:26:58', '2022-02-28 14:36:06', 1),
(66, 'redis 分布式锁 实现方案', '### 什么是分布式锁\n分布式锁其实就是，控制分布式系统不同进程共同访问共享资源的一种锁的实现。如果不同的系统或同一个系统的不同主机之间共享了某个临界资源，往往需要互斥来防止彼此干扰，以保证一致性。特征：\n- 互斥性: 任意时刻，只有一个客户端能持有锁。\n- 锁超时释放：持有锁超时，可以释放，防止不必要的资源浪费，也可以防止死锁。\n- 可重入性: 一个线程如果获取了锁之后,可以再次对其请求加锁。\n- 高性能和高可用：加锁和解锁需要开销尽可能低，同时也要保证高可用，避免分布式锁失效。\n- 安全性：锁只能被持有的客户端删除，不能被其他客户端删除\n\n实现的7种方式\n- INCR\n- SETNX + EXPIRE\n- SETNX + value值是（系统时间+过期时间）\n- 使用Lua脚本(包含SETNX + EXPIRE两条指令)\n- SET的扩展命令（SET EX PX NX）\n- SET EX PX NX  + 校验唯一随机值,再释放锁\n- 开源框架~Redisson\n- 多机实现的分布式锁Redlock\n\n#### INCR（原子性）\nkey 不存在，那么 key 的值会先被初始化为 0 ，然后再执行 INCR 操作进行加一。\n然后其它用户在执行 INCR 操作进行加一时，如果返回的数大于 1 ，说明这个锁正在被使用当中\n\n#### SETNX（原子性） + EXPIRE\n- 先用setnx来抢锁，如果抢到之后，再用expire给锁设置一个过期时间，防止锁忘记了释放\n- setnx:如果 key不存在，则SETNX成功返回1，如果这个key已经存在了，则返回0。\n\n', '2021-09-16 14:59:04', '2022-02-28 15:05:26', 1),
(67, 'GO-micro  环境安装', '#### 新建目录\n```\nmkdir micro-1\n```\n\n#### 安装 go-micro\n```\ngo get go-micro.dev/v4\n```\n并设置：go env -w GO111MODULE=on\n\n#### 安装 go-micro plugins\n```\ngo get -u github.com/asim/go-micro/plugins/registry/consul/v4\n```\n\n#### 安装 protobuf\n\n到：https://github.com/protocolbuffers/protobuf/releases 下载环境的安装包文件\n然后安装，并添加到环境变量\n\n#### 安装 protoc-gen-go\n```\ngo get  github.com/golang/protobuf/protoc-gen-go\n#报错则执行下面这个\ngo install github.com/asim/go-micro/cmd/protoc-gen-micro/v4@latest\n```\n\n#### 创建测试文件:greeter.proto\n```\nsyntax = \"proto3\";\npackage Greeter;\noption go_package = \'./;pb\';\nservice Greeter {\n  rpc Hello(Request) returns (Response) {}\n}\n\nmessage Request {\n  string name = 1;\n}\n\nmessage Response {\n  string msg = 1;\n}\n```\n然后执行：\n```\nprotoc --micro_out=. --go_out=. greeter.proto\n```\n将会生成两个文件：greeter.pb.micro.go、greeter.pb.go则成功\n\n\n', '2022-03-21 15:52:22', '2022-03-21 15:53:11', 1),
(68, 'Mysql 数据恢复', '#### mysql误删数据快速恢复\n相信后端研发的同学在开发过程经常会遇到产品临时修改线上数据的需求，如果手法很稳那么很庆幸可以很快完成任务，很不幸某一天突然手一抖把表里的数据修改错误或者误删了，这个时候你会发现各种问题反馈接踵而来。如果身边有BDA或者有这方面经验的同事那么可以很快解决这个问题，如果没有那么希望这篇文章可以帮到你。\n#### 第一步：保证mysql已经开启binlog，查看命令：\n\n查看binklog是否开启\n```\nshow variables like \'%log_bin%\';\n```\n\n查看binlog存放日志文件目录：\n```\nshow variables like \'%datadir%\';\n```\n值为OFF，需开启，值为ON，已开启。\n\n如果没有开启binlog，也没有预先生成回滚SQL，那可能真的无法快速回滚了。对存放重要业务数据的MySQL，强烈建议开启binlog。\n\n#### 第二步：进入binlog文件目录，找出日志文件\n\n#### 第三步：切换到mysqlbinlog目录\n当线上数据出现错误的时候首先可以询问具体操作人记录时间点，这个时候可以借助mysql自带的binlog解析工具mysqlbinlog，具体位置在mysql安装目录**/mysql/bin/下\n\n#### 第四步：通过mysqlbinlog工具命令查看数据库增删改查记录（必须切换到mysqlbinlog目录才有效）\n\n例子1：查询2018-11-12 09:00:00到2018-11-13 20:00:00 数据库为 youxi 的操作日志，输入如下命令将数据写入到一个备用的txt文件中\n\n mysqlbinlog --no-defaults --database=youxi --start-datetime=\"2018-11-12 09:00:00\" --stop-datetime=\"2018-11-13 20:00:00\" /data/mysql/mysql-bin.000015    > template_coupon_tb_product_category.txt\n例子2：查询2018-11-12 09:00:00到2018-11-13 20:00:00 数据库为 youxi 的操作日志，并输出到屏幕上\n\nmysqlbinlog --no-defaults --database=youxi --start-datetime=\"2018-11-12 09:00:00\" --stop-datetime=\"2018-11-13 20:00:00\" /data/mysql/mysql-bin.000015   |more\n例子3：查询2018-11-12 09:00:00到2018-11-13 20:00:00 数据库为 youxi 的操作日志，并且过滤出 只包括 template_coupon_tb_product_category 表数据的操作记录 ，输入如下命令将数据写入到一个备用的txt文件中\n\nmysqlbinlog --no-defaults --database=youxi --start-datetime=\"2018-11-12 09:00:00\" --stop-datetime=\"2018-11-13 20:00:00\" /data/mysql/mysql-bin.000015   | grep template_coupon_tb_product_category   > template_coupon_tb_product_category.txt\n\n\n#### 复制代码\nmysqlbinlog 命令的语法格式：\nmysqlbinlog mysql-bin.0000xx | mysql -u用户名 -p密码 数据库名\n\n\n常用参数选项解释：\n--start-position=875 起始pos点\n--stop-position=954 结束pos点\n--start-datetime=\"2016-9-25 22:01:08\" 起始时间点\n--stop-datetime=\"2019-9-25 22:09:46\" 结束时间点\n--database=zyyshop 指定只恢复zyyshop数据库(一台主机上往往有多个数据库，只限本地log日志)\n\n不常用选项： \n-u --user=name 连接到远程主机的用户名\n-p --password[=name] 连接到远程主机的密码\n-h --host=name 从远程主机上获取binlog日志\n--read-from-remote-server 从某个MySQL服务器上读取binlog日志\n复制代码\n第五步：利用第四步输出的sql语句或者txt文本进行语句过滤，重新插入数据或更新数据', '2022-03-22 11:35:28', NULL, 1),
(69, 'Docker 创建容器', '### mysql容器\n```\ndocker run -it -p 3306:3306\n--restart=always \n--name mysql-test\n-v /usr/local/mysql/conf:/etc/mysql\n-v /usr/local/mysql/my.cnf:/etc/mysql/my.cnf \n-v /usr/local/mysql/logs:/var/log/mysql \n-v /usr/local/mysql/data:/var/lib/mysql \n-e MYSQL_ROOT_PASSWORD=root\n-d mysql:5.7\n\n```', '2022-03-28 21:25:05', NULL, 1),
(70, 'PHP-FPM 进程模型', '#### 介绍\n注意：PHP 默认单进程模式，FPM、CLI 都是默认单进程。\nPHP-FPM 采用的是 **Master/Worker** 进程模型。\n当 PHP-FPM 启动时，会读取配置文件，然后创建一个Master进程和若干个Worker进程（具体是几个Worker进程是由php-fpm.conf中配置的个数决定），Worker进程是由Master进程fork出来的。\n\n#### Master进程和Worker进程的作用\n- Master进程：负责管理Worker进程、监听端口\n- Worker进程：处理业务逻辑\n\n#### PHP-FPM进程管理方式有动态（Dynamic）、静态（Static）、按需（Ondemand）三种\n\n**动态（Dynamic）**\nPHP-FPM启动时会创建一定数量的Worker进程。当请求数逐渐增大时，会动态增加Worker进程的数量；当请求数降下来时，会销毁刚才动态创建出来的Worker进程。\n在这种方式下，如果配置的最大进程数过大，当请求量增加时会出现大量Worker进程，进程之间会频繁切换，浪费大量CPU资源。 下面的三个参数可以配置Worker进程的数量： \npm.start_servers：动态方式下的起始php-fpm进程数量\npm.min_spare_servers：动态方式下的最小php-fpm进程数量 \npm.max_spare_servers：动态方式下的最大php-fpm进程数量\n\n**静态（Static**\nPHP-FPM启动时会创建配置文件中指定数量的Worker进程，不会根据请求数量的多少而增加减少。因为PHP-FPM开启的每个Worker进程同一时间只能处理一个请求，所以在这种方式下当请求增大的时候，将会出现等待的情形，用参数pm.max_children可以配置Worker进程的数量\n\n**按需（Ondemand）**\nPHP-FPM启动时，不会创建Worker进程，当请求到达的时候Master进程才会fork出子进程。在这种模式下，如果请求量比较大，Master进程会非常繁忙，会占用大量CPU时间。所以这种模式不适合大流量的环境。\n\n\n#### Nginx+PHP-FPM的架构中，Web服务器与PHP-FPM通信的过程\n当用户请求一个http地址时，Nginx会收到请求，然后将请求转发给PHP-FPM，PHP-FPM收到请求后会将请求转发给一个空闲的Worker进程。当Worker进程处理完后会将结果返回给Nginx，Ngixn再讲内容返回给用户。\n', '2021-10-19 21:44:53', '2022-03-28 22:09:23', 1),
(71, 'Mysql 四种事务隔离级', '### 四种隔离级别\n- 未提交读(Read Uncommitted)：允许脏读，也就是可能读取到其他会话中未提交事务修改的数据\n- 提交读(Read Committed)：只能读取到已经提交的数据。Oracle等多数数据库默认都是该级别 (不重复读)\n- 可重复读(Repeated Read)：可重复读。在同一个事务内的查询都是事务开始时刻一致的，**InnoDB默认级别**。在SQL标准中，该隔离级别消除了不可重复读，但是还存在幻象读\n- 串行读(Serializable)：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞\n\n### 未提交读 （Read Uncommitted）\n脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。\n\n###  提交读（Read Committed）\n指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。\n\n### 可重复读（Repeatable Read）\n这是MySQL的InnoDB默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。\n\n### 串行化（Serializable）\n这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争\n', '2019-11-29 16:03:52', '2022-03-29 16:04:16', 1),
(72, 'Dokcer 搭建 Mqtt服务', '### 创建容器\n```\ndocker pull registry.cn-hangzhou.aliyuncs.com/synbop/emqttd:2.3.6\ndocker run --name emq -p 18083:18083 -p 1883:1883 -p 8084:8084 -p 8883:8883 -p 8083:8083 -d registry.cn-hangzhou.aliyuncs.com/synbop/emqttd:2.3.6\n```\n### 进入emq容器\n```\n docker exec -it emq /bin/sh\n```\n### 关闭匿名认证(默认是开启的谁都能够登录)\n```\nvi /opt/emqttd/etc/emq.conf\n\nallow_anonymous = false\n```\n### 设置账号密码连接验证\n```\nvim emqx_auth_username.conf\n\nauth.user.4.username = test1\nauth.user.4.password = test1_pass\n\n```\n\n然后打开：ip:18083 ,点击插件，打开EMQX代理服务器，然后开启插件运行\n\n\n### 订阅通配符规则\n\n##### 主题层级\n\n譬如在上文的例子中：\n\n    订阅：/sys/device/8685754894158765/ctrl\n    上报：/sys/device/8685754894158765/reply\n\n每一个 / 都是分隔符，用来分割主题的每一层级，以订阅的主题为例，它就被分割成了4个层级：\n\n    /sys/device/8685754894158765/ctrl\n    层级1. sys\n    层级2. device\n    层级3. 8685754894158765\n    层级4. ctrl\n\n\n\n\n##### 多层通配符 是可以匹配主题中任意层级次数的通配符。\n比如，如果你订阅了 /sys/device/#，那么，你可以接收到以下这些主题的消息：\n\n    /sys/device\n    /sys/device/8685754894158765/reply\n    /sys/device/8685754894158766/reply\n    /sys/device/8685754894158767/reply\n    /sys/device/abce/efg/h/ijkl\n    ...\n\n通过示例我们可以看出，#可以匹配大于等于0的层级。\n服务端使用通配符 # 订阅主题。设备上报数据，服务端收到数据后，再根据设备的上报的真实主题 和 payload 进行处理。\n\n##### 单层通配符+\n\n+只可匹配主题的某一层级。\n\n比如，如果你订阅了 /sys/device/+，那么，你可以接收到以下这些主题的消息：\n\n    /sys/device/8685754894158765\n    /sys/device/8685754894158766\n    /sys/device/8685754894158767\n    /sys/device/abce\n    ...\n\n但是不能收到如下主题的消息：\n\n    /sys/device/8685754894158767/reply\n    /sys/device/abce/efg/h/ijkl\n    /sys/device\n\n因为他们都超过了 + 1层级的要求。需要注意的是，/sys/device因为是0层级，所以也不符合要求，无法收到数据。', '2022-04-14 11:58:33', '2022-04-14 13:23:15', 1),
(73, '结果体、Json互转', '### 结构体转Json\n\n```\ntype commonStruct struct {\n	ResponseType string\n	RequestType string\n	ID string\n	Timestamp int64\n}\n\n\nm := &commonStruct{\n	ResponseType: \"device_info\",\n	ID:           \"12379231343\",\n	Timestamp:  gtime.Timestamp(),\n}\nbyte,err:= json.Marshal(m)\nif err != nil {\n	fmt.Print(err.Error())\n	return\n}\n\nval := string(byte)\n\n```\n### Json转结构体\n```\ntype commonStruct struct {\n	ResponseType string\n	RequestType string\n	ID string\n	Timestamp int64\n}\nvar d commonStruct\nerr := json.Unmarshal([]byte(payload), &d)\nif err != nil {\n	fmt.Println(\"unmarshal failed!\")\n	return\n}\nfmt.Println(\"unmarshal result:\", d)\n\n```\n\n', '2022-04-18 13:15:27', '2022-04-18 13:20:53', 1),
(74, 'nginx 配置 域名 转发静态端口页面', '目的：将  Emq（端口18083） 面板用xxx.cn去访问\n这里用域名去代理访问，配置如下\n```\nserver{\n	listen 80;\n	listen 443 ssl;\n	#填写域名\n	server_name xxx.cn www.xxx.cn;\n\n	#填写绑定证书的域名\n	ssl_certificate /cert/xxx.cn.crt;\n	#私钥文件名称\n	ssl_certificate_key /cert/xxx.cn.key;\n	ssl_session_timeout 5m;\n	#请按照以下协议配置\n	ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n	#请按照以下套件配置，配置加密套件，写法遵循 openssl 标准\n	ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:HIGH:!aNULL:!MD5:!RC4:!DHE;\n	ssl_prefer_server_ciphers on;\n	\n	#添加跨域配置\n	add_header Access-Control-Allow-Origin *;\n	add_header Access-Control-Allow-Methods POST,GET, OPTIONS;\n	add_header Access-Control-Allow-Headers Authorization;\n	#转发配置\n	location / {\n		proxy_set_header Host $host:$server_port;\n		proxy_set_header X-Real-IP $remote_addr;\n		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n		#这里转发到 emq 面板的 18083端口\n		proxy_pass http: //127.0.0.1:18083/;\n	}\n}\n```', '2022-04-20 11:28:22', '2022-04-20 11:28:41', 1),
(75, 'supervisor命令说明', '\n### 常用命令\n```\nsupervisorctl status 查看所有进程状态\nsupervisorctl start xx\nsupervisorctl restart xx\nsupervisorctl upload xx 配置修改后重新加载配置\n```', '2022-04-24 14:42:28', NULL, 1),
(77, 'win10源码安装 Django 报错 [Errno 13] Permission denied', '#### 当执行命令：python setup.py install ，在win10环境源码安装Django时报错如下\n```\n\nThe following error occurred while trying to add or remove files in the\ninstallation directory:\n\n    [Errno 13] Permission denied: \'C:\\\\Program Files\\\\Python39\\\\Lib\\\\site-packages\\\\test-easy-install-13132.write-test\'\n...\n....\n...\n```\n#### 解决方式\n去导报错提示出来的目录：C:\\\\Program Files\\\\Python39\\\\Lib\\\\site-packages\\\\test-easy-install-13132.write-test ，点击属性，修改当前用户的操作权限为为所有控制权（属性-安全-高级-所有控制权）\n\n或者：\n将当前执行命令的目录的权限设置为所有控制权', '2022-04-24 21:46:39', '2022-04-25 20:53:19', 1),
(78, 'Golang 报错：err is shadowed during return', '报错提示如题，其原因是由于作用域导致，从而允许通过\n', '2022-04-27 11:21:21', NULL, 1),
(79, 'docker 部署golang 服务、vue前端项目', '### 项目背景\n- go提供api服务、vue 前端 \n- 独立nginx容器、api服务容器\n\n#### 打包go linux 可执行文件\n```\nset GOARCH=amd64\nset GOOS=linux\ngo build -o api_server main.go\n```\n#### 打包vue前端\n```\nnpm run build \n```\n\n#### 进入linux服务器\n##### 项目文件全部放在 /webapp/demo/目录下，目录结构如下：\n\n- /webapp/demo  \n 	- dist\n	- api_server\n	- config.yaml \n\n##### 创建 Dockerfile 文件，内容如下:\n```\nFROM alpine:latest\nMAINTAINER xxx\nENV TZ=Asia/Shanghai\n#设置时区\n#这一行是个大坑，查了很多办法都不生效，各种方式都用上了，时区还是无法生效，所以直接不要这句\n# RUN ln -snf /usr/shar/zoneinfo/$TZ /etc/localtime && echo \'$TZ\' > /etc/timezone\n#解决办法就是在docker-compose.yaml文件里面去解决，通过映射主机目录的方式使容器时区跟主机时区保持一致\n\nWORKDIR /app\nVOLUME [\"/app\"]\nCOPY ./api_server /app/api_server\nCOPY ./config.yaml /app/config.yaml\nEXPOSE 8100\nENTRYPOINT [\"/app/api_server\"]\n```\n##### build 服务镜像\n```\ndocker build -t go_api_server:v1 .\n```\n##### 创建 nginx 当前项目宿主机配置目录\n```\nmkdir -p nginx/conf.d\n```\n进入conf.d文件夹下面，copy一份nginx 默认配置到当前目录，文件名为default.conf\n##### 在项目目录/webapp/dome 下创建docker-compose.yaml 文件,内容如下：\n```\nversion: \"3.1\"\nservices:\n	web_demo_nginx:\n		container_anme: web_demo_ng\n		image: nginx:latest\n		ports:\n			- \"8101:80\"\n		volumes:\n			- /webapp/demo/nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf\n			- /webapp/demo/dist:/usr/share/nginx/html\n		restart: always\n	web_demo_api_server:\n		container_name: web_demo_api\n		image: go_api_server:v1\n		volumes::\n			- /etc/timezone:/etc/timezone\n			- /etc/localtime:/etc/localtime\n			- /usr/share/zoneinfo/Asia/:/usr/share/zoneinfo/Asia/\n		ports:\n			- \"8100:8100\"\n```\n##### 在/webapp/demo启动服务\n执行命令:docker-composer up\n访问前端：ip:8101\n\n\n\n', '2022-05-11 09:51:59', '2022-05-23 11:40:44', 1),
(80, 'Pyhton Django 搭建本地开发环境', '## 环境准备\n - win11\n - python 3.10\n - Django 4.4\n \n## 开发流程\n启动项目服务（项目根目录执行: python  manage.py runserver ）\n或者：python  manage.py runserver 127.0.0.1：7878\n\n#### 创建django项目\n```\ndjango-admin startapp mysite\n\n```\n#### 数据库迁移\n将会生成 model 文件内容\n```\npython manage.py makemigrations\npython manage.py migrate\n```\n\n##### 创建polls应用\n进入mysite项目根目录下\n```\npython manage.py startapp polls\n```\n\n##### 添加polls项目到mysite\n\n在 mysite/settings.py 中找到 INSTALLED_APPS ，将 polls 添加到最后\n```\nINSTALLED_APPS = [\n    \'polls.apps.PollsConfig\',\n    \'django.contrib.admin\',\n    \'django.contrib.auth\',\n    \'django.contrib.contenttypes\',\n    \'django.contrib.sessions\',\n    \'django.contrib.messages\',\n    \'django.contrib.staticfiles\',\n    \'polls\',\n]\n```\n\n## 配置 mysql\n\n- 安装第三方包:pymysql\n\n#### 在 mysite/__init_.py 中添加\n```\nimport pymysql\npymysql install_as_MySQLdb()\n\n```\n#### 在 mysite/settings.py 中找到 DATABASE ，修改如下:\n```\nDATABASES = {\n    \'default\': {\n        \'ENGINE\': \'django.db.backends.mysql\',\n        #数据库的名字\n        \'NAME\': \'ttsx\',\n        #数据库地址\n        \'HOST\': \'localhost\',\n        #端口\n        \'PORT\': \'3306\',\n        #用户名\n        \'USER\': \'root\',\n        #密码\n        \"PASSWORD\": \'123456\',\n    }\n}\n```\n#### 数据库迁移\n将会生成 model 文件内容\n```\npython manage.py makemigrations polls\npython manage.py migrate polls\n```\n\n**如果发现表没有生成**：\n- 删除 表 django_migrations 中 polls 的最新一次迁移记录\n- 重新执行 polls 的数据库迁移记录\n\n\n## django-admin \n\n#### 设置中文 和 时区\n在 mysite/setting.py 中设置\n```\nLANGUAGE_CODE = \'zh-Hans\'\nTIME_ZONE = \'Asia/Shanghai\'\n```\n', '2022-05-25 16:51:13', NULL, 1),
(81, 'Pycharm 设置项目虚拟环境', '## 环境\n- win11\n- pycharm\n\n\n当在 pycharm 上面设置好虚拟环境后，点击  terminal 之后发现报错：\n```\n提示：无法执行 项目目录 ./venv/scripts/activate 这个文件\n```\n解决如下:\n```\n# win + r 然后输入: \npowershell\n\n# 进入后， 输入以下命令从普通模式转至管理员模式\nStart-Process powershell -Verb runAs \n\n# 查看权限\nGet-ExecutionPolicy -List\n\n# 打开权限，输入以下命令后 输入y 同意\nset-executionpolicy remotesigned\n```\n\n**完成以上命令后**，回到pycharm的 重新打开 terminal ,若前面出现（venv）即成功', '2022-05-26 10:47:33', NULL, 1),
(82, 'netapp进行内网穿透', '## 使用netapp进行内网穿透\n\n场景：本地开发的服务给外网访问\n\nhttps://natapp.cn/  官网下载（看文档教程）\n\n\nwindows下：     ./natapp -authtoken=9ab6b9040a624f40\n\n在Linux/Mac 下：   natapp -authtoken=9ab6b9040a624f40\n\n    \n    \n\n   ', '2022-05-31 23:19:47', NULL, 1),
(83, '前端使用 node 开启 http serverf 服务 进行接口对接', '## 环境要求\n- node \n\n## 步骤\n#### 新建一个server.js ,然后输入以下内容：\n```\nvar http = require(\'http\')\nvar querystring = require(\'querystring\')\nhttp.createServer(function(request, response) {\n  response.setHeader(\'Access-Control-Allow-Origin\', \'*\')\n  // 允许的header类型\n  response.setHeader(\'Access-Control-Allow-Headers\', \'content-type\')\n  // 跨域允许的请求方式\n  response.setHeader(\'Access-Control-Allow-Methods\', \'DELETE,PUT,POST,GET,OPTIONS\')\n  const url = request.url\n  let data = {}\n\n  // 2.注册data事件接收数据（每当收到一段表单提交的数据，该方法会执行一次）\n  request.on(\'data\', function(chunk) {\n    data += chunk\n  })\n\n  request.on(\'end\', function() {\n    data = decodeURI(data)\n    console.log(data)\n    var dataObject = querystring.parse(data)\n    console.log(dataObject)\n  })\n\n  console.log(\'请求url->\' + request.url)\n  if (url === \'/admin/user/login\') {\n    data = userLoginAPi()//此处就是接口返回的数据\n  }\n\n  // 内容类型: text/plain\n  response.writeHead(200,\n    { \'Content-Type\': \'application/json; charset=UTF-8\' })\n  // 发送响应数据\n  response.end(JSON.stringify({\n    code: 20000,\n    msg: true,\n    data: data\n  }))\n}).listen(1002)\n\nfunction userLoginAPi() {\n  return {\n    user_id: 1\n  }\n}\n\n```\n\n#### 开启服务，直接执行:node server.js\n前端通过：127.0.0.1：1002 带上路由请求接口，即可返回数据进行模拟开发对接后端', '2022-06-02 09:29:47', '2022-06-06 19:31:01', 1),
(85, '人民日报：停止精神内耗的9个好习惯', '# 知乎上有个问题：“一个人活得很累的根源是什么？”\n\n#### 高赞回答说：\n\n不是能力问题，不是外貌问题，而是没能处理好与自己的关系。\n\n确实，很多时候，人之所以感到痛苦，不在于事情本身，而在于我们内心的冲突。\n\n对一件事过于敏感，任何一点风吹草动，都会激起情绪上的波澜。\n#### 久而久之，不仅对自己越来越不自信，甚至对生活也产生了百无聊赖的感受\n\n有时，一天下来，即便什么也没做，也会觉得好累好累。\n\n其实，这些都代表着一种严重的内耗型人格。\n\n内耗的过程，就像是用一把勺子，慢慢将自己掏空。\n\n想要摆脱内耗，让生活回归活力和热忱，人民日报推荐的这九个方法。\n\n## 停止活在他人眼里\n叔本华说：“人性有一个最特别的弱点，就是在意别人如何看待自己。”生活中，很多人之所以不快乐，就是因为太在乎周围人的反应。\n同事无意间的一个眼神，会让心情失落许久；朋友不经意的一句话，会默默纠结半天。\n太过在意别人的看法和评价，后果往往是，在敏感和讨好中委屈了自己。\n你要明白，生活说到底，是取悦自己的过程。那些发生在自己身上99%的事情，都与别人无关。\n真正需要在意的，不是周围人的眼光，而是自己内心的感受。\n学会放下对别人的关注和期待，把时间和爱留给自己。\n当你学会将生活的重心转移到自己身上，你才能活出最闪耀的人生。\n\n## 停止后悔\n一时的反思可以推动我们进步，长久的懊悔只会令我们步履维艰。\n你要相信，人生没有白走的路。\n昨日失去的，明日必以另一种方式补偿你。\n与其沉湎于不能改变的过去，不如坦然放下。\n毕竟，我们无从改变过往的遗憾，却可以决定未来能不能不要留下遗憾。\n\n## 停止苛求完美\n因为这个世界，不可能什么事情都如你所愿。\n《道德经》中说：“大成若缺，其用不弊。”\n圆满的事物好像有所欠缺，但它的作用不会衰竭。\n与其在苛求完美的路上让自己精疲力竭，不如放松下来，给生活留一点缺口。\n保留那份遗憾，人生也许不够完美，但是却变得更加完整。\n\n## 停止思虑过度\n很多事就是这样，本来没什么，就是因为想太多，才让一切变得复杂。\n常言道：“有心者有所累，无心者无所谓。”\n人生的幸福，有时候就在于放空。\n不要思虑过多，更不要自寻烦恼。\n当你用一颗简单的心去看待世界，你才能在纷繁人世中享受到岁月静好的幸福。\n\n## 停止陷入消极\n有句话说：“事情压不垮人，但面对事情的态度可以。\n”乐观的人，总能以从容和满怀希望的步履轻松走过岁月而消极的人，却总是陷入失败和困惑的阴影里。\n比如，表白被拒了，就觉得此生注定孤独； 比如，一次没考好，就觉得以后都前途灰暗。\n小问题造成了负面的情绪，负面的情绪又进一步放大了问题。\n最后一点小事，都变成了一场灾难。\n真正优秀的人，不是遇不到困难。而\n是在困难来临时，不会将自己置身于颓废和悲观的情绪之中。\n因为他们明白，一味沉溺于负面的情绪，也改变不了现状。\n与其在闷闷不乐中，让事情越变越糟，不如用更加积极的心态去面对风风雨雨。\n保持微笑，凡事看淡，好运才会与你不期而遇。\n\n## 停止反复犹豫\n\n犹犹豫豫到最后，常常发现自己什么也没有做成。\n作家脱不花曾说：人生总有很多左右为难的事。如果你在做与不做之间纠结，那么，不要反复推演，立即去做。\n所谓三思后行，如果只停留在“三思”，所有美好的愿景都会沦为遗憾。\n放弃脑海中左右摇摆的想法，扔掉心里徘徊不定的计划。\n趁着年轻，趁着还有梦，大胆地去追逐，放肆地去折腾。很多事情，你不果断尝试，永远都不会知道结果会是怎样。\n成也好，败也罢，只要你勇敢地迈出了第一步，相信一定能收获意想不到的惊喜。\n\n## 停止自我攻击\n\n内耗的一个重大原因，就是无法接纳自己，进而自我攻击。\n当你不满意自己，对自己挑三拣四时，你就注定很难得到快乐。\n人活在世上，最难也最重要的课程，就是和自己和解。\n或许你不善言辞，但是你有着出色的行动力，能代替一切花言巧语；或许你能力一般，但是你一直勤勤恳恳，让家人得以衣食无忧；或许你普普通通，但是你有着良好的品行，足以得到大家的喜爱和尊重。\n所以，从今天起，不要再自我贬低。\n学会相信自己，欣赏自己，看到自己身上的闪光点。\n只有你拥抱自己，世界才会敞开怀抱接纳你。\n\n## 停止拖延\n\n拖延是一片雪花到雪崩的积累，长久拖延只会让我们陷入焦虑和紧张的情绪之中。\n打败拖延也很简单，只需要记住两个字：行动。\n今日事，今日毕，永远不要把问题拖到明天再处理。\n当你培养了自己的行动力，那些让你不安和烦躁的问题，就会逐一消解。也只有行动起来，那些美好的愿景才不会成为口头的臆想。\n你所渴望的改变，需要从现在开始改变。\n不拖延、不等待、不逃避，想要的生活才会奔你而来。\n杨绛先生说：人虽然渺小，人生虽然短，但是人能学，人能修身，人能自我完善，人的可贵在于人的本身。\n任何时候，我们都是自己精神内耗的制造者，也是唯一的终结者。\n告别内耗，是一场自己和自己的战斗。\n当你克服了内心的障碍，你会见到别样的风景，领略到不一样的人生\n\n\n\n\n\n\n\n\n\n', '2022-06-08 09:26:26', NULL, 1),
(86, 'go  win11环境 交叉编译 Linux可执行文件无法执行问题', '## 环境\n- win11\n- go 1.18\n- goland 2022.2\n\n## 目标\n打包 go 项目到linux 环境执行\n##操作\n```\nset GOARCH=amd64\nset GOOS=linux\ngo build -o main main.go\n\n```\n## 问题\n可成功 go build .\n但是Linux 环境 chmod +x main  之后一直无法执行\n\n在win10系统可以，有人说是win系统问题，有的说是goland问题，具体不知道怎么造成的\n## 排除思路\n在 Linux 环境查看可执行文件格式\n```\nfile main\n```\n可以发现其文件格式是 For  MS Windows\n则是由于打包的命令：set GOOS=linux 不生效\n\n## 解决\n通过 git bash 打开项目目录通过以下方式打包\n```\nexprot GOARCH=amd64\nexport GOOS=linux\ngo build -o main main.go\n```', '2022-06-09 18:40:31', NULL, 1),
(87, 'python 多线程环形数组遍历', '### 从 2个 环形队列 循环打印 ml 数组，实现：2个环形数组输出：10->20->30->40->10 ...\n代码如下\n```python\nimport threading\nimport time\n\n# 所有线程容器\nall_list = {}\n# 多个环形数组\nids = [1,2]\ndef start(id: int):\n    #测试取值数组\n    ml = [\"10\", \"20\", \"30\", \"40\"]\n    timer_v = threading.Timer(2, start, [id])\n    timer_v.start()\n    # 默认从第一个开始\n    k = 0\n    if id in all_list.keys():\n        dd = all_list[id]\n        # 如果小于循环列表长度，则取下一个\n        if dd[\"k\"] < len(ml) - 1:\n            k = dd[\"k\"]+ 1\n    \n    all_list[id] = {\n        \'id\':id,\n        \"k\": k,\n        \"t\": timer_v,\n    }\n    print(all_list[id])\n    # print(id,v,all_list)\n\nif __name__ == \'__main__\':\n    for id in ids:\n        start(id)\n    time.sleep(4)\n    # 取消一个测试\n    all_list[1][\"t\"].cancel()\n```\n\n\n', '2023-01-15 07:45:01', '2023-01-15 10:46:40', 1),
(88, 'python 多线程mqtt客户端', '```python\nimport threading\nimport time\nimport paho.mqtt.client as mqtt\n\n\n# mqtt 服务资源列表\nmqtt_server_list = {}\nmqtt_server_list_lock = threading.Lock()\n\n# mqtt 线程资源列表\nthreading_list = {}\nthreading_list_lock = threading.Lock()\n\ndef handle_add_mqtt_server(params):\n    t = threading.Thread(target=mqttReprotServer, args=(\n        params[\'id\'],\n        params[\'session_quality\'],\n        params[\'ip\'],\n        params[\'port\'],\n        params[\'broker\'],\n        params[\'user\'],\n        params[\'pass\'],\n        params[\'client_id\'],\n        params[\'subscribe_topic\'],\n        params[\'publicsh_topic\'],\n    ))\n    t.start()\n\n    global threading_list\n\n    threading_list_lock.acquire()\n    threading_list[params[\"id\"]] = t\n    threading_list_lock.release()\n\n\n# 检查 mqtt 的状态\ndef check_mqtt_status(**params):\n    global mqtt_server_list\n    key = params[\"id\"]\n    if key not in mqtt_server_list.keys():\n        return False\n    return mqtt_server_list[key].is_connect()\n\n\n# 退出 mqtt 并kill mqtt线程\ndef close_mqtt_con(id):\n    global mqtt_server_list\n    global threading_list\n\n    key = id\n    # 判断 mqtt 服务是否在\n    if key not in mqtt_server_list.keys():\n        return False\n    mqtt_server_list_lock.acquire()\n    mqtt_server_list[key].is_end = True\n    mqtt_server_list[key].release()\n\n    threading_list_lock.acquire()\n    del threading_list[key]\n    threading_list_lock.release()\n\n    mqtt_server_list_lock.acquire()\n    del mqtt_server_list[key]\n    mqtt_server_list_lock.release()\n    return True\n\n\n# mqtt  服务\nclass mqttReprotServer:\n    is_end = False\n    host = None\n    port = None\n    broker = None\n    userName = None\n    password = None\n    clientID = None\n    mqttClient = None\n    pushTopic = None\n    subTopic = None\n    qos = 0\n\n    def __init__(self, id, qos, host, port, broker, userName, password, clientID, subTopic, pushTopic):\n        try:\n            self.qos = qos\n            self.host = host\n            self.port = port\n            if broker is not None:\n                self.broker = broker\n            self.userName = userName\n            self.password = password\n            self.clientID = clientID\n            self.mqttClient = mqtt.Client(clientID)\n            self.on_mqtt_connect()\n            self.subTopic = subTopic\n            self.on_subscribe(subTopic, qos)\n            self.pushTopic = pushTopic\n            self.reportTime = int(time.time())\n\n            # 加锁\n            global mqtt_server_list\n            mqtt_server_list_lock.acquire()\n            # 储存 mqtt 服务\n            mqtt_server_list[id] = self\n            mqtt_server_list_lock.release()\n\n            print(\"mqtt service is starting\")\n            while True:\n                if self.is_end:\n                    self.on_close_con()\n                    break\n                if self.mqttClient.is_connected():\n                    time.sleep(5)\n                pass\n\n        except Exception as exc:\n            print(2222222, str(exc))\n\n    # 连接MQTT服务器\n    def on_mqtt_connect(self):\n        if self.userName and self.password:\n            self.mqttClient.username_pw_set(self.userName, self.password)\n        self.mqttClient.connect(self.host)\n        self.mqttClient.loop_start()\n\n    # subscribe 消息订阅\n    def on_subscribe(self, topic, qos):\n        self.mqttClient.subscribe(topic, qos)\n        self.mqttClient.on_message = self.on_message_come  # 消息到来处理函数\n\n    # publish 消息发布\n    def on_publish(self, topic, msg, qos):\n        print(\"on_publish2 befor mqtt is connect-->\", self.mqttClient.is_connected())\n        self.mqttClient.publish(topic, msg, qos)\n\n    #  TODO 消息处理函数\n    def on_message_come(self, client, b, msg):\n        print(\"accest  ----》\", msg.topic + \":\" + str(msg.payload.decode(\"utf-8\")))\n        # data = json.loads(msg.payload.decode(\"utf-8\"))\n\n    def is_connect(self):\n        return self.mqttClient.is_connected()\n\n    # 断开\n    def on_close_con(self):\n        self.mqttClient.disconnect()\n\n\n\n```\n', '2022-10-04 16:50:16', '2022-10-04 16:52:16', 1),
(89, 'python多线程写入文件（定期、定行重置）', '```python\n\nimport rpc_config_interface as consts\nimport json\nimport threading\nimport multiprocessing\nimport time\n\n# 间隔x时间 或 行数超过y行清空\n# 储存最近时间 - 储存一次更新一次至最新储存时间\nstore_time = 0\n\n# 储存数据-储存一次-清空一次\ntemp_data = []\nstore_data = []\nmuxt = threading.RLock()\nstore_file_muxt = threading.RLock()\n\n\ndef store_params(params):\n    try:\n        t = insert_temp_data()\n        t.start()\n        t.do(params)\n    except Exception as msg:\n        print(str(msg))\n\n\nclass insert_temp_data(threading.Thread):\n    def __init__(self):\n        threading.Thread.__init__(self)\n\n    def do(self, data):\n        try:\n            global temp_data\n            global store_data\n            global store_time\n            muxt.acquire()\n            temp_data.append(data)\n            now_time = int(round(time.time()) * 1000)\n            if len(temp_data) >= 10000 or (now_time - store_time) >= 2000:\n                store_data = temp_data\n                t = insert_file()\n                t.start()\n                t.do(store_data)\n                temp_data = []\n                store_data = []\n                store_time = now_time\n        finally:\n            muxt.release()\n\nclass insert_file(threading.Thread):\n    def __init__(self):\n        threading.Thread.__init__(self)\n\n    def do(self, data):\n        try:\n            store_file_muxt.acquire()\n            with open(consts.collect_data_file_path, \'r\', encoding=\'utf-8\') as fr:\n                if not fr.read():\n                    tp = []\n                else:\n                    fr.seek(0)\n                    tp = json.load(fr)\n            tp += data\n            with open(consts.collect_data_file_path, \'w+\', encoding=\'utf-8\') as fw:\n                with multiprocessing.Lock():\n                    fw.write(json.dumps(tp))\n        finally:\n            store_file_muxt.release()\n\n\n\n# use demo\n# if __name__ == \'__main__\':\n#     store_params(\"sdf\")\n```\n', '2022-07-13 17:04:18', '2022-07-13 19:04:18', 1),
(90, 'go 实现for中超时跳过', '```\nfunc TestA(t *testing.T) {\n	ls := []int{1, 2, 3, 4, 5, 6, 7, 8}\n	for _, v := range ls {\n		var val = 0\n		var c1 = make(chan bool)\n		go func() {\n			if v == 4 {\n				time.Sleep(time.Duration(900) * time.Millisecond)\n			}else{\n				val = 1\n			}\n			c1 <- true\n		}()\n		select {\n		case <-c1:\n			//println(v,\"ok\")\n		case <-time.After(time.Duration(800) * time.Millisecond):\n			//println(v, \"time after\")\n			break\n		}\n		println(v,val)\n	}\n}\n```', '2023-02-06 19:06:56', NULL, 1),
(91, 'docker 创建 jenkins 容器', '```\ndocker run -u root -itd -p 2080:8080 -p 50000:50000 --name jenkins --privileged=true  -v /home/data/jenkins_home:/var/jenkins_home  jenkins/jenkins:lts\n```', '2023-02-09 13:19:03', '2023-02-14 14:10:37', 1),
(92, 'go 单元测试', '### 命令行\n```\npackage service\n\nimport \"testing\"\n\nfunc Add(i int)  int{\n	return 10+i\n}\nfunc TestAdd(t *testing.T) {\n	println(Add(10))\n}\nfunc TestDesc(t *testing.T) {\n	println(Add(10))\n}\n// 测试单个方法：go test some_test.go -v --run TestAdd\n// 测试当前文件所有方法：go test some_test.go -v \n```', '2023-02-22 17:18:34', NULL, 1),
(93, 'docker 解决报错：failed to create shim task: OCI', '## dockerfile为：\n```\nFROM golang:alpine  as builder\nENV GO111MODULE=on \\\n    CGO_ENABLED=0 \\\n    GOOS=linux \\\n    GOARCH=amd64 \\\n    GOPROXY=\"https://goproxy.cn,direct\"\nWORKDIR /app\nCOPY . .\nRUN  go mod tidy && go build -o blog_gin_api -ldflags=\"-w -s\" blog_api.go\nFROM  alpine:latest\nRUN apk add --no-cache bash\nWORKDIR  /root\nCOPY  --from=builder /app/config/config.toml  .\nCOPY  --from=builder /app/blog_gin_api  .\nEXPOSE 6008\nCMD [\"/root/blog_gin_api\"]\n\n```\n\n## 报错详情：\n```\ndocker: Error response from daemon: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: \"xxx\"\n```\n\n## 问题关键点在于 cmd []  这里\n## 解决方法\n```\n将\nCMD [\"/root/blog_gin_api\"]\n替换为：\nCMD [\"sh\", \"-c\", \"/root/blog_gin_api\"]\n\n```\n\n', '2023-02-22 20:05:36', NULL, 1);

-- --------------------------------------------------------

--
-- 表的结构 `blog_comment`
--

CREATE TABLE `blog_comment` (
  `id` int UNSIGNED NOT NULL,
  `username` varchar(16) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci NOT NULL,
  `is_author` tinyint(1) NOT NULL DEFAULT '0',
  `parent_id` int UNSIGNED DEFAULT NULL,
  `root_id` int UNSIGNED DEFAULT NULL,
  `content` varchar(255) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci NOT NULL,
  `created_time` varchar(255) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci NOT NULL,
  `article_id` int DEFAULT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb3 ROW_FORMAT=DYNAMIC;

-- --------------------------------------------------------

--
-- 表的结构 `blog_image`
--

CREATE TABLE `blog_image` (
  `id` int NOT NULL,
  `img_url` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '图片地址',
  `create_time` datetime NOT NULL,
  `type` tinyint DEFAULT NULL,
  `status` tinyint DEFAULT '1'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci COMMENT='图片素材库' ROW_FORMAT=DYNAMIC;

-- --------------------------------------------------------

--
-- 表的结构 `blog_tag`
--

CREATE TABLE `blog_tag` (
  `id` int UNSIGNED NOT NULL,
  `tag_name` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `article_sum` int DEFAULT '0'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=DYNAMIC;

--
-- 转存表中的数据 `blog_tag`
--

INSERT INTO `blog_tag` (`id`, `tag_name`, `article_sum`) VALUES
(1, 'Git', 1),
(2, 'Linux', 11),
(3, '随笔-杂文', 5),
(4, 'Mysql', 6),
(5, 'Golang', 22),
(6, '操作系统', 1),
(7, 'Php', 18),
(8, '数据结构与算法', 5),
(9, 'Redis', 7),
(10, '学习资源网站', 1),
(11, '微服务', 2),
(12, 'grpc', 0),
(13, 'Go-micro', 2),
(14, 'docker', 5),
(15, 'mqtt', 1),
(16, 'Nginx', 2),
(17, 'python', 5),
(18, 'node', 1);

-- --------------------------------------------------------

--
-- 表的结构 `blog_tag_article`
--

CREATE TABLE `blog_tag_article` (
  `id` int UNSIGNED NOT NULL,
  `tag_id` int UNSIGNED NOT NULL,
  `article_id` int UNSIGNED NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=DYNAMIC;

--
-- 转存表中的数据 `blog_tag_article`
--

INSERT INTO `blog_tag_article` (`id`, `tag_id`, `article_id`) VALUES
(1, 2, 1),
(2, 2, 2),
(3, 3, 3),
(4, 1, 4),
(5, 5, 5),
(6, 2, 5),
(7, 5, 7),
(8, 7, 8),
(9, 6, 6),
(10, 7, 9),
(11, 7, 10),
(12, 7, 11),
(13, 7, 12),
(14, 7, 13),
(15, 7, 14),
(16, 7, 15),
(17, 7, 16),
(18, 7, 17),
(19, 8, 18),
(20, 2, 19),
(21, 8, 20),
(22, 7, 20),
(23, 8, 22),
(24, 7, 22),
(25, 7, 21),
(26, 8, 21),
(27, 8, 23),
(28, 7, 23),
(29, 9, 24),
(30, 9, 25),
(31, 9, 26),
(32, 9, 27),
(33, 9, 28),
(34, 9, 29),
(35, 2, 30),
(36, 10, 31),
(37, 5, 32),
(38, 3, 33),
(39, 7, 34),
(40, 4, 35),
(41, 11, 36),
(42, 5, 37),
(43, 5, 38),
(44, 5, 39),
(45, 5, 40),
(46, 5, 41),
(47, 5, 42),
(48, 3, 43),
(49, 3, 44),
(50, 5, 45),
(51, 5, 46),
(52, 7, 47),
(53, 3, 48),
(54, 3, 49),
(55, 4, 50),
(56, 2, 51),
(57, 7, 52),
(58, 5, 53),
(59, 5, 54),
(60, 5, 55),
(61, 2, 56),
(62, 5, 57),
(63, 5, 58),
(64, 5, 59),
(65, 4, 60),
(66, 13, 61),
(67, 11, 61),
(68, 5, 61),
(69, 14, 62),
(70, 2, 63),
(71, 3, 64),
(72, 4, 65),
(73, 9, 66),
(74, 13, 67),
(75, 4, 68),
(76, 14, 69),
(77, 7, 70),
(78, 4, 71),
(79, 14, 72),
(80, 15, 72),
(81, 5, 73),
(82, 16, 74),
(83, 2, 75),
(84, 17, 77),
(85, 5, 78),
(86, 14, 79),
(87, 5, 79),
(88, 16, 79),
(89, 17, 81),
(90, 2, 82),
(91, 18, 83),
(92, 3, 84),
(93, 1, 84),
(94, 3, 85),
(95, 5, 86),
(96, 2, 86),
(97, 17, 87),
(98, 17, 88),
(99, 15, 88),
(100, 17, 89),
(101, 5, 90),
(102, 14, 91),
(103, 5, 92),
(104, 14, 93);

-- --------------------------------------------------------

--
-- 表的结构 `blog_user`
--

CREATE TABLE `blog_user` (
  `id` int UNSIGNED NOT NULL,
  `username` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `password` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `avatar` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,
  `introduction` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,
  `nickname` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL,
  `about` text CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=DYNAMIC;

--
-- 转存表中的数据 `blog_user`
--

INSERT INTO `blog_user` (`id`, `username`, `password`, `avatar`, `introduction`, `nickname`, `about`) VALUES
(1, 'ituserxxx', '7ec84e2b7a279d4ae33365c985d3d914', NULL, NULL, 'It User Xxx', NULL);

-- --------------------------------------------------------

--
-- 表的结构 `blog_visitor`
--

CREATE TABLE `blog_visitor` (
  `id` bigint UNSIGNED NOT NULL,
  `uri` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT '访问路径',
  `referer` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT '',
  `ua` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT 'user_agent',
  `ip` varchar(64) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `visit_time` datetime NOT NULL COMMENT '访问时间',
  `ip_address` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci DEFAULT NULL COMMENT '地址'
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci ROW_FORMAT=DYNAMIC;

--
-- 转存表中的数据 `blog_visitor`
--

INSERT INTO `blog_visitor` (`id`, `uri`, `referer`, `ua`, `ip`, `visit_time`, `ip_address`) VALUES
(1, '/blog/article/list', 'http://vtian.top/', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36', '', '2021-10-22 18:35:25', ''),

--
-- 转储表的索引
--

--
-- 表的索引 `blog_article`
--
ALTER TABLE `blog_article`
  ADD PRIMARY KEY (`id`) USING BTREE;

--
-- 表的索引 `blog_comment`
--
ALTER TABLE `blog_comment`
  ADD PRIMARY KEY (`id`) USING BTREE,
  ADD KEY `parent` (`parent_id`) USING BTREE,
  ADD KEY `root` (`root_id`) USING BTREE;

--
-- 表的索引 `blog_image`
--
ALTER TABLE `blog_image`
  ADD PRIMARY KEY (`id`) USING BTREE;

--
-- 表的索引 `blog_tag`
--
ALTER TABLE `blog_tag`
  ADD PRIMARY KEY (`id`) USING BTREE,
  ADD UNIQUE KEY `uni_name` (`tag_name`) USING BTREE;

--
-- 表的索引 `blog_tag_article`
--
ALTER TABLE `blog_tag_article`
  ADD PRIMARY KEY (`id`) USING BTREE,
  ADD KEY `tag_id` (`tag_id`) USING BTREE,
  ADD KEY `article_id` (`article_id`) USING BTREE;

--
-- 表的索引 `blog_user`
--
ALTER TABLE `blog_user`
  ADD PRIMARY KEY (`id`) USING BTREE,
  ADD UNIQUE KEY `uni_nam` (`username`) USING BTREE;

--
-- 表的索引 `blog_visitor`
--
ALTER TABLE `blog_visitor`
  ADD PRIMARY KEY (`id`) USING BTREE;

--
-- 在导出的表使用AUTO_INCREMENT
--

--
-- 使用表AUTO_INCREMENT `blog_article`
--
ALTER TABLE `blog_article`
  MODIFY `id` int NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=94;

--
-- 使用表AUTO_INCREMENT `blog_comment`
--
ALTER TABLE `blog_comment`
  MODIFY `id` int UNSIGNED NOT NULL AUTO_INCREMENT;

--
-- 使用表AUTO_INCREMENT `blog_image`
--
ALTER TABLE `blog_image`
  MODIFY `id` int NOT NULL AUTO_INCREMENT;

--
-- 使用表AUTO_INCREMENT `blog_tag`
--
ALTER TABLE `blog_tag`
  MODIFY `id` int UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=19;

--
-- 使用表AUTO_INCREMENT `blog_tag_article`
--
ALTER TABLE `blog_tag_article`
  MODIFY `id` int UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=105;

--
-- 使用表AUTO_INCREMENT `blog_user`
--
ALTER TABLE `blog_user`
  MODIFY `id` int UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=2;

--
-- 使用表AUTO_INCREMENT `blog_visitor`
--
ALTER TABLE `blog_visitor`
  MODIFY `id` bigint UNSIGNED NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=12532;

--
-- 限制导出的表
--

--
-- 限制表 `blog_comment`
--
ALTER TABLE `blog_comment`
  ADD CONSTRAINT `parent` FOREIGN KEY (`parent_id`) REFERENCES `blog_comment` (`id`) ON DELETE CASCADE ON UPDATE CASCADE,
  ADD CONSTRAINT `root` FOREIGN KEY (`root_id`) REFERENCES `blog_comment` (`id`) ON DELETE CASCADE ON UPDATE CASCADE;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
